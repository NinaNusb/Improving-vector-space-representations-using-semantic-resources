{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise dictionary that will contain the word embeddings\n",
    "#key=word\n",
    "#values=array of numerical representation of the corresponding word (vector)\n",
    "word_embeddings = {}\n",
    "#open pre-trained word embeddings stored in file\n",
    "with open(\"/Users/deeksha/Desktop/Improving-vector-space-representations-using-semantic-resources/data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\", 'r') as file:\n",
    "    #for each line in the file\n",
    "    for line in file:\n",
    "        #split the line into word and vector\n",
    "        values = line.split()\n",
    "        #get the first element which is the word\n",
    "        word = values[0]\n",
    "        #get the remainder of the values which will form the vector represenation of the word in a matrix\n",
    "        vector = np.array(values[1:], dtype='float32')\n",
    "        #assign key=word and values=vector\n",
    "        word_embeddings[word] = vector\n",
    "\n",
    "#Access word vectors\n",
    "#print(word_embeddings['talk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of word pairs from the lexical similarity file\n",
    "word_pairs = []\n",
    "#list of human scores for each word pair\n",
    "human_scores = []\n",
    "#open lexical_similarity file\n",
    "with open (\"/Users/deeksha/Desktop/Improving-vector-space-representations-using-semantic-resources/data/English/evaluations/lexical similarity/ws353_lexical_similarity.txt\", 'r') as file:\n",
    "    #for every line in the file\n",
    "    for line in file:\n",
    "        #split the line by space\n",
    "        #one line contains the word pair and its score\n",
    "        w1, w2, score = line.split()\n",
    "        #add the words to word_pairs\n",
    "        word_pairs.append((w1, w2))\n",
    "        #add the ratings to human_score\n",
    "        human_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('love', 'sex')\n",
      "6.77\n"
     ]
    }
   ],
   "source": [
    "print(word_pairs[0])\n",
    "print(human_scores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of cosine similarities\n",
    "scores = []\n",
    "\n",
    "#for every word pair\n",
    "for w1, w1 in word_pairs:\n",
    "    #check if the words exist in the word_embeddings\n",
    "    if w1 in word_embeddings and w2 in word_embeddings:\n",
    "        #retrieve word1's vector \n",
    "        vec1 = word_embeddings[w1]\n",
    "        #retreive word2's vector\n",
    "        vec2 = word_embeddings[w2]\n",
    "        #calculate cosine between the two vectors\n",
    "        similarity = 1 - cosine(vec1, vec2)\n",
    "        #add the result to scores\n",
    "        scores.append(round(similarity, 2))\n",
    "    #otherwise if words don't exist in the word embeddings\n",
    "    else:\n",
    "        #assign default value of 0.0\n",
    "        scores.append(0.00)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.77', '7.35', '10.00', '7.46', '7.62', '7.58', '5.77', '6.31', '7.50', '6.77', '7.42', '6.85', '6.19', '5.92', '7.00', '6.62', '6.81', '4.62', '5.81', '7.08', '8.08', '1.62', '1.31', '0.92', '1.81', '6.69', '3.73', '0.92', '7.46', '8.12', '7.73', '9.15', '0.31', '0.23', '8.58', '5.92', '6.69', '8.46', '7.65', '1.62', '9.44', '8.62', '9.03', '6.81', '6.63', '7.56', '6.73', '7.65', '2.50', '8.38', '7.38', '6.19', '6.73', '7.92', '8.12', '7.35', '4.88', '5.54', '8.46', '8.13', '3.04', '1.31', '5.96', '6.87', '7.85', '2.65', '8.94', '8.96', '9.29', '8.83', '9.10', '8.87', '9.02', '9.29', '8.79', '7.52', '7.10', '7.38', '6.46', '6.27', '2.69', '4.46', '5.85', '5.00', '2.08', '4.42', '4.38', '1.85', '3.08', '0.92', '3.15', '0.92', '0.54', '2.08', '0.54', '0.62', '8.42', '9.08', '9.04', '8.27', '7.57', '7.29', '8.50', '7.73', '6.88', '5.65', '3.31', '8.00', '8.00', '7.08', '6.85', '7.00', '4.77', '5.62', '5.87', '8.08', '7.00', '6.85', '7.42', '6.58', '6.42', '8.21', '7.69', '7.23', '6.71', '5.58', '7.48', '8.45', '8.06', '8.08', '8.02', '8.11', '7.92', '7.94', '5.85', '3.85', '2.81', '6.65', '2.50', '1.77', '6.04', '6.58', '6.85', '2.40', '2.92', '3.69', '2.15', '7.25', '5.00', '1.92', '5.90', '7.42', '7.27', '1.81', '5.06', '5.09', '6.78', '6.06', '6.94', '8.31', '4.59', '2.94', '5.63', '8.16', '7.53', '4.56', '6.34', '6.56', '2.38', '2.22', '8.66', '4.47', '5.34', '3.69', '3.00', '8.13', '6.31', '6.22', '6.50', '3.91', '2.56', '3.00', '5.63', '7.59', '3.16', '1.19', '3.31', '6.63', '4.75', '3.69', '4.25', '6.56', '4.25', '5.88', '5.94', '7.56', '2.75', '7.03', '5.47', '6.47', '7.91', '4.97', '5.00', '5.19', '7.03', '3.44', '2.31', '5.91', '7.38', '8.13', '4.63', '5.25', '5.03', '6.69', '7.88', '4.50', '4.75', '4.47', '3.25', '5.63', '3.69', '2.94', '5.28', '5.00', '6.44', '4.13', '4.75', '2.38', '4.94', '8.06', '5.31', '8.03', '5.94', '6.00', '5.41', '1.81', '8.97', '6.00', '6.72', '8.00', '4.81', '3.88', '5.16', '2.25', '6.44', '8.88', '6.88', '4.94', '2.56', '6.38', '7.81', '1.75', '4.25', '3.88', '2.88', '7.63', '6.48', '8.44', '7.50', '8.59', '6.34', '3.38', '6.00', '3.88', '7.63', '7.78', '9.22', '7.38', '6.09', '8.50', '8.31', '7.13', '5.91', '6.47', '3.38', '3.63', '7.13', '7.89', '5.97', '7.03', '7.69', '7.47', '6.19', '6.97', '3.56', '7.47', '8.34', '8.70', '7.81', '5.70', '6.22', '6.34', '4.06', '4.47', '5.97', '7.61', '8.36', '7.41', '2.69', '3.94', '7.16', '5.63', '7.53', '8.31', '8.81', '6.25', '8.30', '5.25', '8.53', '7.94', '6.88', '5.94', '4.06', '6.25', '7.72', '6.19', '2.97', '1.94', '3.75', '3.31', '3.69', '7.44', '6.41', '5.44', '6.25', '2.63', '0.88', '3.19', '4.69', '6.75', '5.31', '7.31', '5.75', '3.97', '3.47', '3.63', '5.56', '7.83', '3.88', '5.31', '6.81', '7.59', '7.19', '4.38', '6.53', '6.19', '7.69', '6.31', '6.03', '8.34', '6.25', '6.34', '3.78']\n",
      "[0.12, 0.15, 0.1, 0.15, 0.11, 0.21, 0.16, 0.16, 0.1, 0.18, 0.18, 0.08, 0.11, 0.13, 0.11, 0.21, 0.19, 0.1, 0.06, 0.12, 0.29, 0.07, 0.0, 0.09, 0.11, 0.11, 0.15, 0.29, 0.2, 0.12, 0.15, 0.07, 0.07, 0.07, 0.22, 0.07, 0.18, 0.0, 0.0, 0.12, 0.12, 0.2, 0.12, 0.15, 0.16, 0.06, 0.19, 0.12, 0.0, 0.19, 0.08, 0.04, 0.18, 0.22, 0.09, 0.12, 0.12, 0.12, 0.16, 0.08, 0.16, 0.13, 0.11, 0.06, 0.21, 0.21, 0.23, 0.14, 0.18, 0.1, 0.18, 0.13, 0.09, 0.14, 0.17, 0.13, 0.16, 0.12, 0.11, 0.34, 0.11, 0.22, 0.16, 0.06, 0.19, 0.15, 0.24, 0.27, 0.19, 0.29, 0.15, 0.09, 0.06, 0.19, 0.09, 0.18, 0.22, 0.07, 0.22, 0.24, 0.24, 0.26, 0.18, 0.11, 0.1, 0.07, 0.23, 0.09, 0.12, 0.07, 0.19, 0.2, 0.1, 0.18, 0.16, 0.12, 0.07, 0.1, 0.14, 0.12, 0.21, 0.0, 0.15, 0.13, 0.23, 0.11, 0.09, 0.08, 0.09, 0.17, 0.11, 0.02, 0.16, 0.3, 0.24, 0.1, 0.09, 0.19, 0.24, 0.21, 0.29, 0.14, 0.19, 0.09, 0.19, 0.14, 0.16, 0.11, 0.14, 0.1, 0.08, 0.15, 0.16, 0.16, 0.17, 0.1, 0.1, 0.15, 0.06, 0.09, 0.15, 0.22, 0.19, 0.11, 0.3, 0.06, 0.16, 0.15, 0.14, 0.15, 0.14, 0.15, 0.06, 0.3, 0.15, 0.22, 0.24, 0.15, 0.0, 0.33, 0.14, 0.16, 0.08, 0.3, 0.22, 0.14, 0.15, 0.18, 0.15, 0.19, 0.19, 0.28, 0.12, 0.1, 0.28, 0.15, 0.15, 0.19, 0.23, 0.08, 0.09, 0.28, 0.17, 0.08, 0.14, 0.16, 0.09, 0.09, 0.08, 0.0, 0.14, 0.13, 0.06, 0.2, 0.23, 0.26, 0.12, 0.05, 0.07, 0.32, 0.16, 0.14, 0.14, 0.18, 0.1, 0.11, 0.13, 0.08, 0.14, 0.07, 0.1, 0.1, 0.12, 0.13, 0.14, 0.25, 0.18, 0.25, 0.19, 0.12, 0.1, 0.21, 0.21, 0.13, 0.27, 0.29, 0.14, 0.14, 0.08, 0.25, 0.07, 0.05, 0.16, 0.2, 0.12, 0.12, 0.12, 0.1, 0.29, 0.18, 0.12, 0.19, 0.06, 0.06, 0.08, 0.13, 0.13, 0.17, 0.08, 0.17, 0.09, 0.13, 0.19, 0.16, 0.21, 0.12, 0.09, 0.22, 0.2, 0.19, 0.16, 0.16, 0.27, 0.16, 0.27, 0.18, 0.14, 0.08, 0.14, 0.21, 0.11, 0.05, 0.3, 0.13, 0.16, 0.16, 0.09, 0.09, 0.14, 0.2, 0.18, 0.18, 0.17, 0.15, 0.09, 0.16, 0.22, 0.19, 0.09, 0.22, 0.1, 0.13, 0.29, 0.07, 0.25, 0.2, 0.19, 0.12, 0.22, 0.3, 0.24, 0.0, 0.11, 0.11, 0.1, 0.3, 0.13, 0.23, 0.31, 0.12, 0.27, 0.14, 0.23, 0.18, 0.2, 0.19, 0.2, 0.2, 0.13, 0.13, 0.23, 0.17, 0.22, 0.3, 0.26, 0.26, -0.0, 0.14, 0.18, 0.07, 0.26, 0.19, 1]\n"
     ]
    }
   ],
   "source": [
    "print(human_scores)\n",
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spearman\n",
    "- a statistical measure to see how 2 things are related to each other (used when the relation between to sets of data is not a straight line, e.g. relatio between height and weight). \n",
    "\n",
    "- range from [-1, 1]:\n",
    "    - if close to 1, then as one var goes up the other var tends to go up too\n",
    "    - if close to -1, then as one var goes up the other var tends to go down\n",
    "    - if close to 0, then there's not much of a relation between the two vars\n",
    "\n",
    "\n",
    "- affected by outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient:  -0.078\n"
     ]
    }
   ],
   "source": [
    "#calculate the spearman rank correlation\n",
    "spearman_correlation, _ = spearmanr(human_scores, scores)\n",
    "print(\"Correlation coefficient: \", round(spearman_correlation,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pearson\n",
    "\n",
    "- a statistical measure that quantifies the strength and direction of the linear relationshipo between two continuous variables.\n",
    "\n",
    "- range from [-1, 1]. Same interpretation as Spearman\n",
    "\n",
    "- p_value (point of reference, usually, O,05) determines how genuine the relation between the two vars are (if they are random or not)\n",
    "    - high p_value -> relation due to random chance\n",
    "    - low p_value -> evidence of a significant or real relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation coefficient:  -0.0843\n",
      "p_value:  0.1139\n"
     ]
    }
   ],
   "source": [
    "#convert values from string to float\n",
    "human_scores = [float(value) for value in (human_scores)]\n",
    "#compute the pearson correlation coefficient and the p_value\n",
    "pearsonr_correlation, p_value = pearsonr(human_scores, scores)\n",
    "\n",
    "#print results\n",
    "print(\"Correlation coefficient: \", round(pearsonr_correlation, 4))\n",
    "print(\"p_value: \", round(p_value, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
