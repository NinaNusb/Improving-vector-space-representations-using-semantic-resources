{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to /Users/deeksha/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import nltk\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for creating a semantic lexicon dictionary \n",
    "def semantic_lexicon_dict(target_words):\n",
    "    #dictionary to store the related words for each target word\n",
    "    #keys = target words\n",
    "    #values = list related words\n",
    "    lexicon = {}\n",
    "\n",
    "    #Use WordNet to find related words through various semantic relations for each target word\n",
    "    #loop over the target words\n",
    "    for word in target_words:\n",
    "        #initialise empty related_words list which will hold \n",
    "        #all the semantically related words extracted from WordNet\n",
    "        related_words = []\n",
    "        #iterate through each synset (set of synonyms)\n",
    "        for syn in wn.synsets(word, lang='fra'):\n",
    "            #iterate thorugh each lemma (individual word) for the synset and append to related_words\n",
    "            for lemma in syn.lemmas('fra'):\n",
    "                if lemma.name() != word:\n",
    "                    related_words.append(lemma.name())\n",
    "            #check antonym for first lemma of the synset and append\n",
    "            if syn.lemmas('fra')[0].antonyms():\n",
    "                related_words.append(syn.lemmas('fra')[0].antonyms()[0].name())\n",
    "            #check for hyponym and append\n",
    "            for hypo in syn.hyponyms():\n",
    "                for lemma in hypo.lemmas('fra'):\n",
    "                    related_words.append(lemma.name())\n",
    "            #check for hypernym and append\n",
    "            for hyper in syn.hypernyms():\n",
    "                for lemma in hyper.lemmas('fra'):\n",
    "                    related_words.append(lemma.name())\n",
    "            #check for meronym and append\n",
    "            for part in syn.part_meronyms():\n",
    "                for lemma in part.lemmas('fra'):\n",
    "                    related_words.append(lemma.name())\n",
    "            #check for holonym and append\n",
    "            for whole in syn.part_holonyms():\n",
    "                for lemma in whole.lemmas('fra'):\n",
    "                    related_words.append(lemma.name())\n",
    "            #iterate through each lemma for the current synset\n",
    "            #for each lemma not the same as target word\n",
    "            #find all lemmas that have same spelling and append\n",
    "            for lemma in syn.lemmas('fra'):\n",
    "                if lemma.name() != word:\n",
    "                    homonyms = wn.lemmas(lemma.name())\n",
    "                    for homonym in homonyms:\n",
    "                        related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gentil': ['affriolant', 'alléchant', 'attachant', 'attirant', 'attrayant', 'mignon', 'ravissant', 'accommodant', 'affable', 'amène', 'affable', 'aimable', 'affable', 'aimable', 'amical', 'amène', 'affable', 'léger', 'mou', 'adorable', 'attendrissant', 'attractif', 'mignon', 'adorable', 'angélique', 'affriolant', 'aguicheur', 'alléchant', 'attachant', 'attirant', 'attractif', 'attrayant', 'mignon', 'ravissant', 'goy', 'goï', 'Christian', 'chrétien', 'chrétienne', 'goy'], 'joli': [], 'chien': ['canis_familiaris', 'basenji', 'corgi', 'bâtard', 'corniaud', 'dalmatien', 'Chien_de_montagne_des_Pyrénées', 'bichon', 'Leonberg', 'Terre-Neuve', 'aboyeur', 'chien', 'chienchien', 'clébard', 'toutou', 'caniche', 'carlin', 'chiot', 'jouet', 'canin', 'canine', 'animal_domestique', 'drapeau', 'Canis_familiaris', 'aboyeur', 'chienchien', 'clébard', 'toutou', 'canis_familiaris', 'chien', 'chien_de_chasse', 'afghan', 'lévrier_afghan', 'basset_hound', 'beagle', 'chien_de_saint-hubert', 'détective', 'limier', 'fox_hound', 'lévrier', 'lévrier_anglais', 'busard', 'Lévrier_persan', 'lévrier_persan', 'lévrier_écossais', 'braque_de_Weimar', 'appui', 'soutien', 'support', 'clic', 'cliquer', 'cliquet', 'stop', 'franc', 'hot-dog', 'andouille', 'saucisse', 'saucisson', 'hot-dog', 'red_hot', 'franc', 'hot-dog', 'achille', 'quignon', 'talon', 'Moi', 'canaille', 'gredin', 'méchant', 'scélérat', 'vilain', 'talon', 'gars', 'individu', 'mec']}\n",
      "['canis_familiaris', 'basenji', 'corgi', 'bâtard', 'corniaud', 'dalmatien', 'Chien_de_montagne_des_Pyrénées', 'bichon', 'Leonberg', 'Terre-Neuve', 'aboyeur', 'chien', 'chienchien', 'clébard', 'toutou', 'caniche', 'carlin', 'chiot', 'jouet', 'canin', 'canine', 'animal_domestique', 'drapeau', 'Canis_familiaris', 'aboyeur', 'chienchien', 'clébard', 'toutou', 'canis_familiaris', 'chien', 'chien_de_chasse', 'afghan', 'lévrier_afghan', 'basset_hound', 'beagle', 'chien_de_saint-hubert', 'détective', 'limier', 'fox_hound', 'lévrier', 'lévrier_anglais', 'busard', 'Lévrier_persan', 'lévrier_persan', 'lévrier_écossais', 'braque_de_Weimar', 'appui', 'soutien', 'support', 'clic', 'cliquer', 'cliquet', 'stop', 'franc', 'hot-dog', 'andouille', 'saucisse', 'saucisson', 'hot-dog', 'red_hot', 'franc', 'hot-dog', 'achille', 'quignon', 'talon', 'Moi', 'canaille', 'gredin', 'méchant', 'scélérat', 'vilain', 'talon', 'gars', 'individu', 'mec']\n"
     ]
    }
   ],
   "source": [
    "#Define the target words (sentiment analysis task)\n",
    "\n",
    "target_words = ['gentil', 'joli', 'chien']\n",
    "\n",
    "#Create the semantic lexicon dictionary by passing the target words as argument\n",
    "semantic_lexicon_dictionary = semantic_lexicon_dict(target_words)\n",
    "\n",
    "#prints the semantic lexicon dictionary\n",
    "print(semantic_lexicon_dictionary)\n",
    "\n",
    "#check the semantically related words for \"x\"\n",
    "print(semantic_lexicon_dictionary.get(\"chien\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
