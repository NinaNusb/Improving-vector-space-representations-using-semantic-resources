{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, matutils\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation of the retrofitting algorithm on a toy corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generating a toy corpus of the same format as the real corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained Word2Vec model to generate the toy corpus\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating functions to generate a toy corpus in the same format as for the provided word embeddings\n",
    "def convert_matrix_to_dict(wordVecMat, wordList):\n",
    "    wordVecs = {}\n",
    "    for i, word in enumerate(wordList):\n",
    "        wordVecs[word] = wordVecMat[i]\n",
    "    return wordVecs\n",
    "\n",
    "def convert_dict_to_matrix(wordVecs):\n",
    "    wordVecMat = np.stack(list(wordVecs.values()))\n",
    "    return wordVecMat\n",
    "\n",
    "def vectorize_list(corpus):\n",
    "    corpus_vecs = [model[word] for word in corpus]\n",
    "    return corpus_vecs\n",
    "\n",
    "# Useful for the big corpus to retrive the word list from the keys\n",
    "def get_embeddings_words(wordVecs):\n",
    "    wordList = list(wordVecs.keys()) \n",
    "    return wordList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same input format as the real corpus, i.e a dictionnary having for keys the words and for values their corresponding embeddings\n",
    "toy_corpus = [\"cat\", \"tiger\", \"computer\", \"keyboard\", \"plane\", \"car\", \"doctor\", \"nurse\", \"love\", \"sex\"]\n",
    "toy_list_vecs = vectorize_list(toy_corpus)\n",
    "toy_wordVecs = convert_matrix_to_dict(toy_list_vecs, toy_corpus)\n",
    "toy_wordList = get_embeddings_words(toy_wordVecs) # Not necessary for the toy corpus as toy_wordList == toy_corpus but generated here for reproductibility reasons with the real corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Calculating the similarities between the words of the corpus before the retrofitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    similarity = dot_product / norm_product\n",
    "    return similarity\n",
    "\n",
    "def generate_cosine_similarity_matrix(dict_vecs): \n",
    "    num_vectors = len(dict_vecs)\n",
    "    similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "    for i, word1 in enumerate(dict_vecs):\n",
    "        for j, word2 in enumerate(dict_vecs):\n",
    "            similarity_matrix[i, j] = calculate_cosine_similarity(dict_vecs[word1], dict_vecs[word2])\n",
    "    return similarity_matrix\n",
    "\n",
    "def print_vec_similarities(wordList, similarity_matrix):\n",
    "    for word, vec in zip(wordList, similarity_matrix):\n",
    "        print(f'Similarities with \"{word}\":')\n",
    "        for i in range(len(vec)):\n",
    "            similarity = vec[i]\n",
    "            print(f'  - \"{wordList[i]}\": {similarity:.4f}')\n",
    "        print()\n",
    "\n",
    "def print_vec_difference(wordList, similarity_matrix1, similarity_matrix2):\n",
    "    for i, word in enumerate(wordList):\n",
    "        print(f\"\\nSimilarities with \\\"{word}\\\":\")\n",
    "        for j, neighbor in enumerate(wordList):\n",
    "            similarity1 = similarity_matrix1[i, j]\n",
    "            similarity2 = similarity_matrix2[i, j]\n",
    "            difference = similarity2 - similarity1 \n",
    "            print(f\"  - \\\"{neighbor}\\\": {similarity1:.4f} -> {similarity2:.4f} (Difference: {difference:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 10)\n",
      "2\n",
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a matrix of similarity between the word vectors of the corpus\n",
    "toy_similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "# Check its shape and dimension\n",
    "print(type(toy_similarity_matrix)) \n",
    "print(toy_similarity_matrix.shape)  \n",
    "print(toy_similarity_matrix.ndim) \n",
    "print('')\n",
    "print_vec_similarities(toy_wordList, toy_similarity_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Managing the words' neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon(target_words, relation_types):\n",
    "    lexicon = {}\n",
    "        \n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "                    if \"antonyms\" in relation_types:\n",
    "                        if syn.lemmas()[0].antonyms():\n",
    "                            related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "                    if \"hyponyms\" in relation_types:\n",
    "                        for hypo in syn.hyponyms():\n",
    "                            for lemma in hypo.lemmas():\n",
    "                                related_words.append(lemma.name())\n",
    "                    if \"hypernyms\" in relation_types:\n",
    "                        for hyper in syn.hypernyms():\n",
    "                            for lemma in hyper.lemmas():\n",
    "                                related_words.append(lemma.name())\n",
    "                    if \"meronyms\" in relation_types:\n",
    "                        for part in syn.part_meronyms():\n",
    "                            for lemma in part.lemmas():\n",
    "                                related_words.append(lemma.name())\n",
    "                    if \"holonyms\" in relation_types:\n",
    "                        for whole in syn.part_holonyms():\n",
    "                            for lemma in whole.lemmas():\n",
    "                                related_words.append(lemma.name())\n",
    "                    if \"homonyms\" in relation_types:\n",
    "                        for lemma in syn.lemmas():\n",
    "                            if lemma.name() != word:\n",
    "                                homonyms = wordnet.lemmas(lemma.name())\n",
    "                                for homonym in homonyms:\n",
    "                                    related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Generate a matrix of embeddings from the values in the word vectors dictionary\n",
    "toy_wordVecMat = convert_dict_to_matrix(toy_wordVecs)\n",
    "\n",
    "# Checking its shape and dimension \n",
    "print(type(toy_wordVecMat)) \n",
    "print(toy_wordVecMat.shape)  \n",
    "print(toy_wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbors_embedding_matrix(wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        embeddings = [\n",
    "            model.get_vector(neighbor)\n",
    "            for neighbor in neighbors\n",
    "            if model.has_index_for(neighbor)\n",
    "        ]\n",
    "        if len(embeddings) > 0:\n",
    "            average_embedding = np.sum(embeddings, axis=0) / len(embeddings)\n",
    "        else:\n",
    "            # Handle the case where a word has no embeddings for its synonyms\n",
    "            average_embedding = np.zeros(model.vector_size) \n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "    return neighbors_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Generate the neighbor matrix for the words in the toy corpus\n",
    "toy_neighbors_matrix = create_neighbors_embedding_matrix(toy_wordList, \"synonyms\")\n",
    "# Check its shape and dimension (they should match those of the matrix of embeddings)\n",
    "print(type(toy_neighbors_matrix)) \n",
    "print(toy_neighbors_matrix.shape) \n",
    "print(toy_neighbors_matrix.ndim) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Retrofitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter):\n",
    "    # Create a deep copy of wordVecMat \n",
    "    newWordVecMat = np.copy(wordVecMat, order='K')\n",
    "    \n",
    "    for _ in range(nb_iter):        \n",
    "        # Update the word embeddings using retrofitting formula\n",
    "        newWordVecMat = (alpha * newWordVecMat + beta * neighbors_matrix) / (alpha + beta)\n",
    "\n",
    "        # TODO: calculer similarité après chaque itération\n",
    "        # Stoping criterion\n",
    "        if np.linalg.norm(newWordVecMat - wordVecMat) < 1e-2:\n",
    "            break # TODO: return the embedding\n",
    "\n",
    "    return newWordVecMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.2028 (Difference: -0.3145)\n",
      "  - \"computer\": 0.1732 -> 0.1974 (Difference: 0.0241)\n",
      "  - \"keyboard\": 0.1834 -> 0.2057 (Difference: 0.0223)\n",
      "  - \"plane\": 0.1833 -> 0.3947 (Difference: 0.2114)\n",
      "  - \"car\": 0.2153 -> 0.2636 (Difference: 0.0483)\n",
      "  - \"doctor\": 0.1292 -> 0.3436 (Difference: 0.2144)\n",
      "  - \"nurse\": 0.1594 -> 0.5487 (Difference: 0.3893)\n",
      "  - \"love\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"sex\": 0.1368 -> 0.2601 (Difference: 0.1233)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.2028 (Difference: -0.3145)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"keyboard\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"plane\": 0.1660 -> 0.0734 (Difference: -0.0926)\n",
      "  - \"car\": 0.1672 -> 0.1005 (Difference: -0.0668)\n",
      "  - \"doctor\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"nurse\": 0.1111 -> 0.2028 (Difference: 0.0917)\n",
      "  - \"love\": 0.0871 -> 0.1912 (Difference: 0.1041)\n",
      "  - \"sex\": 0.2222 -> 0.1883 (Difference: -0.0339)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1974 (Difference: 0.0241)\n",
      "  - \"tiger\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.2398 (Difference: -0.1566)\n",
      "  - \"plane\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"car\": 0.2461 -> 0.2276 (Difference: -0.0185)\n",
      "  - \"doctor\": 0.1628 -> 0.2100 (Difference: 0.0472)\n",
      "  - \"nurse\": 0.2178 -> 0.1209 (Difference: -0.0969)\n",
      "  - \"love\": 0.0573 -> 0.2347 (Difference: 0.1774)\n",
      "  - \"sex\": 0.1853 -> 0.0771 (Difference: -0.1083)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2057 (Difference: 0.0223)\n",
      "  - \"tiger\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"computer\": 0.3964 -> 0.2398 (Difference: -0.1566)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.2897 (Difference: 0.1891)\n",
      "  - \"car\": 0.1498 -> 0.1576 (Difference: 0.0077)\n",
      "  - \"doctor\": 0.0850 -> 0.1381 (Difference: 0.0530)\n",
      "  - \"nurse\": 0.1220 -> 0.1669 (Difference: 0.0449)\n",
      "  - \"love\": 0.1591 -> 0.2741 (Difference: 0.1149)\n",
      "  - \"sex\": 0.0943 -> 0.1065 (Difference: 0.0122)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.3947 (Difference: 0.2114)\n",
      "  - \"tiger\": 0.1660 -> 0.0734 (Difference: -0.0926)\n",
      "  - \"computer\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"keyboard\": 0.1006 -> 0.2897 (Difference: 0.1891)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3545 (Difference: -0.0235)\n",
      "  - \"doctor\": 0.1879 -> 0.2185 (Difference: 0.0306)\n",
      "  - \"nurse\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"love\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"sex\": 0.0587 -> 0.1187 (Difference: 0.0600)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2636 (Difference: 0.0483)\n",
      "  - \"tiger\": 0.1672 -> 0.1005 (Difference: -0.0668)\n",
      "  - \"computer\": 0.2461 -> 0.2276 (Difference: -0.0185)\n",
      "  - \"keyboard\": 0.1498 -> 0.1576 (Difference: 0.0077)\n",
      "  - \"plane\": 0.3780 -> 0.3545 (Difference: -0.0235)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"nurse\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"love\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"sex\": 0.1169 -> 0.0665 (Difference: -0.0504)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.3436 (Difference: 0.2144)\n",
      "  - \"tiger\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"computer\": 0.1628 -> 0.2100 (Difference: 0.0472)\n",
      "  - \"keyboard\": 0.0850 -> 0.1381 (Difference: 0.0530)\n",
      "  - \"plane\": 0.1879 -> 0.2185 (Difference: 0.0306)\n",
      "  - \"car\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.3451 (Difference: -0.2868)\n",
      "  - \"love\": 0.0831 -> 0.3307 (Difference: 0.2476)\n",
      "  - \"sex\": 0.1994 -> 0.1756 (Difference: -0.0238)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.5487 (Difference: 0.3893)\n",
      "  - \"tiger\": 0.1111 -> 0.2028 (Difference: 0.0917)\n",
      "  - \"computer\": 0.2178 -> 0.1209 (Difference: -0.0969)\n",
      "  - \"keyboard\": 0.1220 -> 0.1669 (Difference: 0.0449)\n",
      "  - \"plane\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"car\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"doctor\": 0.6320 -> 0.3451 (Difference: -0.2868)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"love\": 0.0631 -> 0.5446 (Difference: 0.4815)\n",
      "  - \"sex\": 0.1997 -> 0.4092 (Difference: 0.2095)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"tiger\": 0.0871 -> 0.1912 (Difference: 0.1041)\n",
      "  - \"computer\": 0.0573 -> 0.2347 (Difference: 0.1774)\n",
      "  - \"keyboard\": 0.1591 -> 0.2741 (Difference: 0.1149)\n",
      "  - \"plane\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"car\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"doctor\": 0.0831 -> 0.3307 (Difference: 0.2476)\n",
      "  - \"nurse\": 0.0631 -> 0.5446 (Difference: 0.4815)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3620 (Difference: 0.0980)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2601 (Difference: 0.1233)\n",
      "  - \"tiger\": 0.2222 -> 0.1883 (Difference: -0.0339)\n",
      "  - \"computer\": 0.1853 -> 0.0771 (Difference: -0.1083)\n",
      "  - \"keyboard\": 0.0943 -> 0.1065 (Difference: 0.0122)\n",
      "  - \"plane\": 0.0587 -> 0.1187 (Difference: 0.0600)\n",
      "  - \"car\": 0.1169 -> 0.0665 (Difference: -0.0504)\n",
      "  - \"doctor\": 0.1994 -> 0.1756 (Difference: -0.0238)\n",
      "  - \"nurse\": 0.1997 -> 0.4092 (Difference: 0.2095)\n",
      "  - \"love\": 0.2639 -> 0.3620 (Difference: 0.0980)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Retrofitting the toy word embeddings\n",
    "toy_retrofitted_vecs = retrofitting_wordVecs(toy_wordVecMat, toy_neighbors_matrix, alpha=1, beta=1, nb_iter=10)\n",
    "# Convert the matrix of retrofitted embeddings to a dictionary\n",
    "toy_retrofitted_wordVecs = convert_matrix_to_dict(toy_retrofitted_vecs, toy_wordList)\n",
    "# Generate the similarity matrix\n",
    "toy_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(toy_retrofitted_wordVecs)\n",
    "print_vec_difference(toy_wordList, toy_similarity_matrix, toy_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_embedding_updates(original_matrix, retrofitted_matrix):\n",
    "    absolute_diff = np.abs(original_matrix - retrofitted_matrix)\n",
    "    mean_absolute_diff = np.mean(absolute_diff)\n",
    "    return mean_absolute_diff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Tuning the (hyper)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 1.1000000000000003, 'nb_iter': 15}\n",
      "Best embedding update: 0.12671235242449622\n"
     ]
    }
   ],
   "source": [
    "# Tuning the (hyper)parameters\n",
    "toy_best_embed_update = 0  # Variable to store the best similarity score\n",
    "toy_best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "\n",
    "# TODO: Testing on \"cat\" and \"tiger\": the human score is 0.735\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1,16):\n",
    "            # Retrofit the embeddings\n",
    "            toy_retrofitted_vec_tn = retrofitting_wordVecs(toy_wordVecMat, toy_neighbors_matrix, alpha, beta, nb_iter)\n",
    "            toy_embed_update = measure_embedding_updates(toy_wordVecMat, toy_retrofitted_vec_tn)\n",
    "            # print(\" alpha =\", alpha, \" beta=\", beta, \"nb_iter =\", nb_iter, \" similarity score =\", similarity_score)\n",
    "            if toy_embed_update > toy_best_embed_update:\n",
    "                toy_best_embed_update = toy_embed_update\n",
    "                toy_best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "print(\"Best hyperparameters:\", toy_best_params)\n",
    "print(\"Best embedding update:\", toy_best_embed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.2020 (Difference: -0.3153)\n",
      "  - \"computer\": 0.1732 -> 0.1972 (Difference: 0.0239)\n",
      "  - \"keyboard\": 0.1834 -> 0.2055 (Difference: 0.0220)\n",
      "  - \"plane\": 0.1833 -> 0.3945 (Difference: 0.2111)\n",
      "  - \"car\": 0.2153 -> 0.2635 (Difference: 0.0482)\n",
      "  - \"doctor\": 0.1292 -> 0.3434 (Difference: 0.2141)\n",
      "  - \"nurse\": 0.1594 -> 0.5485 (Difference: 0.3892)\n",
      "  - \"love\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"sex\": 0.1368 -> 0.2599 (Difference: 0.1231)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.2020 (Difference: -0.3153)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"keyboard\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"plane\": 0.1660 -> 0.0731 (Difference: -0.0930)\n",
      "  - \"car\": 0.1672 -> 0.1003 (Difference: -0.0669)\n",
      "  - \"doctor\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"nurse\": 0.1111 -> 0.2026 (Difference: 0.0915)\n",
      "  - \"love\": 0.0871 -> 0.1910 (Difference: 0.1040)\n",
      "  - \"sex\": 0.2222 -> 0.1881 (Difference: -0.0341)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1972 (Difference: 0.0239)\n",
      "  - \"tiger\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.2393 (Difference: -0.1571)\n",
      "  - \"plane\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"car\": 0.2461 -> 0.2273 (Difference: -0.0188)\n",
      "  - \"doctor\": 0.1628 -> 0.2099 (Difference: 0.0471)\n",
      "  - \"nurse\": 0.2178 -> 0.1207 (Difference: -0.0971)\n",
      "  - \"love\": 0.0573 -> 0.2348 (Difference: 0.1775)\n",
      "  - \"sex\": 0.1853 -> 0.0769 (Difference: -0.1084)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2055 (Difference: 0.0220)\n",
      "  - \"tiger\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"computer\": 0.3964 -> 0.2393 (Difference: -0.1571)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.2897 (Difference: 0.1892)\n",
      "  - \"car\": 0.1498 -> 0.1575 (Difference: 0.0077)\n",
      "  - \"doctor\": 0.0850 -> 0.1380 (Difference: 0.0530)\n",
      "  - \"nurse\": 0.1220 -> 0.1668 (Difference: 0.0448)\n",
      "  - \"love\": 0.1591 -> 0.2741 (Difference: 0.1150)\n",
      "  - \"sex\": 0.0943 -> 0.1064 (Difference: 0.0121)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.3945 (Difference: 0.2111)\n",
      "  - \"tiger\": 0.1660 -> 0.0731 (Difference: -0.0930)\n",
      "  - \"computer\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"keyboard\": 0.1006 -> 0.2897 (Difference: 0.1892)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3540 (Difference: -0.0239)\n",
      "  - \"doctor\": 0.1879 -> 0.2183 (Difference: 0.0305)\n",
      "  - \"nurse\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"love\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"sex\": 0.0587 -> 0.1186 (Difference: 0.0599)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2635 (Difference: 0.0482)\n",
      "  - \"tiger\": 0.1672 -> 0.1003 (Difference: -0.0669)\n",
      "  - \"computer\": 0.2461 -> 0.2273 (Difference: -0.0188)\n",
      "  - \"keyboard\": 0.1498 -> 0.1575 (Difference: 0.0077)\n",
      "  - \"plane\": 0.3780 -> 0.3540 (Difference: -0.0239)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"nurse\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"love\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"sex\": 0.1169 -> 0.0663 (Difference: -0.0506)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.3434 (Difference: 0.2141)\n",
      "  - \"tiger\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"computer\": 0.1628 -> 0.2099 (Difference: 0.0471)\n",
      "  - \"keyboard\": 0.0850 -> 0.1380 (Difference: 0.0530)\n",
      "  - \"plane\": 0.1879 -> 0.2183 (Difference: 0.0305)\n",
      "  - \"car\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.3445 (Difference: -0.2875)\n",
      "  - \"love\": 0.0831 -> 0.3308 (Difference: 0.2477)\n",
      "  - \"sex\": 0.1994 -> 0.1755 (Difference: -0.0239)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.5485 (Difference: 0.3892)\n",
      "  - \"tiger\": 0.1111 -> 0.2026 (Difference: 0.0915)\n",
      "  - \"computer\": 0.2178 -> 0.1207 (Difference: -0.0971)\n",
      "  - \"keyboard\": 0.1220 -> 0.1668 (Difference: 0.0448)\n",
      "  - \"plane\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"car\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"doctor\": 0.6320 -> 0.3445 (Difference: -0.2875)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.5447 (Difference: 0.4817)\n",
      "  - \"sex\": 0.1997 -> 0.4091 (Difference: 0.2094)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"tiger\": 0.0871 -> 0.1910 (Difference: 0.1040)\n",
      "  - \"computer\": 0.0573 -> 0.2348 (Difference: 0.1775)\n",
      "  - \"keyboard\": 0.1591 -> 0.2741 (Difference: 0.1150)\n",
      "  - \"plane\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"car\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"doctor\": 0.0831 -> 0.3308 (Difference: 0.2477)\n",
      "  - \"nurse\": 0.0631 -> 0.5447 (Difference: 0.4817)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3616 (Difference: 0.0977)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2599 (Difference: 0.1231)\n",
      "  - \"tiger\": 0.2222 -> 0.1881 (Difference: -0.0341)\n",
      "  - \"computer\": 0.1853 -> 0.0769 (Difference: -0.1084)\n",
      "  - \"keyboard\": 0.0943 -> 0.1064 (Difference: 0.0121)\n",
      "  - \"plane\": 0.0587 -> 0.1186 (Difference: 0.0599)\n",
      "  - \"car\": 0.1169 -> 0.0663 (Difference: -0.0506)\n",
      "  - \"doctor\": 0.1994 -> 0.1755 (Difference: -0.0239)\n",
      "  - \"nurse\": 0.1997 -> 0.4091 (Difference: 0.2094)\n",
      "  - \"love\": 0.2639 -> 0.3616 (Difference: 0.0977)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Retrofitting the original embeddings with the new (hyper)parameter values\n",
    "toy_new_retrofitted_vec = retrofitting_wordVecs(toy_wordVecMat, toy_neighbors_matrix, alpha=0.1, beta=1.1000000000000003, nb_iter=15)\n",
    "toy_new_retrofitted_dict = convert_matrix_to_dict(toy_new_retrofitted_vec, toy_wordList)\n",
    "toy_new_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(toy_new_retrofitted_dict)\n",
    "print_vec_difference(toy_wordList, toy_similarity_matrix, toy_new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"tiger\": 0.2028 -> 0.2020 (Difference: -0.0008)\n",
      "  - \"computer\": 0.1974 -> 0.1972 (Difference: -0.0002)\n",
      "  - \"keyboard\": 0.2057 -> 0.2055 (Difference: -0.0003)\n",
      "  - \"plane\": 0.3947 -> 0.3945 (Difference: -0.0002)\n",
      "  - \"car\": 0.2636 -> 0.2635 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.3436 -> 0.3434 (Difference: -0.0002)\n",
      "  - \"nurse\": 0.5487 -> 0.5485 (Difference: -0.0001)\n",
      "  - \"love\": 0.5941 -> 0.5941 (Difference: -0.0001)\n",
      "  - \"sex\": 0.2601 -> 0.2599 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.2028 -> 0.2020 (Difference: -0.0008)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0903 -> 0.0903 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1831 -> 0.1831 (Difference: 0.0001)\n",
      "  - \"plane\": 0.0734 -> 0.0731 (Difference: -0.0004)\n",
      "  - \"car\": 0.1005 -> 0.1003 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.0891 -> 0.0891 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.2028 -> 0.2026 (Difference: -0.0002)\n",
      "  - \"love\": 0.1912 -> 0.1910 (Difference: -0.0002)\n",
      "  - \"sex\": 0.1883 -> 0.1881 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1974 -> 0.1972 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0903 -> 0.0903 (Difference: 0.0000)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.2398 -> 0.2393 (Difference: -0.0004)\n",
      "  - \"plane\": 0.4086 -> 0.4086 (Difference: -0.0000)\n",
      "  - \"car\": 0.2276 -> 0.2273 (Difference: -0.0003)\n",
      "  - \"doctor\": 0.2100 -> 0.2099 (Difference: -0.0001)\n",
      "  - \"nurse\": 0.1209 -> 0.1207 (Difference: -0.0002)\n",
      "  - \"love\": 0.2347 -> 0.2348 (Difference: 0.0001)\n",
      "  - \"sex\": 0.0771 -> 0.0769 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2057 -> 0.2055 (Difference: -0.0003)\n",
      "  - \"tiger\": 0.1831 -> 0.1831 (Difference: 0.0001)\n",
      "  - \"computer\": 0.2398 -> 0.2393 (Difference: -0.0004)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.2897 -> 0.2897 (Difference: 0.0000)\n",
      "  - \"car\": 0.1576 -> 0.1575 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.1381 -> 0.1380 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.1669 -> 0.1668 (Difference: -0.0001)\n",
      "  - \"love\": 0.2741 -> 0.2741 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1065 -> 0.1064 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.3947 -> 0.3945 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0734 -> 0.0731 (Difference: -0.0004)\n",
      "  - \"computer\": 0.4086 -> 0.4086 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.2897 -> 0.2897 (Difference: 0.0000)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3545 -> 0.3540 (Difference: -0.0004)\n",
      "  - \"doctor\": 0.2185 -> 0.2183 (Difference: -0.0001)\n",
      "  - \"nurse\": 0.2824 -> 0.2824 (Difference: -0.0000)\n",
      "  - \"love\": 0.3285 -> 0.3285 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1187 -> 0.1186 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2636 -> 0.2635 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.1005 -> 0.1003 (Difference: -0.0001)\n",
      "  - \"computer\": 0.2276 -> 0.2273 (Difference: -0.0003)\n",
      "  - \"keyboard\": 0.1576 -> 0.1575 (Difference: -0.0001)\n",
      "  - \"plane\": 0.3545 -> 0.3540 (Difference: -0.0004)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1919 -> 0.1919 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1608 -> 0.1608 (Difference: -0.0000)\n",
      "  - \"love\": 0.2495 -> 0.2495 (Difference: -0.0000)\n",
      "  - \"sex\": 0.0665 -> 0.0663 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.3436 -> 0.3434 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0891 -> 0.0891 (Difference: -0.0000)\n",
      "  - \"computer\": 0.2100 -> 0.2099 (Difference: -0.0001)\n",
      "  - \"keyboard\": 0.1381 -> 0.1380 (Difference: -0.0000)\n",
      "  - \"plane\": 0.2185 -> 0.2183 (Difference: -0.0001)\n",
      "  - \"car\": 0.1919 -> 0.1919 (Difference: 0.0000)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.3451 -> 0.3445 (Difference: -0.0006)\n",
      "  - \"love\": 0.3307 -> 0.3308 (Difference: 0.0001)\n",
      "  - \"sex\": 0.1756 -> 0.1755 (Difference: -0.0000)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.5487 -> 0.5485 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.2028 -> 0.2026 (Difference: -0.0002)\n",
      "  - \"computer\": 0.1209 -> 0.1207 (Difference: -0.0002)\n",
      "  - \"keyboard\": 0.1669 -> 0.1668 (Difference: -0.0001)\n",
      "  - \"plane\": 0.2824 -> 0.2824 (Difference: -0.0000)\n",
      "  - \"car\": 0.1608 -> 0.1608 (Difference: -0.0000)\n",
      "  - \"doctor\": 0.3451 -> 0.3445 (Difference: -0.0006)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.5446 -> 0.5447 (Difference: 0.0001)\n",
      "  - \"sex\": 0.4092 -> 0.4091 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.5941 -> 0.5941 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.1912 -> 0.1910 (Difference: -0.0002)\n",
      "  - \"computer\": 0.2347 -> 0.2348 (Difference: 0.0001)\n",
      "  - \"keyboard\": 0.2741 -> 0.2741 (Difference: 0.0000)\n",
      "  - \"plane\": 0.3285 -> 0.3285 (Difference: 0.0000)\n",
      "  - \"car\": 0.2495 -> 0.2495 (Difference: -0.0000)\n",
      "  - \"doctor\": 0.3307 -> 0.3308 (Difference: 0.0001)\n",
      "  - \"nurse\": 0.5446 -> 0.5447 (Difference: 0.0001)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"sex\": 0.3620 -> 0.3616 (Difference: -0.0003)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2601 -> 0.2599 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.1883 -> 0.1881 (Difference: -0.0002)\n",
      "  - \"computer\": 0.0771 -> 0.0769 (Difference: -0.0001)\n",
      "  - \"keyboard\": 0.1065 -> 0.1064 (Difference: -0.0001)\n",
      "  - \"plane\": 0.1187 -> 0.1186 (Difference: -0.0001)\n",
      "  - \"car\": 0.0665 -> 0.0663 (Difference: -0.0002)\n",
      "  - \"doctor\": 0.1756 -> 0.1755 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.4092 -> 0.4091 (Difference: -0.0001)\n",
      "  - \"love\": 0.3620 -> 0.3616 (Difference: -0.0003)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Checking the difference between the first retrofitted similarity matrix and the one with the updated (hyper)parameter values\n",
    "print_vec_difference(toy_wordList, toy_retrofitted_similarity_matrix, toy_new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Retrofitting the English gensim corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "\n",
    "def norm_word(word):\n",
    "  \"\"\"\n",
    "  - input: word\n",
    "  - return: a normalized version of it\n",
    "  Normalization process: includes checking if the word is a number or a punctuation mark and replacing it with special tokens\n",
    "  \"\"\"\n",
    "  if isNumber.search(word.lower()):\n",
    "    return '---num---'\n",
    "  # check if the word consists only of non-alphanumeric characters by removing all non-alphanumeric characters from the word \n",
    "  # and checking if the result is an empty string\n",
    "  elif re.sub(r'\\W+', '', word) == '':\n",
    "    return '---punc---'\n",
    "  else:\n",
    "  # if input word not a number nor a punctuation mark, return a lowercase version of input word\n",
    "    return word.lower()\n",
    "  \n",
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    first_line = True\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # Skip the first line\n",
    "      if first_line:\n",
    "        first_line =False\n",
    "        continue\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors\n",
    "\n",
    "''' Read the PPDB word relations as a dictionary '''\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.lower().strip().split()\n",
    "            lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
    "\n",
    "''' Write word vectors to file '''\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "  \"\"\"\n",
    "  - input: a dictionary wordVectors where keys are words and values are their corresponding word vectors\n",
    "           file name outFileName\n",
    "  \"\"\"\n",
    "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "  outFile = open(outFileName, 'w', encoding= 'utf-8')  \n",
    "  for word, values in wordVectors.items():\n",
    "    outFile.write(word+' ')\n",
    "    for val in wordVectors[word]:\n",
    "      # write the word vectors to the ouptut file in the format:\n",
    "      # word1 val1 val2 val3 ...\n",
    "      # word2 val1 val2 val3 ...\n",
    "      # ...\n",
    "      outFile.write('%.4f' %(val)+' ')\n",
    "    outFile.write('\\n')      \n",
    "  outFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n"
     ]
    }
   ],
   "source": [
    "# Retrieving the word vectors in a dictionary (key: word, value: embedding)\n",
    "EN_wordVecs = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "# Retrieving the pairs of words with human scores\n",
    "EN_lexical_similarity = read_lexicon(\"../data/English/lexicon/ws353_lexical_similarity.txt\")\n",
    "# Creating an output file to print back the updated embeddings\n",
    "EN_output_file = \"../data/English/output_vectors/output_vectors.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the necessary objects for the retrofitting\n",
    "EN_wordList = get_embeddings_words(EN_wordVecs)\n",
    "EN_neighbors_dict = get_wordnet_lexicon(EN_wordList, \"synonyms\") #[\"antonyms\", \"hyponyms\", \"hypernyms\", \"meronyms\", \"holonyms\", \"homonyms\"]\n",
    "EN_wordVecMat = convert_dict_to_matrix(EN_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the similarity between the word vectors of the corpus \n",
    "# (only considering the words in the lexicon similarity file)\n",
    "\n",
    "def print_lexical_similarities(wordVecs, lines, lang):\n",
    "    # Create a list to store the words\n",
    "    word_list = []\n",
    "\n",
    "    # Iterate over the lines and extract the words\n",
    "    for line in lines:\n",
    "        if lang == 'en':\n",
    "            words = line.strip().split('\\t')\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "        word1 = words[0]\n",
    "        word2 = words[1]\n",
    "        word_list.append((word1, word2))  # Store the words as a tuple\n",
    "\n",
    "    # Determine the subset of words present in the wordVecs file while preserving the order\n",
    "    subset = [word for word in word_list if word[0] in wordVecs and word[1] in wordVecs]\n",
    "\n",
    "    # Create a dictionary to map words to indices\n",
    "    w2i = {word: index for index, word in enumerate(wordVecs)}\n",
    "\n",
    "    # Create an empty list to store the similarities\n",
    "    similarities = []\n",
    "\n",
    "    # Iterate over each tuple in the subset\n",
    "    for word1, word2 in subset:\n",
    "        if word1 in wordVecs and word2 in wordVecs:\n",
    "            # Retrieve the embeddings for the words\n",
    "            embedding1 = wordVecs[word1]\n",
    "            embedding2 = wordVecs[word2]\n",
    "\n",
    "            # Calculate the similarity between the embeddings\n",
    "            similarity_score = cosine_similarity([embedding1], [embedding2])\n",
    "\n",
    "            # Append the similarity value to the list of similarities\n",
    "            similarities.append(similarity_score)\n",
    "\n",
    "    # Print the similarities\n",
    "    for i, similarity_score in enumerate(similarities):\n",
    "        print(f\"Similarity between '{subset[i][0]}' and '{subset[i][1]}': {similarity_score[0][0]}\")\n",
    "\n",
    "def print_similarity_difference(wordVecs1, wordVecs2, lines, lang):\n",
    "    # Create a list to store the words\n",
    "    word_list = []\n",
    "\n",
    "    # Iterate over the lines and extract the words\n",
    "    for line in lines:\n",
    "        if lang == 'en':\n",
    "            words = line.strip().split('\\t')\n",
    "        else:\n",
    "            words = line.strip().split()\n",
    "        word1 = words[0]\n",
    "        word2 = words[1]\n",
    "        word_list.append((word1, word2))  # Store the words as a tuple\n",
    "\n",
    "    # Determine the subset of words present in both wordVecs1 and wordVecs2 while preserving the order\n",
    "    subset = [word for word in word_list if word[0] in wordVecs1 and word[1] in wordVecs2]\n",
    "\n",
    "    # Create an empty list to store the similarity scores\n",
    "    similarities1 = []\n",
    "    similarities2 = []\n",
    "\n",
    "    # Iterate over each tuple in the subset\n",
    "    for word1, word2 in subset:\n",
    "        # Retrieve the embeddings for the words from wordVecs1\n",
    "        embedding1 = wordVecs1[word1]\n",
    "        embedding2 = wordVecs1[word2]\n",
    "\n",
    "        # Calculate the similarity between the embeddings in wordVecs1\n",
    "        similarity_score1 = cosine_similarity([embedding1], [embedding2])\n",
    "\n",
    "        # Retrieve the embeddings for the words from wordVecs2\n",
    "        embedding1 = wordVecs2[word1]\n",
    "        embedding2 = wordVecs2[word2]\n",
    "\n",
    "        # Calculate the similarity between the embeddings in wordVecs2\n",
    "        similarity_score2 = cosine_similarity([embedding1], [embedding2])\n",
    "\n",
    "        # Append the similarity scores to the respective lists\n",
    "        similarities1.append(similarity_score1[0][0])\n",
    "        similarities2.append(similarity_score2[0][0])\n",
    "\n",
    "    # Print the similarities and their difference\n",
    "    for i, (word1, word2) in enumerate(subset):\n",
    "        similarity1 = similarities1[i]\n",
    "        similarity2 = similarities2[i]\n",
    "        difference = similarity1 - similarity2\n",
    "        test=[]\n",
    "        if difference != 0.0:        \n",
    "            print(f\"Similarity between '{word1}' and '{word2}' before retrofitting: {similarity1}\")\n",
    "            print(f\"Similarity between '{word1}' and '{word2}' after retrofitting: {similarity2}\")\n",
    "            print(f\"Update: {difference}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'love' and 'sex': 0.3213976283166737\n",
      "Similarity between 'tiger' and 'cat': 0.4484269447717373\n",
      "Similarity between 'tiger' and 'tiger': 1.0\n",
      "Similarity between 'book' and 'paper': 0.5720403096134581\n",
      "Similarity between 'computer' and 'keyboard': 0.4902811841797181\n",
      "Similarity between 'computer' and 'internet': 0.49881600720718505\n",
      "Similarity between 'plane' and 'car': 0.4094837589536879\n",
      "Similarity between 'train' and 'car': 0.5024532628135742\n",
      "Similarity between 'telephone' and 'communication': 0.36768667290283835\n",
      "Similarity between 'television' and 'radio': 0.6536351915117727\n",
      "Similarity between 'media' and 'radio': 0.3209847572779895\n",
      "Similarity between 'drug' and 'abuse': 0.42865908078081993\n",
      "Similarity between 'bread' and 'butter': 0.8071053286387004\n",
      "Similarity between 'cucumber' and 'potato': 0.6915610413305441\n",
      "Similarity between 'doctor' and 'nurse': 0.5676552249319599\n",
      "Similarity between 'professor' and 'doctor': 0.5076438957646101\n",
      "Similarity between 'student' and 'professor': 0.45578493020098115\n",
      "Similarity between 'smart' and 'student': 0.2940012954759296\n",
      "Similarity between 'smart' and 'stupid': 0.39617691896753526\n",
      "Similarity between 'company' and 'stock': 0.46077310446425557\n",
      "Similarity between 'stock' and 'market': 0.5385185527611723\n",
      "Similarity between 'stock' and 'phone': 0.2537954804905717\n",
      "Similarity between 'stock' and 'jaguar': 0.24541597641521512\n",
      "Similarity between 'stock' and 'egg': 0.17158691336839396\n",
      "Similarity between 'fertility' and 'egg': 0.29469937801142465\n",
      "Similarity between 'stock' and 'live': 0.1875328178693288\n",
      "Similarity between 'stock' and 'life': 0.16227126965853364\n",
      "Similarity between 'book' and 'library': 0.38331650882604734\n",
      "Similarity between 'bank' and 'money': 0.3817619966211285\n",
      "Similarity between 'wood' and 'forest': 0.4513705729701868\n",
      "Similarity between 'money' and 'cash': 0.7500799480892854\n",
      "Similarity between 'professor' and 'cucumber': 0.09663273096654584\n",
      "Similarity between 'king' and 'cabbage': 0.1682218573112498\n",
      "Similarity between 'king' and 'queen': 0.6852263900680836\n",
      "Similarity between 'king' and 'rook': 0.29040233820098826\n",
      "Similarity between 'bishop' and 'rabbi': 0.44022479884512833\n",
      "Similarity between 'holy' and 'sex': 0.10285249855240487\n",
      "Similarity between 'fuck' and 'sex': 0.2583644208592573\n",
      "Similarity between 'football' and 'soccer': 0.732992880777482\n",
      "Similarity between 'football' and 'basketball': 0.7350006454613549\n",
      "Similarity between 'football' and 'tennis': 0.4979653308167488\n",
      "Similarity between 'tennis' and 'racket': 0.3102321036702446\n",
      "Similarity between 'law' and 'lawyer': 0.546109843782221\n",
      "Similarity between 'movie' and 'star': 0.38941927715237745\n",
      "Similarity between 'movie' and 'popcorn': 0.4541689909060221\n",
      "Similarity between 'movie' and 'critic': 0.33297393132298003\n",
      "Similarity between 'movie' and 'theater': 0.46441696370849056\n",
      "Similarity between 'physics' and 'proton': 0.3705833220077318\n",
      "Similarity between 'physics' and 'chemistry': 0.8327436735273508\n",
      "Similarity between 'space' and 'chemistry': 0.23392004698030291\n",
      "Similarity between 'alcohol' and 'chemistry': 0.2859536043744763\n",
      "Similarity between 'vodka' and 'gin': 0.5707338038897669\n",
      "Similarity between 'vodka' and 'brandy': 0.6550828058805547\n",
      "Similarity between 'drink' and 'car': 0.3548774555088685\n",
      "Similarity between 'drink' and 'ear': 0.21796934800647\n",
      "Similarity between 'drink' and 'mouth': 0.2979787069985778\n",
      "Similarity between 'drink' and 'eat': 0.6519650698252718\n",
      "Similarity between 'baby' and 'mother': 0.6094044955749424\n",
      "Similarity between 'drink' and 'mother': 0.2769888776806356\n",
      "Similarity between 'car' and 'automobile': 0.6533339368005837\n",
      "Similarity between 'gem' and 'jewel': 0.6713427529333966\n",
      "Similarity between 'journey' and 'voyage': 0.5104090589807883\n",
      "Similarity between 'boy' and 'lad': 0.5799155222244894\n",
      "Similarity between 'coast' and 'shore': 0.6010836392294177\n",
      "Similarity between 'asylum' and 'madhouse': 0.3119981062009018\n",
      "Similarity between 'magician' and 'wizard': 0.467031460051122\n",
      "Similarity between 'midday' and 'noon': 0.7981434151232776\n",
      "Similarity between 'furnace' and 'stove': 0.6711621765208311\n",
      "Similarity between 'food' and 'fruit': 0.5270629824510354\n",
      "Similarity between 'bird' and 'cock': 0.46689846889330416\n",
      "Similarity between 'bird' and 'crane': 0.49624411866584933\n",
      "Similarity between 'tool' and 'implement': 0.4377713516384724\n",
      "Similarity between 'brother' and 'monk': 0.3294016727339705\n",
      "Similarity between 'crane' and 'implement': 0.13885292653754006\n",
      "Similarity between 'lad' and 'brother': 0.28885342906104405\n",
      "Similarity between 'journey' and 'car': 0.24120297213219638\n",
      "Similarity between 'monk' and 'oracle': 0.2347094685478309\n",
      "Similarity between 'cemetery' and 'woodland': 0.395080038464906\n",
      "Similarity between 'food' and 'rooster': 0.24790878465146252\n",
      "Similarity between 'coast' and 'hill': 0.3147352473168207\n",
      "Similarity between 'forest' and 'graveyard': 0.24633859114233356\n",
      "Similarity between 'shore' and 'woodland': 0.38322100534530096\n",
      "Similarity between 'monk' and 'slave': 0.2541671122536606\n",
      "Similarity between 'coast' and 'forest': 0.3989787151730762\n",
      "Similarity between 'lad' and 'wizard': 0.22255492846786296\n",
      "Similarity between 'chord' and 'smile': 0.24309603147008846\n",
      "Similarity between 'glass' and 'magician': 0.273117680911635\n",
      "Similarity between 'noon' and 'string': 0.11740553954822505\n",
      "Similarity between 'rooster' and 'voyage': 0.08814789651141473\n",
      "Similarity between 'money' and 'dollar': 0.471340879007201\n",
      "Similarity between 'money' and 'cash': 0.7500799480892854\n",
      "Similarity between 'money' and 'currency': 0.457569525785614\n",
      "Similarity between 'money' and 'wealth': 0.49691614869804546\n",
      "Similarity between 'money' and 'property': 0.36332694292999324\n",
      "Similarity between 'money' and 'possession': 0.26704900150074873\n",
      "Similarity between 'money' and 'bank': 0.3817619966211285\n",
      "Similarity between 'money' and 'deposit': 0.3864688457388147\n",
      "Similarity between 'money' and 'withdrawal': 0.1838273498787751\n",
      "Similarity between 'money' and 'laundering': 0.4877732859775846\n",
      "Similarity between 'money' and 'operation': 0.12615036874456567\n",
      "Similarity between 'tiger' and 'jaguar': 0.5153315923593653\n",
      "Similarity between 'tiger' and 'feline': 0.39987473998456113\n",
      "Similarity between 'tiger' and 'carnivore': 0.3377899887983067\n",
      "Similarity between 'tiger' and 'mammal': 0.3139792918670319\n",
      "Similarity between 'tiger' and 'animal': 0.34446900444212614\n",
      "Similarity between 'tiger' and 'organism': 0.1727525390581988\n",
      "Similarity between 'tiger' and 'fauna': 0.22103905147723926\n",
      "Similarity between 'tiger' and 'zoo': 0.45376140773023\n",
      "Similarity between 'psychology' and 'psychiatry': 0.7696149098639089\n",
      "Similarity between 'psychology' and 'anxiety': 0.39844391637524584\n",
      "Similarity between 'psychology' and 'fear': 0.1964973180767654\n",
      "Similarity between 'psychology' and 'depression': 0.2608744652717436\n",
      "Similarity between 'psychology' and 'clinic': 0.43601861730354335\n",
      "Similarity between 'psychology' and 'doctor': 0.4309964190930099\n",
      "Similarity between 'psychology' and 'mind': 0.3569885743635376\n",
      "Similarity between 'psychology' and 'health': 0.4966090103404135\n",
      "Similarity between 'psychology' and 'science': 0.6665620157509726\n",
      "Similarity between 'psychology' and 'discipline': 0.3314297807693717\n",
      "Similarity between 'psychology' and 'cognition': 0.6759983910138431\n",
      "Similarity between 'planet' and 'star': 0.519761477538004\n",
      "Similarity between 'planet' and 'constellation': 0.4977904510675082\n",
      "Similarity between 'planet' and 'moon': 0.574677769918392\n",
      "Similarity between 'planet' and 'sun': 0.4611190640217323\n",
      "Similarity between 'planet' and 'galaxy': 0.5653450099902443\n",
      "Similarity between 'planet' and 'space': 0.4130999340303344\n",
      "Similarity between 'planet' and 'astronomer': 0.3480027755941616\n",
      "Similarity between 'precedent' and 'example': 0.3482787912209587\n",
      "Similarity between 'precedent' and 'information': 0.19287277733703073\n",
      "Similarity between 'precedent' and 'cognition': 0.0829476856720916\n",
      "Similarity between 'precedent' and 'law': 0.37162107814369055\n",
      "Similarity between 'precedent' and 'collection': 0.14303226231401617\n",
      "Similarity between 'precedent' and 'group': 0.09534828286901065\n",
      "Similarity between 'precedent' and 'antecedent': 0.2910666566807138\n",
      "Similarity between 'cup' and 'coffee': 0.20797550452839314\n",
      "Similarity between 'cup' and 'tableware': 0.16531159656431751\n",
      "Similarity between 'cup' and 'article': 0.10711890223332217\n",
      "Similarity between 'cup' and 'artifact': 0.1080216076937357\n",
      "Similarity between 'cup' and 'object': 0.07251832640887662\n",
      "Similarity between 'cup' and 'entity': 0.1394455736511904\n",
      "Similarity between 'cup' and 'drink': 0.20242876395843212\n",
      "Similarity between 'cup' and 'food': 0.0807667007012764\n",
      "Similarity between 'cup' and 'substance': 0.05640861645139696\n",
      "Similarity between 'cup' and 'liquid': 0.15859567621272105\n",
      "Similarity between 'jaguar' and 'cat': 0.32344008680522707\n",
      "Similarity between 'jaguar' and 'car': 0.47178156153854967\n",
      "Similarity between 'energy' and 'secretary': 0.14870377486678638\n",
      "Similarity between 'secretary' and 'senate': 0.5107258624859309\n",
      "Similarity between 'energy' and 'laboratory': 0.3690024035447106\n",
      "Similarity between 'computer' and 'laboratory': 0.4192700792767917\n",
      "Similarity between 'weapon' and 'secret': 0.3756434854529629\n",
      "Similarity between 'investigation' and 'effort': 0.31541103128757547\n",
      "Similarity between 'news' and 'report': 0.42827631995825033\n",
      "Similarity between 'canyon' and 'landscape': 0.31199456760585376\n",
      "Similarity between 'image' and 'surface': 0.2006105310106386\n",
      "Similarity between 'discovery' and 'space': 0.23063979442308355\n",
      "Similarity between 'water' and 'seepage': 0.5381568167791105\n",
      "Similarity between 'sign' and 'recess': 0.16953179194067447\n",
      "Similarity between 'mile' and 'kilometer': 0.7193962460158686\n",
      "Similarity between 'computer' and 'news': 0.2285664151144775\n",
      "Similarity between 'territory' and 'surface': 0.17314869458684998\n",
      "Similarity between 'atmosphere' and 'landscape': 0.3094822829874144\n",
      "Similarity between 'president' and 'medal': 0.3244123254801186\n",
      "Similarity between 'war' and 'troops': 0.42153916415040305\n",
      "Similarity between 'record' and 'number': 0.2982527996274973\n",
      "Similarity between 'skin' and 'eye': 0.5272105414526764\n",
      "Similarity between 'theater' and 'history': 0.24835518385837307\n",
      "Similarity between 'volunteer' and 'motto': 0.31070638950154694\n",
      "Similarity between 'prejudice' and 'recognition': 0.1569417528015616\n",
      "Similarity between 'decoration' and 'valor': 0.5058515653001794\n",
      "Similarity between 'century' and 'year': 0.3005721451838296\n",
      "Similarity between 'century' and 'nation': 0.21864306199795505\n",
      "Similarity between 'delay' and 'racism': 0.09040073832228933\n",
      "Similarity between 'delay' and 'news': 0.15109896237642725\n",
      "Similarity between 'minister' and 'party': 0.41903029933289204\n",
      "Similarity between 'peace' and 'plan': 0.27627026579666114\n",
      "Similarity between 'minority' and 'peace': 0.23639444584679556\n",
      "Similarity between 'attempt' and 'peace': 0.19563450568731033\n",
      "Similarity between 'government' and 'crisis': 0.40390346060649457\n",
      "Similarity between 'deployment' and 'departure': 0.35505174295597863\n",
      "Similarity between 'deployment' and 'withdrawal': 0.4294599502486629\n",
      "Similarity between 'energy' and 'crisis': 0.24562669856959823\n",
      "Similarity between 'announcement' and 'news': 0.4144241780349597\n",
      "Similarity between 'announcement' and 'effort': 0.29492976985580477\n",
      "Similarity between 'stroke' and 'hospital': 0.3218452148656307\n",
      "Similarity between 'disability' and 'death': 0.2270331948422127\n",
      "Similarity between 'victim' and 'emergency': 0.2543353428930358\n",
      "Similarity between 'treatment' and 'recovery': 0.4401718058418478\n",
      "Similarity between 'journal' and 'association': 0.36273327977460246\n",
      "Similarity between 'doctor' and 'personnel': 0.23438268637054316\n",
      "Similarity between 'doctor' and 'liability': 0.13848875298442692\n",
      "Similarity between 'liability' and 'insurance': 0.5834748552408184\n",
      "Similarity between 'school' and 'center': 0.3671201646462656\n",
      "Similarity between 'reason' and 'hypertension': 0.144423274776883\n",
      "Similarity between 'reason' and 'criterion': 0.42197100760154505\n",
      "Similarity between 'hundred' and 'percent': 0.3963913899953862\n",
      "Similarity between 'hospital' and 'infrastructure': 0.22509102964735866\n",
      "Similarity between 'death' and 'row': 0.24864641736479412\n",
      "Similarity between 'death' and 'inmate': 0.3408138610282122\n",
      "Similarity between 'lawyer' and 'evidence': 0.1865072638891968\n",
      "Similarity between 'life' and 'death': 0.3931775431368855\n",
      "Similarity between 'life' and 'term': 0.21162744982172005\n",
      "Similarity between 'word' and 'similarity': 0.30616878851257395\n",
      "Similarity between 'board' and 'recommendation': 0.37079919685341345\n",
      "Similarity between 'governor' and 'interview': 0.13601457824475652\n",
      "Similarity between 'peace' and 'atmosphere': 0.22281773646342043\n",
      "Similarity between 'peace' and 'insurance': 0.18095855845062\n",
      "Similarity between 'territory' and 'kilometer': 0.2984545710206714\n",
      "Similarity between 'travel' and 'activity': 0.25162807367655476\n",
      "Similarity between 'competition' and 'price': 0.2980840078723433\n",
      "Similarity between 'consumer' and 'confidence': 0.18944417036385178\n",
      "Similarity between 'consumer' and 'energy': 0.4368284673985543\n",
      "Similarity between 'problem' and 'airport': 0.10641880311909256\n",
      "Similarity between 'car' and 'flight': 0.3147276417699101\n",
      "Similarity between 'credit' and 'card': 0.467679804710897\n",
      "Similarity between 'credit' and 'information': 0.3236116230803933\n",
      "Similarity between 'hotel' and 'reservation': 0.3312412119391827\n",
      "Similarity between 'grocery' and 'money': 0.31541913433912633\n",
      "Similarity between 'registration' and 'arrangement': 0.22005397134358096\n",
      "Similarity between 'arrangement' and 'accommodation': 0.37577253442072794\n",
      "Similarity between 'month' and 'hotel': 0.1843158001493066\n",
      "Similarity between 'type' and 'kind': 0.5226445651278104\n",
      "Similarity between 'arrival' and 'hotel': 0.2379218396577449\n",
      "Similarity between 'bed' and 'closet': 0.514430679723206\n",
      "Similarity between 'closet' and 'clothes': 0.46717911310929067\n",
      "Similarity between 'situation' and 'conclusion': 0.36559048912987213\n",
      "Similarity between 'situation' and 'isolation': 0.32896806680719665\n",
      "Similarity between 'impartiality' and 'interest': 0.25425832004418547\n",
      "Similarity between 'direction' and 'combination': 0.2255150923554187\n",
      "Similarity between 'street' and 'place': 0.2814481774100284\n",
      "Similarity between 'street' and 'avenue': 0.7944696888211877\n",
      "Similarity between 'street' and 'block': 0.3272265135369973\n",
      "Similarity between 'street' and 'children': 0.21689014006223406\n",
      "Similarity between 'listing' and 'proximity': 0.12003172246279278\n",
      "Similarity between 'listing' and 'category': 0.4023952990054468\n",
      "Similarity between 'cell' and 'phone': 0.42862021128596994\n",
      "Similarity between 'production' and 'hike': 0.0938559905103312\n",
      "Similarity between 'benchmark' and 'index': 0.575850437852915\n",
      "Similarity between 'media' and 'trading': 0.17525306262110277\n",
      "Similarity between 'media' and 'gain': 0.26197772989341506\n",
      "Similarity between 'dividend' and 'payment': 0.5364874542444955\n",
      "Similarity between 'dividend' and 'calculation': 0.3507031694077017\n",
      "Similarity between 'calculation' and 'computation': 0.687704014429982\n",
      "Similarity between 'currency' and 'market': 0.45398172042498663\n",
      "Similarity between 'oil' and 'stock': 0.32418891516998\n",
      "Similarity between 'announcement' and 'production': 0.24923300212796567\n",
      "Similarity between 'announcement' and 'warning': 0.2613362807351249\n",
      "Similarity between 'profit' and 'warning': 0.05171257099383002\n",
      "Similarity between 'profit' and 'loss': 0.19591486661921312\n",
      "Similarity between 'dollar' and 'yen': 0.4977735716983742\n",
      "Similarity between 'dollar' and 'buck': 0.3611598893952871\n",
      "Similarity between 'dollar' and 'profit': 0.33508607815462904\n",
      "Similarity between 'dollar' and 'loss': 0.12362969070393039\n",
      "Similarity between 'computer' and 'software': 0.6468620907416638\n",
      "Similarity between 'network' and 'hardware': 0.3177904514376401\n",
      "Similarity between 'phone' and 'equipment': 0.30961041225437763\n",
      "Similarity between 'equipment' and 'maker': 0.24174991446424224\n",
      "Similarity between 'luxury' and 'car': 0.4174046574650426\n",
      "Similarity between 'five' and 'month': 0.43915704514951853\n",
      "Similarity between 'report' and 'gain': 0.05346097750505492\n",
      "Similarity between 'investor' and 'earning': 0.17898559190018085\n",
      "Similarity between 'liquid' and 'water': 0.5512252578990561\n",
      "Similarity between 'baseball' and 'season': 0.40714763631610656\n",
      "Similarity between 'game' and 'victory': 0.32052317597447866\n",
      "Similarity between 'game' and 'team': 0.3602181279448463\n",
      "Similarity between 'marathon' and 'sprint': 0.5465444238280975\n",
      "Similarity between 'game' and 'series': 0.42139494523759286\n",
      "Similarity between 'game' and 'defeat': 0.35115345990732666\n",
      "Similarity between 'seven' and 'series': 0.41648462403604086\n",
      "Similarity between 'seafood' and 'sea': 0.3306571798167045\n",
      "Similarity between 'seafood' and 'food': 0.6978338489756991\n",
      "Similarity between 'seafood' and 'lobster': 0.7010583437527236\n",
      "Similarity between 'lobster' and 'food': 0.4759274122251642\n",
      "Similarity between 'lobster' and 'wine': 0.41791529878156675\n",
      "Similarity between 'food' and 'preparation': 0.4106230287433116\n",
      "Similarity between 'video' and 'archive': 0.1356101712212238\n",
      "Similarity between 'start' and 'year': 0.3445289658727612\n",
      "Similarity between 'start' and 'match': 0.31434689209982597\n",
      "Similarity between 'game' and 'round': 0.28621710641695486\n",
      "Similarity between 'boxing' and 'round': 0.19154012630495382\n",
      "Similarity between 'championship' and 'tournament': 0.7444553855765738\n",
      "Similarity between 'fighting' and 'defeating': 0.29337143790539577\n",
      "Similarity between 'line' and 'insurance': 0.14398239143371\n",
      "Similarity between 'day' and 'summer': 0.37266241017908114\n",
      "Similarity between 'summer' and 'drought': 0.2621906266869796\n",
      "Similarity between 'summer' and 'nature': 0.1853843496297093\n",
      "Similarity between 'day' and 'dawn': 0.37852736143093796\n",
      "Similarity between 'nature' and 'environment': 0.5263190161943299\n",
      "Similarity between 'environment' and 'ecology': 0.5759535900602069\n",
      "Similarity between 'nature' and 'man': 0.28627321889494334\n",
      "Similarity between 'man' and 'woman': 0.6658470105380624\n",
      "Similarity between 'man' and 'governor': 0.22529994330088682\n",
      "Similarity between 'murder' and 'manslaughter': 0.7050093014917536\n",
      "Similarity between 'soap' and 'opera': 0.5597841918886536\n",
      "Similarity between 'opera' and 'performance': 0.34825366227979776\n",
      "Similarity between 'life' and 'lesson': 0.2927790955891807\n",
      "Similarity between 'focus' and 'life': 0.37360468819818893\n",
      "Similarity between 'production' and 'crew': 0.24360373090856294\n",
      "Similarity between 'television' and 'film': 0.568723193092448\n",
      "Similarity between 'lover' and 'quarrel': 0.44007927187742446\n",
      "Similarity between 'viewer' and 'serial': 0.20212685614156517\n",
      "Similarity between 'possibility' and 'girl': 0.15245454509034184\n",
      "Similarity between 'population' and 'development': 0.22605376529930335\n",
      "Similarity between 'morality' and 'importance': 0.31423138018774754\n",
      "Similarity between 'morality' and 'marriage': 0.38633256898497703\n",
      "Similarity between 'gender' and 'equality': 0.5862350883267482\n",
      "Similarity between 'change' and 'attitude': 0.311045702462625\n",
      "Similarity between 'family' and 'planning': 0.150242238240384\n",
      "Similarity between 'opera' and 'industry': 0.1999320091974873\n",
      "Similarity between 'sugar' and 'approach': 0.09573850955033071\n",
      "Similarity between 'practice' and 'institution': 0.34664063586638316\n",
      "Similarity between 'ministry' and 'culture': 0.35637908192730194\n",
      "Similarity between 'problem' and 'challenge': 0.3147201635668211\n",
      "Similarity between 'size' and 'prominence': 0.19908037983633792\n",
      "Similarity between 'country' and 'citizen': 0.3858730649025389\n",
      "Similarity between 'planet' and 'people': 0.16107155519293073\n",
      "Similarity between 'development' and 'issue': 0.1699497042447709\n",
      "Similarity between 'experience' and 'music': 0.27052414819144976\n",
      "Similarity between 'music' and 'project': 0.3108060141539901\n",
      "Similarity between 'glass' and 'metal': 0.47637366241410384\n",
      "Similarity between 'aluminum' and 'metal': 0.5818277272279189\n",
      "Similarity between 'chance' and 'credibility': 0.3169952828269589\n",
      "Similarity between 'exhibit' and 'memorabilia': 0.38623598677526755\n",
      "Similarity between 'concert' and 'virtuoso': 0.48561499552017373\n",
      "Similarity between 'rock' and 'jazz': 0.5421643742927887\n",
      "Similarity between 'museum' and 'theater': 0.4679903266892968\n",
      "Similarity between 'observation' and 'architecture': 0.24924606890034434\n",
      "Similarity between 'space' and 'world': 0.16201209623194165\n",
      "Similarity between 'preservation' and 'world': 0.1278478491868286\n",
      "Similarity between 'admission' and 'ticket': 0.41643268596243277\n",
      "Similarity between 'shower' and 'thunderstorm': 0.48556203317784374\n",
      "Similarity between 'shower' and 'flood': 0.24936297450262368\n",
      "Similarity between 'weather' and 'forecast': 0.642593401789184\n",
      "Similarity between 'disaster' and 'area': 0.25571124304709214\n",
      "Similarity between 'governor' and 'office': 0.42209747699357636\n",
      "Similarity between 'architecture' and 'century': 0.30194647996254603\n"
     ]
    }
   ],
   "source": [
    "# Retrive word pairs from the lexical similarity file\n",
    "with open('../data/English/lexicon/ws353_lexical_similarity.txt', 'r') as file:\n",
    "    EN_lines = file.readlines()\n",
    "# Get their similarities\n",
    "print_lexical_similarities(EN_wordVecs, EN_lines, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the matrix of neighbor's embeddings has been updated to retrieve the embeddings from the matrix of embeddings to update rather than from word2vec\n",
    "def retrieve_neighbors_embedding_matrix(wordVecMat, wordList, neighbors_dict):\n",
    "    valid_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors) & set(wordList)\n",
    "\n",
    "    embedding_size = wordVecMat.shape[1]\n",
    "    average_embeddings = []\n",
    "\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        if neighbors and any(neighbor in valid_neighbors for neighbor in neighbors):\n",
    "            embeddings = np.array([\n",
    "                wordVecMat[wordList.index(neighbor)] if neighbor in wordList else np.zeros(embedding_size)\n",
    "                for neighbor in neighbors\n",
    "                if neighbor in valid_neighbors\n",
    "            ])\n",
    "            if embeddings.size > 0:\n",
    "                average_embedding = np.mean(embeddings, axis=0)\n",
    "                average_embeddings.append(average_embedding)\n",
    "        else:\n",
    "            average_embeddings.append(np.zeros(embedding_size))\n",
    "\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "    return neighbors_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the matrix of neighbor's embeddings\n",
    "EN_neighbors_matrix= retrieve_neighbors_embedding_matrix(EN_wordVecMat, EN_wordList, EN_neighbors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07520224 0.07037208 0.0224631  ... 0.03620975 0.02141031 0.15191107]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the matrix of neighbor's embedding on a subset\n",
    "EN_subset_wordVecs = {word: EN_wordVecs[word] for word in EN_wordList[:100]}\n",
    "EN_subset_neighbors_dict = {word: EN_neighbors_dict[word] for word in list(EN_neighbors_dict.keys())[:100]}\n",
    "EN_subset_wordVecMat = EN_wordVecMat[:100] \n",
    "EN_subset_wordList = EN_wordList[:100]\n",
    "\n",
    "# Test the function on the subset\n",
    "EN_subset_neighbors_matrix = retrieve_neighbors_embedding_matrix(EN_subset_wordVecMat, EN_subset_wordList, EN_subset_neighbors_dict)\n",
    "\n",
    "# Print the result\n",
    "print(EN_subset_neighbors_matrix)\n",
    "print(type(EN_subset_neighbors_matrix))  \n",
    "print(EN_subset_neighbors_matrix.shape)  \n",
    "print(EN_subset_neighbors_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of word embeddings\n",
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n",
      "\n",
      "Matrix of neighbors' embeddings\n",
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Checking that the matrices we pass as argument of the retrofitting algorithm have the same shape and dimension\n",
    "print(\"Matrix of word embeddings\")\n",
    "print(type(EN_neighbors_matrix))  \n",
    "print(EN_neighbors_matrix.shape)  \n",
    "print(EN_neighbors_matrix.ndim) \n",
    "print(\"\\nMatrix of neighbors' embeddings\")\n",
    "print(type(EN_wordVecMat))  \n",
    "print(EN_wordVecMat.shape)  \n",
    "print(EN_wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrofitting the English word embeddings\n",
    "EN_retrofitted_vecs = retrofitting_wordVecs(EN_wordVecMat, EN_neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'love' and 'sex' before retrofitting: 0.3213976283166737\n",
      "Similarity between 'love' and 'sex' after retrofitting: 0.47673179076915473\n",
      "Update: -0.15533416245248105\n",
      "\n",
      "Similarity between 'tiger' and 'cat' before retrofitting: 0.4484269447717373\n",
      "Similarity between 'tiger' and 'cat' after retrofitting: 0.37263892654144615\n",
      "Update: 0.07578801823029113\n",
      "\n",
      "Similarity between 'book' and 'paper' before retrofitting: 0.5720403096134581\n",
      "Similarity between 'book' and 'paper' after retrofitting: 0.6017146691372111\n",
      "Update: -0.02967435952375297\n",
      "\n",
      "Similarity between 'computer' and 'keyboard' before retrofitting: 0.4902811841797181\n",
      "Similarity between 'computer' and 'keyboard' after retrofitting: 0.34049956739588355\n",
      "Update: 0.14978161678383456\n",
      "\n",
      "Similarity between 'computer' and 'internet' before retrofitting: 0.49881600720718505\n",
      "Similarity between 'computer' and 'internet' after retrofitting: 0.27021129120136117\n",
      "Update: 0.22860471600582388\n",
      "\n",
      "Similarity between 'plane' and 'car' before retrofitting: 0.4094837589536879\n",
      "Similarity between 'plane' and 'car' after retrofitting: 0.5931817346935466\n",
      "Update: -0.18369797573985874\n",
      "\n",
      "Similarity between 'train' and 'car' before retrofitting: 0.5024532628135742\n",
      "Similarity between 'train' and 'car' after retrofitting: 0.49903921916515626\n",
      "Update: 0.003414043648417908\n",
      "\n",
      "Similarity between 'telephone' and 'communication' before retrofitting: 0.36768667290283835\n",
      "Similarity between 'telephone' and 'communication' after retrofitting: 0.34492853307700583\n",
      "Update: 0.022758139825832524\n",
      "\n",
      "Similarity between 'television' and 'radio' before retrofitting: 0.6536351915117727\n",
      "Similarity between 'television' and 'radio' after retrofitting: 0.44772063631111764\n",
      "Update: 0.2059145552006551\n",
      "\n",
      "Similarity between 'media' and 'radio' before retrofitting: 0.3209847572779895\n",
      "Similarity between 'media' and 'radio' after retrofitting: 0.2737096389950668\n",
      "Update: 0.04727511828292269\n",
      "\n",
      "Similarity between 'drug' and 'abuse' before retrofitting: 0.42865908078081993\n",
      "Similarity between 'drug' and 'abuse' after retrofitting: 0.29386442268243734\n",
      "Update: 0.1347946580983826\n",
      "\n",
      "Similarity between 'bread' and 'butter' before retrofitting: 0.8071053286387004\n",
      "Similarity between 'bread' and 'butter' after retrofitting: 0.7396441094699389\n",
      "Update: 0.06746121916876158\n",
      "\n",
      "Similarity between 'cucumber' and 'potato' before retrofitting: 0.6915610413305441\n",
      "Similarity between 'cucumber' and 'potato' after retrofitting: 0.3649099139751552\n",
      "Update: 0.32665112735538887\n",
      "\n",
      "Similarity between 'doctor' and 'nurse' before retrofitting: 0.5676552249319599\n",
      "Similarity between 'doctor' and 'nurse' after retrofitting: 0.5541206972939656\n",
      "Update: 0.013534527637994231\n",
      "\n",
      "Similarity between 'professor' and 'doctor' before retrofitting: 0.5076438957646101\n",
      "Similarity between 'professor' and 'doctor' after retrofitting: 0.3243882426689553\n",
      "Update: 0.18325565309565484\n",
      "\n",
      "Similarity between 'student' and 'professor' before retrofitting: 0.45578493020098115\n",
      "Similarity between 'student' and 'professor' after retrofitting: 0.5089591495266298\n",
      "Update: -0.05317421932564864\n",
      "\n",
      "Similarity between 'smart' and 'student' before retrofitting: 0.2940012954759296\n",
      "Similarity between 'smart' and 'student' after retrofitting: 0.3859304201558171\n",
      "Update: -0.09192912467988745\n",
      "\n",
      "Similarity between 'smart' and 'stupid' before retrofitting: 0.39617691896753526\n",
      "Similarity between 'smart' and 'stupid' after retrofitting: 0.6405435463507957\n",
      "Update: -0.24436662738326043\n",
      "\n",
      "Similarity between 'company' and 'stock' before retrofitting: 0.46077310446425557\n",
      "Similarity between 'company' and 'stock' after retrofitting: 0.584120646866672\n",
      "Update: -0.12334754240241641\n",
      "\n",
      "Similarity between 'stock' and 'market' before retrofitting: 0.5385185527611723\n",
      "Similarity between 'stock' and 'market' after retrofitting: 0.4477442757064972\n",
      "Update: 0.09077427705467511\n",
      "\n",
      "Similarity between 'stock' and 'phone' before retrofitting: 0.2537954804905717\n",
      "Similarity between 'stock' and 'phone' after retrofitting: 0.42294863867215726\n",
      "Update: -0.16915315818158555\n",
      "\n",
      "Similarity between 'stock' and 'jaguar' before retrofitting: 0.24541597641521512\n",
      "Similarity between 'stock' and 'jaguar' after retrofitting: 0.25282904866993056\n",
      "Update: -0.007413072254715436\n",
      "\n",
      "Similarity between 'stock' and 'egg' before retrofitting: 0.17158691336839396\n",
      "Similarity between 'stock' and 'egg' after retrofitting: 0.6009145406929466\n",
      "Update: -0.42932762732455265\n",
      "\n",
      "Similarity between 'fertility' and 'egg' before retrofitting: 0.29469937801142465\n",
      "Similarity between 'fertility' and 'egg' after retrofitting: 0.44432881163546806\n",
      "Update: -0.1496294336240434\n",
      "\n",
      "Similarity between 'stock' and 'live' before retrofitting: 0.1875328178693288\n",
      "Similarity between 'stock' and 'live' after retrofitting: 0.7090321778033475\n",
      "Update: -0.5214993599340187\n",
      "\n",
      "Similarity between 'stock' and 'life' before retrofitting: 0.16227126965853364\n",
      "Similarity between 'stock' and 'life' after retrofitting: 0.634351546074186\n",
      "Update: -0.4720802764156523\n",
      "\n",
      "Similarity between 'book' and 'library' before retrofitting: 0.38331650882604734\n",
      "Similarity between 'book' and 'library' after retrofitting: 0.38378587309064005\n",
      "Update: -0.00046936426459270875\n",
      "\n",
      "Similarity between 'bank' and 'money' before retrofitting: 0.3817619966211285\n",
      "Similarity between 'bank' and 'money' after retrofitting: 0.4241351293144971\n",
      "Update: -0.04237313269336862\n",
      "\n",
      "Similarity between 'wood' and 'forest' before retrofitting: 0.4513705729701868\n",
      "Similarity between 'wood' and 'forest' after retrofitting: 0.774333560239174\n",
      "Update: -0.3229629872689872\n",
      "\n",
      "Similarity between 'professor' and 'cucumber' before retrofitting: 0.09663273096654584\n",
      "Similarity between 'professor' and 'cucumber' after retrofitting: 0.10706882638050585\n",
      "Update: -0.010436095413960012\n",
      "\n",
      "Similarity between 'king' and 'cabbage' before retrofitting: 0.1682218573112498\n",
      "Similarity between 'king' and 'cabbage' after retrofitting: 0.47342469005826604\n",
      "Update: -0.3052028327470162\n",
      "\n",
      "Similarity between 'king' and 'queen' before retrofitting: 0.6852263900680836\n",
      "Similarity between 'king' and 'queen' after retrofitting: 0.49184125466146467\n",
      "Update: 0.19338513540661895\n",
      "\n",
      "Similarity between 'king' and 'rook' before retrofitting: 0.29040233820098826\n",
      "Similarity between 'king' and 'rook' after retrofitting: 0.5351775064176779\n",
      "Update: -0.24477516821668965\n",
      "\n",
      "Similarity between 'holy' and 'sex' before retrofitting: 0.10285249855240487\n",
      "Similarity between 'holy' and 'sex' after retrofitting: 0.16906877474090898\n",
      "Update: -0.0662162761885041\n",
      "\n",
      "Similarity between 'fuck' and 'sex' before retrofitting: 0.2583644208592573\n",
      "Similarity between 'fuck' and 'sex' after retrofitting: 0.35740679055574703\n",
      "Update: -0.09904236969648972\n",
      "\n",
      "Similarity between 'football' and 'basketball' before retrofitting: 0.7350006454613549\n",
      "Similarity between 'football' and 'basketball' after retrofitting: 0.29847944911630636\n",
      "Update: 0.43652119634504855\n",
      "\n",
      "Similarity between 'tennis' and 'racket' before retrofitting: 0.3102321036702446\n",
      "Similarity between 'tennis' and 'racket' after retrofitting: 0.3028579925183662\n",
      "Update: 0.007374111151878415\n",
      "\n",
      "Similarity between 'law' and 'lawyer' before retrofitting: 0.546109843782221\n",
      "Similarity between 'law' and 'lawyer' after retrofitting: 0.515752470852215\n",
      "Update: 0.030357372930006066\n",
      "\n",
      "Similarity between 'movie' and 'star' before retrofitting: 0.38941927715237745\n",
      "Similarity between 'movie' and 'star' after retrofitting: 0.5559701312196881\n",
      "Update: -0.16655085406731063\n",
      "\n",
      "Similarity between 'movie' and 'popcorn' before retrofitting: 0.4541689909060221\n",
      "Similarity between 'movie' and 'popcorn' after retrofitting: 0.43471051766591556\n",
      "Update: 0.019458473240106522\n",
      "\n",
      "Similarity between 'movie' and 'critic' before retrofitting: 0.33297393132298003\n",
      "Similarity between 'movie' and 'critic' after retrofitting: 0.3774476016942395\n",
      "Update: -0.04447367037125949\n",
      "\n",
      "Similarity between 'movie' and 'theater' before retrofitting: 0.46441696370849056\n",
      "Similarity between 'movie' and 'theater' after retrofitting: 0.4540702924567128\n",
      "Update: 0.01034667125177774\n",
      "\n",
      "Similarity between 'physics' and 'proton' before retrofitting: 0.3705833220077318\n",
      "Similarity between 'physics' and 'proton' after retrofitting: 0.22330474068167414\n",
      "Update: 0.14727858132605767\n",
      "\n",
      "Similarity between 'physics' and 'chemistry' before retrofitting: 0.8327436735273508\n",
      "Similarity between 'physics' and 'chemistry' after retrofitting: 0.5342429462383825\n",
      "Update: 0.29850072728896826\n",
      "\n",
      "Similarity between 'space' and 'chemistry' before retrofitting: 0.23392004698030291\n",
      "Similarity between 'space' and 'chemistry' after retrofitting: 0.2521568468403932\n",
      "Update: -0.018236799860090275\n",
      "\n",
      "Similarity between 'alcohol' and 'chemistry' before retrofitting: 0.2859536043744763\n",
      "Similarity between 'alcohol' and 'chemistry' after retrofitting: 0.253489534374766\n",
      "Update: 0.0324640699997103\n",
      "\n",
      "Similarity between 'vodka' and 'gin' before retrofitting: 0.5707338038897669\n",
      "Similarity between 'vodka' and 'gin' after retrofitting: 0.1391713170544293\n",
      "Update: 0.4315624868353376\n",
      "\n",
      "Similarity between 'drink' and 'car' before retrofitting: 0.3548774555088685\n",
      "Similarity between 'drink' and 'car' after retrofitting: 0.383084599870104\n",
      "Update: -0.028207144361235503\n",
      "\n",
      "Similarity between 'drink' and 'ear' before retrofitting: 0.21796934800647\n",
      "Similarity between 'drink' and 'ear' after retrofitting: 0.2312023251910153\n",
      "Update: -0.013232977184545303\n",
      "\n",
      "Similarity between 'drink' and 'mouth' before retrofitting: 0.2979787069985778\n",
      "Similarity between 'drink' and 'mouth' after retrofitting: 0.5310385209963709\n",
      "Update: -0.23305981399779313\n",
      "\n",
      "Similarity between 'drink' and 'eat' before retrofitting: 0.6519650698252718\n",
      "Similarity between 'drink' and 'eat' after retrofitting: 0.5273312933807202\n",
      "Update: 0.12463377644455165\n",
      "\n",
      "Similarity between 'baby' and 'mother' before retrofitting: 0.6094044955749424\n",
      "Similarity between 'baby' and 'mother' after retrofitting: 0.6350704901362537\n",
      "Update: -0.025665994561311356\n",
      "\n",
      "Similarity between 'drink' and 'mother' before retrofitting: 0.2769888776806356\n",
      "Similarity between 'drink' and 'mother' after retrofitting: 0.5320677461974065\n",
      "Update: -0.25507886851677086\n",
      "\n",
      "Similarity between 'car' and 'automobile' before retrofitting: 0.6533339368005837\n",
      "Similarity between 'car' and 'automobile' after retrofitting: 0.9223466812408789\n",
      "Update: -0.2690127444402952\n",
      "\n",
      "Similarity between 'gem' and 'jewel' before retrofitting: 0.6713427529333966\n",
      "Similarity between 'gem' and 'jewel' after retrofitting: 0.7530941974581123\n",
      "Update: -0.08175144452471572\n",
      "\n",
      "Similarity between 'journey' and 'voyage' before retrofitting: 0.5104090589807883\n",
      "Similarity between 'journey' and 'voyage' after retrofitting: 0.5406146809073077\n",
      "Update: -0.030205621926519433\n",
      "\n",
      "Similarity between 'boy' and 'lad' before retrofitting: 0.5799155222244894\n",
      "Similarity between 'boy' and 'lad' after retrofitting: 0.45179948483892923\n",
      "Update: 0.12811603738556016\n",
      "\n",
      "Similarity between 'coast' and 'shore' before retrofitting: 0.6010836392294177\n",
      "Similarity between 'coast' and 'shore' after retrofitting: 0.4434778074905991\n",
      "Update: 0.15760583173881854\n",
      "\n",
      "Similarity between 'asylum' and 'madhouse' before retrofitting: 0.3119981062009018\n",
      "Similarity between 'asylum' and 'madhouse' after retrofitting: 0.4863104161972909\n",
      "Update: -0.17431230999638908\n",
      "\n",
      "Similarity between 'magician' and 'wizard' before retrofitting: 0.467031460051122\n",
      "Similarity between 'magician' and 'wizard' after retrofitting: 0.7791410859973409\n",
      "Update: -0.3121096259462189\n",
      "\n",
      "Similarity between 'midday' and 'noon' before retrofitting: 0.7981434151232776\n",
      "Similarity between 'midday' and 'noon' after retrofitting: 0.9290242846971936\n",
      "Update: -0.13088086957391598\n",
      "\n",
      "Similarity between 'furnace' and 'stove' before retrofitting: 0.6711621765208311\n",
      "Similarity between 'furnace' and 'stove' after retrofitting: 0.32867292706629875\n",
      "Update: 0.34248924945453235\n",
      "\n",
      "Similarity between 'food' and 'fruit' before retrofitting: 0.5270629824510354\n",
      "Similarity between 'food' and 'fruit' after retrofitting: 0.4370800168536068\n",
      "Update: 0.08998296559742863\n",
      "\n",
      "Similarity between 'bird' and 'cock' before retrofitting: 0.46689846889330416\n",
      "Similarity between 'bird' and 'cock' after retrofitting: 0.7373243879243734\n",
      "Update: -0.2704259190310692\n",
      "\n",
      "Similarity between 'bird' and 'crane' before retrofitting: 0.49624411866584933\n",
      "Similarity between 'bird' and 'crane' after retrofitting: 0.5100420834562829\n",
      "Update: -0.013797964790433548\n",
      "\n",
      "Similarity between 'tool' and 'implement' before retrofitting: 0.4377713516384724\n",
      "Similarity between 'tool' and 'implement' after retrofitting: 0.20945973206204296\n",
      "Update: 0.22831161957642945\n",
      "\n",
      "Similarity between 'brother' and 'monk' before retrofitting: 0.3294016727339705\n",
      "Similarity between 'brother' and 'monk' after retrofitting: 0.16672233657100294\n",
      "Update: 0.16267933616296754\n",
      "\n",
      "Similarity between 'crane' and 'implement' before retrofitting: 0.13885292653754006\n",
      "Similarity between 'crane' and 'implement' after retrofitting: 0.06883350504252446\n",
      "Update: 0.0700194214950156\n",
      "\n",
      "Similarity between 'lad' and 'brother' before retrofitting: 0.28885342906104405\n",
      "Similarity between 'lad' and 'brother' after retrofitting: 0.6972047985225966\n",
      "Update: -0.4083513694615526\n",
      "\n",
      "Similarity between 'journey' and 'car' before retrofitting: 0.24120297213219638\n",
      "Similarity between 'journey' and 'car' after retrofitting: 0.36001539392470117\n",
      "Update: -0.11881242179250479\n",
      "\n",
      "Similarity between 'monk' and 'oracle' before retrofitting: 0.2347094685478309\n",
      "Similarity between 'monk' and 'oracle' after retrofitting: 0.32196415366854764\n",
      "Update: -0.08725468512071674\n",
      "\n",
      "Similarity between 'cemetery' and 'woodland' before retrofitting: 0.395080038464906\n",
      "Similarity between 'cemetery' and 'woodland' after retrofitting: 0.3124715600768404\n",
      "Update: 0.08260847838806562\n",
      "\n",
      "Similarity between 'food' and 'rooster' before retrofitting: 0.24790878465146252\n",
      "Similarity between 'food' and 'rooster' after retrofitting: 0.08749111981036554\n",
      "Update: 0.16041766484109699\n",
      "\n",
      "Similarity between 'coast' and 'hill' before retrofitting: 0.3147352473168207\n",
      "Similarity between 'coast' and 'hill' after retrofitting: 0.4089151430072367\n",
      "Update: -0.09417989569041602\n",
      "\n",
      "Similarity between 'forest' and 'graveyard' before retrofitting: 0.24633859114233356\n",
      "Similarity between 'forest' and 'graveyard' after retrofitting: 0.4112395539283558\n",
      "Update: -0.16490096278602226\n",
      "\n",
      "Similarity between 'shore' and 'woodland' before retrofitting: 0.38322100534530096\n",
      "Similarity between 'shore' and 'woodland' after retrofitting: 0.5005419939173099\n",
      "Update: -0.11732098857200896\n",
      "\n",
      "Similarity between 'monk' and 'slave' before retrofitting: 0.2541671122536606\n",
      "Similarity between 'monk' and 'slave' after retrofitting: 0.11034781283394685\n",
      "Update: 0.14381929941971378\n",
      "\n",
      "Similarity between 'coast' and 'forest' before retrofitting: 0.3989787151730762\n",
      "Similarity between 'coast' and 'forest' after retrofitting: 0.504798813958996\n",
      "Update: -0.10582009878591975\n",
      "\n",
      "Similarity between 'lad' and 'wizard' before retrofitting: 0.22255492846786296\n",
      "Similarity between 'lad' and 'wizard' after retrofitting: 0.6469331567861198\n",
      "Update: -0.4243782283182569\n",
      "\n",
      "Similarity between 'chord' and 'smile' before retrofitting: 0.24309603147008846\n",
      "Similarity between 'chord' and 'smile' after retrofitting: 0.08304922280709447\n",
      "Update: 0.16004680866299398\n",
      "\n",
      "Similarity between 'glass' and 'magician' before retrofitting: 0.273117680911635\n",
      "Similarity between 'glass' and 'magician' after retrofitting: 0.43715288315054407\n",
      "Update: -0.16403520223890905\n",
      "\n",
      "Similarity between 'noon' and 'string' before retrofitting: 0.11740553954822505\n",
      "Similarity between 'noon' and 'string' after retrofitting: 0.30899183918619105\n",
      "Update: -0.191586299637966\n",
      "\n",
      "Similarity between 'rooster' and 'voyage' before retrofitting: 0.08814789651141473\n",
      "Similarity between 'rooster' and 'voyage' after retrofitting: 0.13804316416192997\n",
      "Update: -0.04989526765051523\n",
      "\n",
      "Similarity between 'money' and 'dollar' before retrofitting: 0.471340879007201\n",
      "Similarity between 'money' and 'dollar' after retrofitting: 0.22282877107193866\n",
      "Update: 0.24851210793526235\n",
      "\n",
      "Similarity between 'money' and 'wealth' before retrofitting: 0.49691614869804546\n",
      "Similarity between 'money' and 'wealth' after retrofitting: 0.3782684653376151\n",
      "Update: 0.11864768336043036\n",
      "\n",
      "Similarity between 'money' and 'property' before retrofitting: 0.36332694292999324\n",
      "Similarity between 'money' and 'property' after retrofitting: 0.3357940452341845\n",
      "Update: 0.027532897695808745\n",
      "\n",
      "Similarity between 'money' and 'possession' before retrofitting: 0.26704900150074873\n",
      "Similarity between 'money' and 'possession' after retrofitting: 0.3561124283301802\n",
      "Update: -0.08906342682943147\n",
      "\n",
      "Similarity between 'money' and 'bank' before retrofitting: 0.3817619966211285\n",
      "Similarity between 'money' and 'bank' after retrofitting: 0.4241351293144971\n",
      "Update: -0.04237313269336862\n",
      "\n",
      "Similarity between 'money' and 'deposit' before retrofitting: 0.3864688457388147\n",
      "Similarity between 'money' and 'deposit' after retrofitting: 0.34308451043192134\n",
      "Update: 0.04338433530689334\n",
      "\n",
      "Similarity between 'money' and 'withdrawal' before retrofitting: 0.1838273498787751\n",
      "Similarity between 'money' and 'withdrawal' after retrofitting: 0.07599430655170247\n",
      "Update: 0.10783304332707264\n",
      "\n",
      "Similarity between 'money' and 'laundering' before retrofitting: 0.4877732859775846\n",
      "Similarity between 'money' and 'laundering' after retrofitting: 0.5484581701366702\n",
      "Update: -0.06068488415908557\n",
      "\n",
      "Similarity between 'money' and 'operation' before retrofitting: 0.12615036874456567\n",
      "Similarity between 'money' and 'operation' after retrofitting: 0.2355486367909615\n",
      "Update: -0.10939826804639582\n",
      "\n",
      "Similarity between 'tiger' and 'jaguar' before retrofitting: 0.5153315923593653\n",
      "Similarity between 'tiger' and 'jaguar' after retrofitting: 0.5427602037005163\n",
      "Update: -0.027428611341150932\n",
      "\n",
      "Similarity between 'tiger' and 'mammal' before retrofitting: 0.3139792918670319\n",
      "Similarity between 'tiger' and 'mammal' after retrofitting: 0.20656892926982207\n",
      "Update: 0.10741036259720982\n",
      "\n",
      "Similarity between 'tiger' and 'animal' before retrofitting: 0.34446900444212614\n",
      "Similarity between 'tiger' and 'animal' after retrofitting: 0.37701286895060776\n",
      "Update: -0.032543864508481624\n",
      "\n",
      "Similarity between 'tiger' and 'organism' before retrofitting: 0.1727525390581988\n",
      "Similarity between 'tiger' and 'organism' after retrofitting: 0.2168268803380865\n",
      "Update: -0.04407434127988771\n",
      "\n",
      "Similarity between 'tiger' and 'fauna' before retrofitting: 0.22103905147723926\n",
      "Similarity between 'tiger' and 'fauna' after retrofitting: 0.47549776231029767\n",
      "Update: -0.2544587108330584\n",
      "\n",
      "Similarity between 'tiger' and 'zoo' before retrofitting: 0.45376140773023\n",
      "Similarity between 'tiger' and 'zoo' after retrofitting: 0.37017287668774346\n",
      "Update: 0.08358853104248654\n",
      "\n",
      "Similarity between 'psychology' and 'psychiatry' before retrofitting: 0.7696149098639089\n",
      "Similarity between 'psychology' and 'psychiatry' after retrofitting: 0.730036982634293\n",
      "Update: 0.03957792722961595\n",
      "\n",
      "Similarity between 'psychology' and 'fear' before retrofitting: 0.1964973180767654\n",
      "Similarity between 'psychology' and 'fear' after retrofitting: 0.2729806955480711\n",
      "Update: -0.07648337747130568\n",
      "\n",
      "Similarity between 'psychology' and 'depression' before retrofitting: 0.2608744652717436\n",
      "Similarity between 'psychology' and 'depression' after retrofitting: 0.2765869340760054\n",
      "Update: -0.015712468804261748\n",
      "\n",
      "Similarity between 'psychology' and 'doctor' before retrofitting: 0.4309964190930099\n",
      "Similarity between 'psychology' and 'doctor' after retrofitting: 0.3313376488310437\n",
      "Update: 0.09965877026196618\n",
      "\n",
      "Similarity between 'psychology' and 'mind' before retrofitting: 0.3569885743635376\n",
      "Similarity between 'psychology' and 'mind' after retrofitting: 0.43787526183357484\n",
      "Update: -0.08088668747003724\n",
      "\n",
      "Similarity between 'psychology' and 'health' before retrofitting: 0.4966090103404135\n",
      "Similarity between 'psychology' and 'health' after retrofitting: 0.3460668847101036\n",
      "Update: 0.1505421256303099\n",
      "\n",
      "Similarity between 'psychology' and 'science' before retrofitting: 0.6665620157509726\n",
      "Similarity between 'psychology' and 'science' after retrofitting: 0.2599779102409812\n",
      "Update: 0.4065841055099914\n",
      "\n",
      "Similarity between 'psychology' and 'discipline' before retrofitting: 0.3314297807693717\n",
      "Similarity between 'psychology' and 'discipline' after retrofitting: 0.45937109006653304\n",
      "Update: -0.12794130929716135\n",
      "\n",
      "Similarity between 'psychology' and 'cognition' before retrofitting: 0.6759983910138431\n",
      "Similarity between 'psychology' and 'cognition' after retrofitting: 0.3675360775602543\n",
      "Update: 0.30846231345358877\n",
      "\n",
      "Similarity between 'planet' and 'star' before retrofitting: 0.519761477538004\n",
      "Similarity between 'planet' and 'star' after retrofitting: 0.3109010371864469\n",
      "Update: 0.20886044035155704\n",
      "\n",
      "Similarity between 'planet' and 'constellation' before retrofitting: 0.4977904510675082\n",
      "Similarity between 'planet' and 'constellation' after retrofitting: 0.3171962965239624\n",
      "Update: 0.18059415454354577\n",
      "\n",
      "Similarity between 'planet' and 'moon' before retrofitting: 0.574677769918392\n",
      "Similarity between 'planet' and 'moon' after retrofitting: 0.17668092862304743\n",
      "Update: 0.3979968412953446\n",
      "\n",
      "Similarity between 'planet' and 'sun' before retrofitting: 0.4611190640217323\n",
      "Similarity between 'planet' and 'sun' after retrofitting: 0.2594561663573248\n",
      "Update: 0.20166289766440748\n",
      "\n",
      "Similarity between 'planet' and 'galaxy' before retrofitting: 0.5653450099902443\n",
      "Similarity between 'planet' and 'galaxy' after retrofitting: 0.3656395595706004\n",
      "Update: 0.19970545041964388\n",
      "\n",
      "Similarity between 'planet' and 'space' before retrofitting: 0.4130999340303344\n",
      "Similarity between 'planet' and 'space' after retrofitting: 0.37950453485973007\n",
      "Update: 0.033595399170604334\n",
      "\n",
      "Similarity between 'planet' and 'astronomer' before retrofitting: 0.3480027755941616\n",
      "Similarity between 'planet' and 'astronomer' after retrofitting: 0.31413467663244243\n",
      "Update: 0.03386809896171916\n",
      "\n",
      "Similarity between 'precedent' and 'example' before retrofitting: 0.3482787912209587\n",
      "Similarity between 'precedent' and 'example' after retrofitting: 0.4183949632492969\n",
      "Update: -0.07011617202833825\n",
      "\n",
      "Similarity between 'precedent' and 'information' before retrofitting: 0.19287277733703073\n",
      "Similarity between 'precedent' and 'information' after retrofitting: 0.23768165652852866\n",
      "Update: -0.044808879191497925\n",
      "\n",
      "Similarity between 'precedent' and 'cognition' before retrofitting: 0.0829476856720916\n",
      "Similarity between 'precedent' and 'cognition' after retrofitting: 0.1675472551370699\n",
      "Update: -0.08459956946497829\n",
      "\n",
      "Similarity between 'precedent' and 'law' before retrofitting: 0.37162107814369055\n",
      "Similarity between 'precedent' and 'law' after retrofitting: 0.32298209304870473\n",
      "Update: 0.04863898509498582\n",
      "\n",
      "Similarity between 'precedent' and 'collection' before retrofitting: 0.14303226231401617\n",
      "Similarity between 'precedent' and 'collection' after retrofitting: 0.23766638075026453\n",
      "Update: -0.09463411843624836\n",
      "\n",
      "Similarity between 'precedent' and 'group' before retrofitting: 0.09534828286901065\n",
      "Similarity between 'precedent' and 'group' after retrofitting: 0.24877295714739733\n",
      "Update: -0.15342467427838669\n",
      "\n",
      "Similarity between 'precedent' and 'antecedent' before retrofitting: 0.2910666566807138\n",
      "Similarity between 'precedent' and 'antecedent' after retrofitting: 0.18151776562631805\n",
      "Update: 0.10954889105439575\n",
      "\n",
      "Similarity between 'cup' and 'coffee' before retrofitting: 0.20797550452839314\n",
      "Similarity between 'cup' and 'coffee' after retrofitting: 0.16022757148207528\n",
      "Update: 0.04774793304631786\n",
      "\n",
      "Similarity between 'cup' and 'article' before retrofitting: 0.10711890223332217\n",
      "Similarity between 'cup' and 'article' after retrofitting: 0.09438571601537438\n",
      "Update: 0.012733186217947792\n",
      "\n",
      "Similarity between 'cup' and 'artifact' before retrofitting: 0.1080216076937357\n",
      "Similarity between 'cup' and 'artifact' after retrofitting: 0.1513480372448976\n",
      "Update: -0.043326429551161894\n",
      "\n",
      "Similarity between 'cup' and 'object' before retrofitting: 0.07251832640887662\n",
      "Similarity between 'cup' and 'object' after retrofitting: 0.11780188290575555\n",
      "Update: -0.04528355649687893\n",
      "\n",
      "Similarity between 'cup' and 'drink' before retrofitting: 0.20242876395843212\n",
      "Similarity between 'cup' and 'drink' after retrofitting: 0.22085022603599816\n",
      "Update: -0.018421462077566036\n",
      "\n",
      "Similarity between 'cup' and 'food' before retrofitting: 0.0807667007012764\n",
      "Similarity between 'cup' and 'food' after retrofitting: 0.13338359745741865\n",
      "Update: -0.052616896756142256\n",
      "\n",
      "Similarity between 'cup' and 'substance' before retrofitting: 0.05640861645139696\n",
      "Similarity between 'cup' and 'substance' after retrofitting: 0.2419303478926712\n",
      "Update: -0.18552173144127423\n",
      "\n",
      "Similarity between 'cup' and 'liquid' before retrofitting: 0.15859567621272105\n",
      "Similarity between 'cup' and 'liquid' after retrofitting: 0.2905111136151666\n",
      "Update: -0.13191543740244557\n",
      "\n",
      "Similarity between 'jaguar' and 'cat' before retrofitting: 0.32344008680522707\n",
      "Similarity between 'jaguar' and 'cat' after retrofitting: 0.3650405174236211\n",
      "Update: -0.041600430618394024\n",
      "\n",
      "Similarity between 'jaguar' and 'car' before retrofitting: 0.47178156153854967\n",
      "Similarity between 'jaguar' and 'car' after retrofitting: 0.2503430245379872\n",
      "Update: 0.22143853700056249\n",
      "\n",
      "Similarity between 'energy' and 'secretary' before retrofitting: 0.14870377486678638\n",
      "Similarity between 'energy' and 'secretary' after retrofitting: 0.21775413182119424\n",
      "Update: -0.06905035695440787\n",
      "\n",
      "Similarity between 'secretary' and 'senate' before retrofitting: 0.5107258624859309\n",
      "Similarity between 'secretary' and 'senate' after retrofitting: 0.13618877767308726\n",
      "Update: 0.37453708481284365\n",
      "\n",
      "Similarity between 'energy' and 'laboratory' before retrofitting: 0.3690024035447106\n",
      "Similarity between 'energy' and 'laboratory' after retrofitting: 0.26543603478771843\n",
      "Update: 0.10356636875699216\n",
      "\n",
      "Similarity between 'computer' and 'laboratory' before retrofitting: 0.4192700792767917\n",
      "Similarity between 'computer' and 'laboratory' after retrofitting: 0.326729784611162\n",
      "Update: 0.09254029466562974\n",
      "\n",
      "Similarity between 'weapon' and 'secret' before retrofitting: 0.3756434854529629\n",
      "Similarity between 'weapon' and 'secret' after retrofitting: 0.26802836199863955\n",
      "Update: 0.10761512345432334\n",
      "\n",
      "Similarity between 'investigation' and 'effort' before retrofitting: 0.31541103128757547\n",
      "Similarity between 'investigation' and 'effort' after retrofitting: 0.3835985046885717\n",
      "Update: -0.06818747340099623\n",
      "\n",
      "Similarity between 'news' and 'report' before retrofitting: 0.42827631995825033\n",
      "Similarity between 'news' and 'report' after retrofitting: 0.4907810972262448\n",
      "Update: -0.06250477726799447\n",
      "\n",
      "Similarity between 'canyon' and 'landscape' before retrofitting: 0.31199456760585376\n",
      "Similarity between 'canyon' and 'landscape' after retrofitting: 0.2679061131308578\n",
      "Update: 0.04408845447499593\n",
      "\n",
      "Similarity between 'image' and 'surface' before retrofitting: 0.2006105310106386\n",
      "Similarity between 'image' and 'surface' after retrofitting: 0.5926317024844087\n",
      "Update: -0.39202117147377\n",
      "\n",
      "Similarity between 'discovery' and 'space' before retrofitting: 0.23063979442308355\n",
      "Similarity between 'discovery' and 'space' after retrofitting: 0.31671985702246114\n",
      "Update: -0.08608006259937759\n",
      "\n",
      "Similarity between 'water' and 'seepage' before retrofitting: 0.5381568167791105\n",
      "Similarity between 'water' and 'seepage' after retrofitting: 0.472323726562995\n",
      "Update: 0.06583309021611555\n",
      "\n",
      "Similarity between 'sign' and 'recess' before retrofitting: 0.16953179194067447\n",
      "Similarity between 'sign' and 'recess' after retrofitting: 0.5922642948863495\n",
      "Update: -0.422732502945675\n",
      "\n",
      "Similarity between 'mile' and 'kilometer' before retrofitting: 0.7193962460158686\n",
      "Similarity between 'mile' and 'kilometer' after retrofitting: 0.42104423249647355\n",
      "Update: 0.29835201351939505\n",
      "\n",
      "Similarity between 'computer' and 'news' before retrofitting: 0.2285664151144775\n",
      "Similarity between 'computer' and 'news' after retrofitting: 0.28943512632188584\n",
      "Update: -0.06086871120740833\n",
      "\n",
      "Similarity between 'territory' and 'surface' before retrofitting: 0.17314869458684998\n",
      "Similarity between 'territory' and 'surface' after retrofitting: 0.4432059690182126\n",
      "Update: -0.2700572744313626\n",
      "\n",
      "Similarity between 'atmosphere' and 'landscape' before retrofitting: 0.3094822829874144\n",
      "Similarity between 'atmosphere' and 'landscape' after retrofitting: 0.34978335762581214\n",
      "Update: -0.040301074638397716\n",
      "\n",
      "Similarity between 'president' and 'medal' before retrofitting: 0.3244123254801186\n",
      "Similarity between 'president' and 'medal' after retrofitting: 0.24981765845517653\n",
      "Update: 0.07459466702494208\n",
      "\n",
      "Similarity between 'war' and 'troops' before retrofitting: 0.42153916415040305\n",
      "Similarity between 'war' and 'troops' after retrofitting: 0.3682251637329559\n",
      "Update: 0.05331400041744716\n",
      "\n",
      "Similarity between 'record' and 'number' before retrofitting: 0.2982527996274973\n",
      "Similarity between 'record' and 'number' after retrofitting: 0.643837736410245\n",
      "Update: -0.3455849367827477\n",
      "\n",
      "Similarity between 'skin' and 'eye' before retrofitting: 0.5272105414526764\n",
      "Similarity between 'skin' and 'eye' after retrofitting: 0.44272744935777747\n",
      "Update: 0.08448309209489896\n",
      "\n",
      "Similarity between 'theater' and 'history' before retrofitting: 0.24835518385837307\n",
      "Similarity between 'theater' and 'history' after retrofitting: 0.40425071566399073\n",
      "Update: -0.15589553180561766\n",
      "\n",
      "Similarity between 'volunteer' and 'motto' before retrofitting: 0.31070638950154694\n",
      "Similarity between 'volunteer' and 'motto' after retrofitting: 0.21307439181211174\n",
      "Update: 0.0976319976894352\n",
      "\n",
      "Similarity between 'prejudice' and 'recognition' before retrofitting: 0.1569417528015616\n",
      "Similarity between 'prejudice' and 'recognition' after retrofitting: 0.3678990170034874\n",
      "Update: -0.21095726420192581\n",
      "\n",
      "Similarity between 'decoration' and 'valor' before retrofitting: 0.5058515653001794\n",
      "Similarity between 'decoration' and 'valor' after retrofitting: 0.4687991938466501\n",
      "Update: 0.0370523714535293\n",
      "\n",
      "Similarity between 'century' and 'year' before retrofitting: 0.3005721451838296\n",
      "Similarity between 'century' and 'year' after retrofitting: 0.31664609801339166\n",
      "Update: -0.016073952829562088\n",
      "\n",
      "Similarity between 'century' and 'nation' before retrofitting: 0.21864306199795505\n",
      "Similarity between 'century' and 'nation' after retrofitting: 0.307365969717436\n",
      "Update: -0.08872290771948096\n",
      "\n",
      "Similarity between 'delay' and 'racism' before retrofitting: 0.09040073832228933\n",
      "Similarity between 'delay' and 'racism' after retrofitting: 0.22036681951485756\n",
      "Update: -0.12996608119256825\n",
      "\n",
      "Similarity between 'delay' and 'news' before retrofitting: 0.15109896237642725\n",
      "Similarity between 'delay' and 'news' after retrofitting: 0.3782879690001165\n",
      "Update: -0.22718900662368927\n",
      "\n",
      "Similarity between 'minister' and 'party' before retrofitting: 0.41903029933289204\n",
      "Similarity between 'minister' and 'party' after retrofitting: 0.22065790418527134\n",
      "Update: 0.1983723951476207\n",
      "\n",
      "Similarity between 'peace' and 'plan' before retrofitting: 0.27627026579666114\n",
      "Similarity between 'peace' and 'plan' after retrofitting: 0.3366176070116802\n",
      "Update: -0.06034734121501906\n",
      "\n",
      "Similarity between 'minority' and 'peace' before retrofitting: 0.23639444584679556\n",
      "Similarity between 'minority' and 'peace' after retrofitting: 0.1396382629133587\n",
      "Update: 0.09675618293343685\n",
      "\n",
      "Similarity between 'attempt' and 'peace' before retrofitting: 0.19563450568731033\n",
      "Similarity between 'attempt' and 'peace' after retrofitting: 0.40276213033592884\n",
      "Update: -0.2071276246486185\n",
      "\n",
      "Similarity between 'government' and 'crisis' before retrofitting: 0.40390346060649457\n",
      "Similarity between 'government' and 'crisis' after retrofitting: 0.47886524201167463\n",
      "Update: -0.07496178140518006\n",
      "\n",
      "Similarity between 'deployment' and 'departure' before retrofitting: 0.35505174295597863\n",
      "Similarity between 'deployment' and 'departure' after retrofitting: 0.3652610744367434\n",
      "Update: -0.01020933148076475\n",
      "\n",
      "Similarity between 'deployment' and 'withdrawal' before retrofitting: 0.4294599502486629\n",
      "Similarity between 'deployment' and 'withdrawal' after retrofitting: 0.4361557197755615\n",
      "Update: -0.006695769526898598\n",
      "\n",
      "Similarity between 'energy' and 'crisis' before retrofitting: 0.24562669856959823\n",
      "Similarity between 'energy' and 'crisis' after retrofitting: 0.16494896748599536\n",
      "Update: 0.08067773108360288\n",
      "\n",
      "Similarity between 'announcement' and 'news' before retrofitting: 0.4144241780349597\n",
      "Similarity between 'announcement' and 'news' after retrofitting: 0.41578293483283146\n",
      "Update: -0.0013587567978717852\n",
      "\n",
      "Similarity between 'announcement' and 'effort' before retrofitting: 0.29492976985580477\n",
      "Similarity between 'announcement' and 'effort' after retrofitting: 0.4023261056178252\n",
      "Update: -0.10739633576202046\n",
      "\n",
      "Similarity between 'stroke' and 'hospital' before retrofitting: 0.3218452148656307\n",
      "Similarity between 'stroke' and 'hospital' after retrofitting: 0.30980798856664116\n",
      "Update: 0.012037226298989567\n",
      "\n",
      "Similarity between 'disability' and 'death' before retrofitting: 0.2270331948422127\n",
      "Similarity between 'disability' and 'death' after retrofitting: 0.2976955674177987\n",
      "Update: -0.07066237257558597\n",
      "\n",
      "Similarity between 'victim' and 'emergency' before retrofitting: 0.2543353428930358\n",
      "Similarity between 'victim' and 'emergency' after retrofitting: 0.16251275861355752\n",
      "Update: 0.09182258427947826\n",
      "\n",
      "Similarity between 'treatment' and 'recovery' before retrofitting: 0.4401718058418478\n",
      "Similarity between 'treatment' and 'recovery' after retrofitting: 0.41388654467984876\n",
      "Update: 0.02628526116199903\n",
      "\n",
      "Similarity between 'journal' and 'association' before retrofitting: 0.36273327977460246\n",
      "Similarity between 'journal' and 'association' after retrofitting: 0.25687061014586876\n",
      "Update: 0.1058626696287337\n",
      "\n",
      "Similarity between 'doctor' and 'personnel' before retrofitting: 0.23438268637054316\n",
      "Similarity between 'doctor' and 'personnel' after retrofitting: 0.25390910602356576\n",
      "Update: -0.019526419653022598\n",
      "\n",
      "Similarity between 'doctor' and 'liability' before retrofitting: 0.13848875298442692\n",
      "Similarity between 'doctor' and 'liability' after retrofitting: 0.3027141972742123\n",
      "Update: -0.16422544428978536\n",
      "\n",
      "Similarity between 'liability' and 'insurance' before retrofitting: 0.5834748552408184\n",
      "Similarity between 'liability' and 'insurance' after retrofitting: 0.49601827209772403\n",
      "Update: 0.0874565831430944\n",
      "\n",
      "Similarity between 'school' and 'center' before retrofitting: 0.3671201646462656\n",
      "Similarity between 'school' and 'center' after retrofitting: 0.555644094429161\n",
      "Update: -0.18852392978289534\n",
      "\n",
      "Similarity between 'reason' and 'hypertension' before retrofitting: 0.144423274776883\n",
      "Similarity between 'reason' and 'hypertension' after retrofitting: 0.3185856228316871\n",
      "Update: -0.17416234805480413\n",
      "\n",
      "Similarity between 'reason' and 'criterion' before retrofitting: 0.42197100760154505\n",
      "Similarity between 'reason' and 'criterion' after retrofitting: 0.4922663187393192\n",
      "Update: -0.07029531113777415\n",
      "\n",
      "Similarity between 'hundred' and 'percent' before retrofitting: 0.3963913899953862\n",
      "Similarity between 'hundred' and 'percent' after retrofitting: 0.14527039774291975\n",
      "Update: 0.2511209922524664\n",
      "\n",
      "Similarity between 'hospital' and 'infrastructure' before retrofitting: 0.22509102964735866\n",
      "Similarity between 'hospital' and 'infrastructure' after retrofitting: 0.24930652561163086\n",
      "Update: -0.024215495964272193\n",
      "\n",
      "Similarity between 'death' and 'row' before retrofitting: 0.24864641736479412\n",
      "Similarity between 'death' and 'row' after retrofitting: 0.4523198647293468\n",
      "Update: -0.2036734473645527\n",
      "\n",
      "Similarity between 'death' and 'inmate' before retrofitting: 0.3408138610282122\n",
      "Similarity between 'death' and 'inmate' after retrofitting: 0.2908400433255782\n",
      "Update: 0.04997381770263398\n",
      "\n",
      "Similarity between 'lawyer' and 'evidence' before retrofitting: 0.1865072638891968\n",
      "Similarity between 'lawyer' and 'evidence' after retrofitting: 0.28028637936167256\n",
      "Update: -0.09377911547247575\n",
      "\n",
      "Similarity between 'life' and 'death' before retrofitting: 0.3931775431368855\n",
      "Similarity between 'life' and 'death' after retrofitting: 0.540690459326061\n",
      "Update: -0.14751291618917545\n",
      "\n",
      "Similarity between 'life' and 'term' before retrofitting: 0.21162744982172005\n",
      "Similarity between 'life' and 'term' after retrofitting: 0.3552027313736968\n",
      "Update: -0.14357528155197674\n",
      "\n",
      "Similarity between 'word' and 'similarity' before retrofitting: 0.30616878851257395\n",
      "Similarity between 'word' and 'similarity' after retrofitting: 0.23042927371733335\n",
      "Update: 0.0757395147952406\n",
      "\n",
      "Similarity between 'board' and 'recommendation' before retrofitting: 0.37079919685341345\n",
      "Similarity between 'board' and 'recommendation' after retrofitting: 0.3835440856186273\n",
      "Update: -0.012744888765213847\n",
      "\n",
      "Similarity between 'governor' and 'interview' before retrofitting: 0.13601457824475652\n",
      "Similarity between 'governor' and 'interview' after retrofitting: 0.25950088424115403\n",
      "Update: -0.12348630599639751\n",
      "\n",
      "Similarity between 'peace' and 'atmosphere' before retrofitting: 0.22281773646342043\n",
      "Similarity between 'peace' and 'atmosphere' after retrofitting: 0.47895809582509596\n",
      "Update: -0.25614035936167556\n",
      "\n",
      "Similarity between 'peace' and 'insurance' before retrofitting: 0.18095855845062\n",
      "Similarity between 'peace' and 'insurance' after retrofitting: 0.27078838653861564\n",
      "Update: -0.08982982808799564\n",
      "\n",
      "Similarity between 'territory' and 'kilometer' before retrofitting: 0.2984545710206714\n",
      "Similarity between 'territory' and 'kilometer' after retrofitting: 0.36332331272980195\n",
      "Update: -0.06486874170913054\n",
      "\n",
      "Similarity between 'travel' and 'activity' before retrofitting: 0.25162807367655476\n",
      "Similarity between 'travel' and 'activity' after retrofitting: 0.2725038211834166\n",
      "Update: -0.02087574750686183\n",
      "\n",
      "Similarity between 'competition' and 'price' before retrofitting: 0.2980840078723433\n",
      "Similarity between 'competition' and 'price' after retrofitting: 0.28919920061265514\n",
      "Update: 0.008884807259688154\n",
      "\n",
      "Similarity between 'consumer' and 'confidence' before retrofitting: 0.18944417036385178\n",
      "Similarity between 'consumer' and 'confidence' after retrofitting: 0.334855141047467\n",
      "Update: -0.14541097068361522\n",
      "\n",
      "Similarity between 'consumer' and 'energy' before retrofitting: 0.4368284673985543\n",
      "Similarity between 'consumer' and 'energy' after retrofitting: 0.2203226069402237\n",
      "Update: 0.2165058604583306\n",
      "\n",
      "Similarity between 'problem' and 'airport' before retrofitting: 0.10641880311909256\n",
      "Similarity between 'problem' and 'airport' after retrofitting: 0.11940724507703612\n",
      "Update: -0.012988441957943561\n",
      "\n",
      "Similarity between 'car' and 'flight' before retrofitting: 0.3147276417699101\n",
      "Similarity between 'car' and 'flight' after retrofitting: 0.3824616680103719\n",
      "Update: -0.06773402624046182\n",
      "\n",
      "Similarity between 'credit' and 'card' before retrofitting: 0.467679804710897\n",
      "Similarity between 'credit' and 'card' after retrofitting: 0.5631261919490653\n",
      "Update: -0.09544638723816834\n",
      "\n",
      "Similarity between 'credit' and 'information' before retrofitting: 0.3236116230803933\n",
      "Similarity between 'credit' and 'information' after retrofitting: 0.4034942106746738\n",
      "Update: -0.07988258759428046\n",
      "\n",
      "Similarity between 'hotel' and 'reservation' before retrofitting: 0.3312412119391827\n",
      "Similarity between 'hotel' and 'reservation' after retrofitting: 0.38662706865583235\n",
      "Update: -0.05538585671664964\n",
      "\n",
      "Similarity between 'grocery' and 'money' before retrofitting: 0.31541913433912633\n",
      "Similarity between 'grocery' and 'money' after retrofitting: 0.3190394603456553\n",
      "Update: -0.003620326006528951\n",
      "\n",
      "Similarity between 'registration' and 'arrangement' before retrofitting: 0.22005397134358096\n",
      "Similarity between 'registration' and 'arrangement' after retrofitting: 0.4454596538596634\n",
      "Update: -0.22540568251608245\n",
      "\n",
      "Similarity between 'arrangement' and 'accommodation' before retrofitting: 0.37577253442072794\n",
      "Similarity between 'arrangement' and 'accommodation' after retrofitting: 0.435924033422732\n",
      "Update: -0.06015149900200406\n",
      "\n",
      "Similarity between 'type' and 'kind' before retrofitting: 0.5226445651278104\n",
      "Similarity between 'type' and 'kind' after retrofitting: 0.5788969661223462\n",
      "Update: -0.05625240099453577\n",
      "\n",
      "Similarity between 'arrival' and 'hotel' before retrofitting: 0.2379218396577449\n",
      "Similarity between 'arrival' and 'hotel' after retrofitting: 0.1845022756801212\n",
      "Update: 0.05341956397762371\n",
      "\n",
      "Similarity between 'bed' and 'closet' before retrofitting: 0.514430679723206\n",
      "Similarity between 'bed' and 'closet' after retrofitting: 0.5166255033795575\n",
      "Update: -0.0021948236563514856\n",
      "\n",
      "Similarity between 'closet' and 'clothes' before retrofitting: 0.46717911310929067\n",
      "Similarity between 'closet' and 'clothes' after retrofitting: 0.5740247080510471\n",
      "Update: -0.10684559494175644\n",
      "\n",
      "Similarity between 'situation' and 'conclusion' before retrofitting: 0.36559048912987213\n",
      "Similarity between 'situation' and 'conclusion' after retrofitting: 0.6014149446888296\n",
      "Update: -0.23582445555895748\n",
      "\n",
      "Similarity between 'situation' and 'isolation' before retrofitting: 0.32896806680719665\n",
      "Similarity between 'situation' and 'isolation' after retrofitting: 0.25328897716089754\n",
      "Update: 0.0756790896462991\n",
      "\n",
      "Similarity between 'impartiality' and 'interest' before retrofitting: 0.25425832004418547\n",
      "Similarity between 'impartiality' and 'interest' after retrofitting: 0.3829786374996651\n",
      "Update: -0.12872031745547963\n",
      "\n",
      "Similarity between 'direction' and 'combination' before retrofitting: 0.2255150923554187\n",
      "Similarity between 'direction' and 'combination' after retrofitting: 0.45682434138585143\n",
      "Update: -0.23130924903043273\n",
      "\n",
      "Similarity between 'street' and 'place' before retrofitting: 0.2814481774100284\n",
      "Similarity between 'street' and 'place' after retrofitting: 0.4347031148556595\n",
      "Update: -0.15325493744563107\n",
      "\n",
      "Similarity between 'street' and 'avenue' before retrofitting: 0.7944696888211877\n",
      "Similarity between 'street' and 'avenue' after retrofitting: 0.7149147780632746\n",
      "Update: 0.0795549107579131\n",
      "\n",
      "Similarity between 'street' and 'block' before retrofitting: 0.3272265135369973\n",
      "Similarity between 'street' and 'block' after retrofitting: 0.3132529648351719\n",
      "Update: 0.013973548701825378\n",
      "\n",
      "Similarity between 'street' and 'children' before retrofitting: 0.21689014006223406\n",
      "Similarity between 'street' and 'children' after retrofitting: 0.3181518243498603\n",
      "Update: -0.10126168428762622\n",
      "\n",
      "Similarity between 'listing' and 'proximity' before retrofitting: 0.12003172246279278\n",
      "Similarity between 'listing' and 'proximity' after retrofitting: 0.1481380159821849\n",
      "Update: -0.028106293519392117\n",
      "\n",
      "Similarity between 'listing' and 'category' before retrofitting: 0.4023952990054468\n",
      "Similarity between 'listing' and 'category' after retrofitting: 0.35783750096728734\n",
      "Update: 0.04455779803815946\n",
      "\n",
      "Similarity between 'cell' and 'phone' before retrofitting: 0.42862021128596994\n",
      "Similarity between 'cell' and 'phone' after retrofitting: 0.6115189441465659\n",
      "Update: -0.182898732860596\n",
      "\n",
      "Similarity between 'production' and 'hike' before retrofitting: 0.0938559905103312\n",
      "Similarity between 'production' and 'hike' after retrofitting: 0.43741662225475875\n",
      "Update: -0.3435606317444275\n",
      "\n",
      "Similarity between 'benchmark' and 'index' before retrofitting: 0.575850437852915\n",
      "Similarity between 'benchmark' and 'index' after retrofitting: 0.3510019241467566\n",
      "Update: 0.22484851370615838\n",
      "\n",
      "Similarity between 'media' and 'trading' before retrofitting: 0.17525306262110277\n",
      "Similarity between 'media' and 'trading' after retrofitting: 0.2529375414346809\n",
      "Update: -0.07768447881357812\n",
      "\n",
      "Similarity between 'media' and 'gain' before retrofitting: 0.26197772989341506\n",
      "Similarity between 'media' and 'gain' after retrofitting: 0.36510265718523427\n",
      "Update: -0.10312492729181921\n",
      "\n",
      "Similarity between 'dividend' and 'calculation' before retrofitting: 0.3507031694077017\n",
      "Similarity between 'dividend' and 'calculation' after retrofitting: 0.3121751536018203\n",
      "Update: 0.03852801580588139\n",
      "\n",
      "Similarity between 'calculation' and 'computation' before retrofitting: 0.687704014429982\n",
      "Similarity between 'calculation' and 'computation' after retrofitting: 0.887928878112124\n",
      "Update: -0.20022486368214198\n",
      "\n",
      "Similarity between 'currency' and 'market' before retrofitting: 0.45398172042498663\n",
      "Similarity between 'currency' and 'market' after retrofitting: 0.3505223327420696\n",
      "Update: 0.10345938768291701\n",
      "\n",
      "Similarity between 'oil' and 'stock' before retrofitting: 0.32418891516998\n",
      "Similarity between 'oil' and 'stock' after retrofitting: 0.5302704344947221\n",
      "Update: -0.2060815193247421\n",
      "\n",
      "Similarity between 'announcement' and 'production' before retrofitting: 0.24923300212796567\n",
      "Similarity between 'announcement' and 'production' after retrofitting: 0.19723364271778643\n",
      "Update: 0.05199935941017925\n",
      "\n",
      "Similarity between 'announcement' and 'warning' before retrofitting: 0.2613362807351249\n",
      "Similarity between 'announcement' and 'warning' after retrofitting: 0.30216176799147165\n",
      "Update: -0.04082548725634677\n",
      "\n",
      "Similarity between 'profit' and 'warning' before retrofitting: 0.05171257099383002\n",
      "Similarity between 'profit' and 'warning' after retrofitting: 0.2610115264856885\n",
      "Update: -0.20929895549185845\n",
      "\n",
      "Similarity between 'profit' and 'loss' before retrofitting: 0.19591486661921312\n",
      "Similarity between 'profit' and 'loss' after retrofitting: 0.48859218052315007\n",
      "Update: -0.2926773139039369\n",
      "\n",
      "Similarity between 'dollar' and 'yen' before retrofitting: 0.4977735716983742\n",
      "Similarity between 'dollar' and 'yen' after retrofitting: 0.43968574936635896\n",
      "Update: 0.05808782233201526\n",
      "\n",
      "Similarity between 'dollar' and 'buck' before retrofitting: 0.3611598893952871\n",
      "Similarity between 'dollar' and 'buck' after retrofitting: 0.614582252250962\n",
      "Update: -0.2534223628556749\n",
      "\n",
      "Similarity between 'dollar' and 'profit' before retrofitting: 0.33508607815462904\n",
      "Similarity between 'dollar' and 'profit' after retrofitting: 0.2743468859718907\n",
      "Update: 0.06073919218273832\n",
      "\n",
      "Similarity between 'dollar' and 'loss' before retrofitting: 0.12362969070393039\n",
      "Similarity between 'dollar' and 'loss' after retrofitting: 0.35258163508039864\n",
      "Update: -0.22895194437646826\n",
      "\n",
      "Similarity between 'computer' and 'software' before retrofitting: 0.6468620907416638\n",
      "Similarity between 'computer' and 'software' after retrofitting: 0.29199109179546723\n",
      "Update: 0.35487099894619656\n",
      "\n",
      "Similarity between 'network' and 'hardware' before retrofitting: 0.3177904514376401\n",
      "Similarity between 'network' and 'hardware' after retrofitting: 0.4970024856081986\n",
      "Update: -0.17921203417055848\n",
      "\n",
      "Similarity between 'phone' and 'equipment' before retrofitting: 0.30961041225437763\n",
      "Similarity between 'phone' and 'equipment' after retrofitting: 0.41043558595191393\n",
      "Update: -0.1008251736975363\n",
      "\n",
      "Similarity between 'equipment' and 'maker' before retrofitting: 0.24174991446424224\n",
      "Similarity between 'equipment' and 'maker' after retrofitting: 0.4020004581988897\n",
      "Update: -0.16025054373464745\n",
      "\n",
      "Similarity between 'luxury' and 'car' before retrofitting: 0.4174046574650426\n",
      "Similarity between 'luxury' and 'car' after retrofitting: 0.26572347479118297\n",
      "Update: 0.1516811826738596\n",
      "\n",
      "Similarity between 'five' and 'month' before retrofitting: 0.43915704514951853\n",
      "Similarity between 'five' and 'month' after retrofitting: 0.15677301671354507\n",
      "Update: 0.28238402843597343\n",
      "\n",
      "Similarity between 'report' and 'gain' before retrofitting: 0.05346097750505492\n",
      "Similarity between 'report' and 'gain' after retrofitting: 0.5964123790555735\n",
      "Update: -0.5429514015505186\n",
      "\n",
      "Similarity between 'investor' and 'earning' before retrofitting: 0.17898559190018085\n",
      "Similarity between 'investor' and 'earning' after retrofitting: 0.2704446050895251\n",
      "Update: -0.09145901318934427\n",
      "\n",
      "Similarity between 'liquid' and 'water' before retrofitting: 0.5512252578990561\n",
      "Similarity between 'liquid' and 'water' after retrofitting: 0.561493782400468\n",
      "Update: -0.010268524501411913\n",
      "\n",
      "Similarity between 'baseball' and 'season' before retrofitting: 0.40714763631610656\n",
      "Similarity between 'baseball' and 'season' after retrofitting: 0.20709215858356797\n",
      "Update: 0.2000554777325386\n",
      "\n",
      "Similarity between 'game' and 'victory' before retrofitting: 0.32052317597447866\n",
      "Similarity between 'game' and 'victory' after retrofitting: 0.41288443623391785\n",
      "Update: -0.09236126025943919\n",
      "\n",
      "Similarity between 'game' and 'team' before retrofitting: 0.3602181279448463\n",
      "Similarity between 'game' and 'team' after retrofitting: 0.27565673314185685\n",
      "Update: 0.08456139480298946\n",
      "\n",
      "Similarity between 'marathon' and 'sprint' before retrofitting: 0.5465444238280975\n",
      "Similarity between 'marathon' and 'sprint' after retrofitting: 0.3164602457245269\n",
      "Update: 0.23008417810357062\n",
      "\n",
      "Similarity between 'game' and 'series' before retrofitting: 0.42139494523759286\n",
      "Similarity between 'game' and 'series' after retrofitting: 0.2989498868237488\n",
      "Update: 0.12244505841384407\n",
      "\n",
      "Similarity between 'game' and 'defeat' before retrofitting: 0.35115345990732666\n",
      "Similarity between 'game' and 'defeat' after retrofitting: 0.6247782800624665\n",
      "Update: -0.27362482015513984\n",
      "\n",
      "Similarity between 'seven' and 'series' before retrofitting: 0.41648462403604086\n",
      "Similarity between 'seven' and 'series' after retrofitting: 0.1745289091594936\n",
      "Update: 0.24195571487654727\n",
      "\n",
      "Similarity between 'seafood' and 'sea' before retrofitting: 0.3306571798167045\n",
      "Similarity between 'seafood' and 'sea' after retrofitting: 0.32203466658951657\n",
      "Update: 0.008622513227187933\n",
      "\n",
      "Similarity between 'seafood' and 'food' before retrofitting: 0.6978338489756991\n",
      "Similarity between 'seafood' and 'food' after retrofitting: 0.43052375990023634\n",
      "Update: 0.2673100890754628\n",
      "\n",
      "Similarity between 'lobster' and 'food' before retrofitting: 0.4759274122251642\n",
      "Similarity between 'lobster' and 'food' after retrofitting: 0.28661932585681504\n",
      "Update: 0.18930808636834917\n",
      "\n",
      "Similarity between 'lobster' and 'wine' before retrofitting: 0.41791529878156675\n",
      "Similarity between 'lobster' and 'wine' after retrofitting: 0.29666648245227617\n",
      "Update: 0.12124881632929058\n",
      "\n",
      "Similarity between 'food' and 'preparation' before retrofitting: 0.4106230287433116\n",
      "Similarity between 'food' and 'preparation' after retrofitting: 0.3787757810883098\n",
      "Update: 0.0318472476550018\n",
      "\n",
      "Similarity between 'video' and 'archive' before retrofitting: 0.1356101712212238\n",
      "Similarity between 'video' and 'archive' after retrofitting: 0.15106054419340856\n",
      "Update: -0.015450372972184767\n",
      "\n",
      "Similarity between 'start' and 'year' before retrofitting: 0.3445289658727612\n",
      "Similarity between 'start' and 'year' after retrofitting: 0.3952494106508335\n",
      "Update: -0.050720444778072304\n",
      "\n",
      "Similarity between 'start' and 'match' before retrofitting: 0.31434689209982597\n",
      "Similarity between 'start' and 'match' after retrofitting: 0.6612698800084355\n",
      "Update: -0.3469229879086095\n",
      "\n",
      "Similarity between 'game' and 'round' before retrofitting: 0.28621710641695486\n",
      "Similarity between 'game' and 'round' after retrofitting: 0.7044950107538356\n",
      "Update: -0.4182779043368807\n",
      "\n",
      "Similarity between 'boxing' and 'round' before retrofitting: 0.19154012630495382\n",
      "Similarity between 'boxing' and 'round' after retrofitting: 0.43902606193416666\n",
      "Update: -0.24748593562921284\n",
      "\n",
      "Similarity between 'championship' and 'tournament' before retrofitting: 0.7444553855765738\n",
      "Similarity between 'championship' and 'tournament' after retrofitting: 0.23428224773244563\n",
      "Update: 0.5101731378441281\n",
      "\n",
      "Similarity between 'fighting' and 'defeating' before retrofitting: 0.29337143790539577\n",
      "Similarity between 'fighting' and 'defeating' after retrofitting: 0.6620720283086722\n",
      "Update: -0.3687005904032764\n",
      "\n",
      "Similarity between 'line' and 'insurance' before retrofitting: 0.14398239143371\n",
      "Similarity between 'line' and 'insurance' after retrofitting: 0.3959708430719263\n",
      "Update: -0.2519884516382163\n",
      "\n",
      "Similarity between 'day' and 'summer' before retrofitting: 0.37266241017908114\n",
      "Similarity between 'day' and 'summer' after retrofitting: 0.425595841597515\n",
      "Update: -0.052933431418433874\n",
      "\n",
      "Similarity between 'summer' and 'drought' before retrofitting: 0.2621906266869796\n",
      "Similarity between 'summer' and 'drought' after retrofitting: 0.29685685739054457\n",
      "Update: -0.03466623070356495\n",
      "\n",
      "Similarity between 'summer' and 'nature' before retrofitting: 0.1853843496297093\n",
      "Similarity between 'summer' and 'nature' after retrofitting: 0.1531045891113991\n",
      "Update: 0.03227976051831019\n",
      "\n",
      "Similarity between 'day' and 'dawn' before retrofitting: 0.37852736143093796\n",
      "Similarity between 'day' and 'dawn' after retrofitting: 0.5843787567638189\n",
      "Update: -0.20585139533288094\n",
      "\n",
      "Similarity between 'nature' and 'environment' before retrofitting: 0.5263190161943299\n",
      "Similarity between 'nature' and 'environment' after retrofitting: 0.47262200033570373\n",
      "Update: 0.05369701585862613\n",
      "\n",
      "Similarity between 'environment' and 'ecology' before retrofitting: 0.5759535900602069\n",
      "Similarity between 'environment' and 'ecology' after retrofitting: 0.35318016892850834\n",
      "Update: 0.2227734211316985\n",
      "\n",
      "Similarity between 'nature' and 'man' before retrofitting: 0.28627321889494334\n",
      "Similarity between 'nature' and 'man' after retrofitting: 0.49151910681909317\n",
      "Update: -0.20524588792414983\n",
      "\n",
      "Similarity between 'man' and 'woman' before retrofitting: 0.6658470105380624\n",
      "Similarity between 'man' and 'woman' after retrofitting: 0.46443789102238736\n",
      "Update: 0.20140911951567503\n",
      "\n",
      "Similarity between 'man' and 'governor' before retrofitting: 0.22529994330088682\n",
      "Similarity between 'man' and 'governor' after retrofitting: 0.21884090761658614\n",
      "Update: 0.0064590356843006735\n",
      "\n",
      "Similarity between 'murder' and 'manslaughter' before retrofitting: 0.7050093014917536\n",
      "Similarity between 'murder' and 'manslaughter' after retrofitting: 0.32770753419337606\n",
      "Update: 0.3773017672983775\n",
      "\n",
      "Similarity between 'soap' and 'opera' before retrofitting: 0.5597841918886536\n",
      "Similarity between 'soap' and 'opera' after retrofitting: 0.21498297405852865\n",
      "Update: 0.34480121783012496\n",
      "\n",
      "Similarity between 'opera' and 'performance' before retrofitting: 0.34825366227979776\n",
      "Similarity between 'opera' and 'performance' after retrofitting: 0.1625334498003517\n",
      "Update: 0.18572021247944606\n",
      "\n",
      "Similarity between 'life' and 'lesson' before retrofitting: 0.2927790955891807\n",
      "Similarity between 'life' and 'lesson' after retrofitting: 0.5118285581018562\n",
      "Update: -0.21904946251267554\n",
      "\n",
      "Similarity between 'focus' and 'life' before retrofitting: 0.37360468819818893\n",
      "Similarity between 'focus' and 'life' after retrofitting: 0.4907702972425834\n",
      "Update: -0.11716560904439449\n",
      "\n",
      "Similarity between 'production' and 'crew' before retrofitting: 0.24360373090856294\n",
      "Similarity between 'production' and 'crew' after retrofitting: 0.19684816479157044\n",
      "Update: 0.0467555661169925\n",
      "\n",
      "Similarity between 'television' and 'film' before retrofitting: 0.568723193092448\n",
      "Similarity between 'television' and 'film' after retrofitting: 0.6044900143471861\n",
      "Update: -0.03576682125473807\n",
      "\n",
      "Similarity between 'lover' and 'quarrel' before retrofitting: 0.44007927187742446\n",
      "Similarity between 'lover' and 'quarrel' after retrofitting: 0.3169022065610689\n",
      "Update: 0.12317706531635558\n",
      "\n",
      "Similarity between 'viewer' and 'serial' before retrofitting: 0.20212685614156517\n",
      "Similarity between 'viewer' and 'serial' after retrofitting: 0.2885906630478035\n",
      "Update: -0.08646380690623834\n",
      "\n",
      "Similarity between 'possibility' and 'girl' before retrofitting: 0.15245454509034184\n",
      "Similarity between 'possibility' and 'girl' after retrofitting: 0.259145728900865\n",
      "Update: -0.10669118381052317\n",
      "\n",
      "Similarity between 'population' and 'development' before retrofitting: 0.22605376529930335\n",
      "Similarity between 'population' and 'development' after retrofitting: 0.25630217567729885\n",
      "Update: -0.0302484103779955\n",
      "\n",
      "Similarity between 'morality' and 'importance' before retrofitting: 0.31423138018774754\n",
      "Similarity between 'morality' and 'importance' after retrofitting: 0.2942037071158457\n",
      "Update: 0.02002767307190184\n",
      "\n",
      "Similarity between 'morality' and 'marriage' before retrofitting: 0.38633256898497703\n",
      "Similarity between 'morality' and 'marriage' after retrofitting: 0.4266187317326758\n",
      "Update: -0.04028616274769875\n",
      "\n",
      "Similarity between 'gender' and 'equality' before retrofitting: 0.5862350883267482\n",
      "Similarity between 'gender' and 'equality' after retrofitting: 0.18267494518305724\n",
      "Update: 0.40356014314369093\n",
      "\n",
      "Similarity between 'change' and 'attitude' before retrofitting: 0.311045702462625\n",
      "Similarity between 'change' and 'attitude' after retrofitting: 0.3126481026512478\n",
      "Update: -0.0016024001886228434\n",
      "\n",
      "Similarity between 'family' and 'planning' before retrofitting: 0.150242238240384\n",
      "Similarity between 'family' and 'planning' after retrofitting: 0.4764862490407527\n",
      "Update: -0.3262440108003687\n",
      "\n",
      "Similarity between 'opera' and 'industry' before retrofitting: 0.1999320091974873\n",
      "Similarity between 'opera' and 'industry' after retrofitting: 0.1614948877434866\n",
      "Update: 0.03843712145400069\n",
      "\n",
      "Similarity between 'sugar' and 'approach' before retrofitting: 0.09573850955033071\n",
      "Similarity between 'sugar' and 'approach' after retrofitting: 0.31277555450179967\n",
      "Update: -0.21703704495146897\n",
      "\n",
      "Similarity between 'practice' and 'institution' before retrofitting: 0.34664063586638316\n",
      "Similarity between 'practice' and 'institution' after retrofitting: 0.5064983444158352\n",
      "Update: -0.15985770854945203\n",
      "\n",
      "Similarity between 'ministry' and 'culture' before retrofitting: 0.35637908192730194\n",
      "Similarity between 'ministry' and 'culture' after retrofitting: 0.31931189022016504\n",
      "Update: 0.037067191707136904\n",
      "\n",
      "Similarity between 'problem' and 'challenge' before retrofitting: 0.3147201635668211\n",
      "Similarity between 'problem' and 'challenge' after retrofitting: 0.29005313417648104\n",
      "Update: 0.024667029390340045\n",
      "\n",
      "Similarity between 'size' and 'prominence' before retrofitting: 0.19908037983633792\n",
      "Similarity between 'size' and 'prominence' after retrofitting: 0.44518735558759664\n",
      "Update: -0.24610697575125873\n",
      "\n",
      "Similarity between 'country' and 'citizen' before retrofitting: 0.3858730649025389\n",
      "Similarity between 'country' and 'citizen' after retrofitting: 0.4726375542031504\n",
      "Update: -0.08676448930061148\n",
      "\n",
      "Similarity between 'planet' and 'people' before retrofitting: 0.16107155519293073\n",
      "Similarity between 'planet' and 'people' after retrofitting: 0.33950518209499375\n",
      "Update: -0.17843362690206302\n",
      "\n",
      "Similarity between 'development' and 'issue' before retrofitting: 0.1699497042447709\n",
      "Similarity between 'development' and 'issue' after retrofitting: 0.5878490064165028\n",
      "Update: -0.41789930217173193\n",
      "\n",
      "Similarity between 'experience' and 'music' before retrofitting: 0.27052414819144976\n",
      "Similarity between 'experience' and 'music' after retrofitting: 0.22726772470558887\n",
      "Update: 0.043256423485860895\n",
      "\n",
      "Similarity between 'music' and 'project' before retrofitting: 0.3108060141539901\n",
      "Similarity between 'music' and 'project' after retrofitting: 0.2699809652512812\n",
      "Update: 0.04082504890270894\n",
      "\n",
      "Similarity between 'glass' and 'metal' before retrofitting: 0.47637366241410384\n",
      "Similarity between 'glass' and 'metal' after retrofitting: 0.5271616472454037\n",
      "Update: -0.05078798483129987\n",
      "\n",
      "Similarity between 'aluminum' and 'metal' before retrofitting: 0.5818277272279189\n",
      "Similarity between 'aluminum' and 'metal' after retrofitting: 0.7915368734079101\n",
      "Update: -0.20970914617999126\n",
      "\n",
      "Similarity between 'chance' and 'credibility' before retrofitting: 0.3169952828269589\n",
      "Similarity between 'chance' and 'credibility' after retrofitting: 0.3170315040471688\n",
      "Update: -3.622122020990881e-05\n",
      "\n",
      "Similarity between 'exhibit' and 'memorabilia' before retrofitting: 0.38623598677526755\n",
      "Similarity between 'exhibit' and 'memorabilia' after retrofitting: 0.3570020436427578\n",
      "Update: 0.029233943132509765\n",
      "\n",
      "Similarity between 'concert' and 'virtuoso' before retrofitting: 0.48561499552017373\n",
      "Similarity between 'concert' and 'virtuoso' after retrofitting: 0.35287107192527517\n",
      "Update: 0.13274392359489856\n",
      "\n",
      "Similarity between 'rock' and 'jazz' before retrofitting: 0.5421643742927887\n",
      "Similarity between 'rock' and 'jazz' after retrofitting: 0.6083863593160483\n",
      "Update: -0.0662219850232596\n",
      "\n",
      "Similarity between 'museum' and 'theater' before retrofitting: 0.4679903266892968\n",
      "Similarity between 'museum' and 'theater' after retrofitting: 0.45725471063101425\n",
      "Update: 0.010735616058282549\n",
      "\n",
      "Similarity between 'observation' and 'architecture' before retrofitting: 0.24924606890034434\n",
      "Similarity between 'observation' and 'architecture' after retrofitting: 0.2317621331907918\n",
      "Update: 0.017483935709552534\n",
      "\n",
      "Similarity between 'space' and 'world' before retrofitting: 0.16201209623194165\n",
      "Similarity between 'space' and 'world' after retrofitting: 0.5275527868125033\n",
      "Update: -0.3655406905805616\n",
      "\n",
      "Similarity between 'preservation' and 'world' before retrofitting: 0.1278478491868286\n",
      "Similarity between 'preservation' and 'world' after retrofitting: 0.45495708344225255\n",
      "Update: -0.32710923425542393\n",
      "\n",
      "Similarity between 'admission' and 'ticket' before retrofitting: 0.41643268596243277\n",
      "Similarity between 'admission' and 'ticket' after retrofitting: 0.25948792555693956\n",
      "Update: 0.1569447604054932\n",
      "\n",
      "Similarity between 'shower' and 'thunderstorm' before retrofitting: 0.48556203317784374\n",
      "Similarity between 'shower' and 'thunderstorm' after retrofitting: 0.31176026593506034\n",
      "Update: 0.1738017672427834\n",
      "\n",
      "Similarity between 'shower' and 'flood' before retrofitting: 0.24936297450262368\n",
      "Similarity between 'shower' and 'flood' after retrofitting: 0.40964680099274536\n",
      "Update: -0.16028382649012168\n",
      "\n",
      "Similarity between 'weather' and 'forecast' before retrofitting: 0.642593401789184\n",
      "Similarity between 'weather' and 'forecast' after retrofitting: 0.4900451971643258\n",
      "Update: 0.15254820462485819\n",
      "\n",
      "Similarity between 'disaster' and 'area' before retrofitting: 0.25571124304709214\n",
      "Similarity between 'disaster' and 'area' after retrofitting: 0.37145071754097886\n",
      "Update: -0.11573947449388672\n",
      "\n",
      "Similarity between 'governor' and 'office' before retrofitting: 0.42209747699357636\n",
      "Similarity between 'governor' and 'office' after retrofitting: 0.42998868327623513\n",
      "Update: -0.00789120628265877\n",
      "\n",
      "Similarity between 'architecture' and 'century' before retrofitting: 0.30194647996254603\n",
      "Similarity between 'architecture' and 'century' after retrofitting: 0.11061622831254057\n",
      "Update: 0.19133025165000545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarities between word embedding pairs after the retrofitting\n",
    "EN_retrofitted_wordVecs = convert_matrix_to_dict(EN_retrofitted_vecs, EN_wordList)\n",
    "print_similarity_difference(EN_wordVecs, EN_retrofitted_wordVecs, EN_lines, \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity_batch(X, Y, batch_size):\n",
    "    n_samples_X = X.shape[0]\n",
    "    n_samples_Y = Y.shape[0]\n",
    "    cos_similarities = np.zeros((n_samples_X, n_samples_Y))\n",
    "\n",
    "    for i in range(0, n_samples_X, batch_size):\n",
    "        batch_X = X[i:i+batch_size]\n",
    "        cos_similarities[i:i+batch_size] = cosine_similarity(batch_X, Y)\n",
    "\n",
    "    return cos_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 118. GiB for an array with shape (125776, 125776) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m     17\u001b[0m \u001b[39m# Calculate the cosine similarity between the original and retrofitted embeddings in batches\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m EN_cos_similarities \u001b[39m=\u001b[39m calculate_cosine_similarity_batch(EN_wordVecMat, EN_retrofitted_wordVecs_rt, batch_size)\n\u001b[0;32m     20\u001b[0m \u001b[39m# Compute the average cosine similarity\u001b[39;00m\n\u001b[0;32m     21\u001b[0m avg_cos_similarity \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(EN_cos_similarities)\n",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m, in \u001b[0;36mcalculate_cosine_similarity_batch\u001b[1;34m(X, Y, batch_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m n_samples_X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      3\u001b[0m n_samples_Y \u001b[39m=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m cos_similarities \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((n_samples_X, n_samples_Y))\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n_samples_X, batch_size):\n\u001b[0;32m      7\u001b[0m     batch_X \u001b[39m=\u001b[39m X[i:i\u001b[39m+\u001b[39mbatch_size]\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 118. GiB for an array with shape (125776, 125776) and data type float64"
     ]
    }
   ],
   "source": [
    "# Check the best semantic relation types for the retrofitting\n",
    "relation_types = [\"antonyms\", \"hyponyms\", \"hypernyms\", \"meronyms\", \"holonyms\", \"homonyms\"]\n",
    "EN_avg_cos_similarities = []\n",
    "for relation_type in relation_types:\n",
    "    # Retrieve the neighbors for EN_wordList using the current relation_type\n",
    "    EN_neighbors_dict_rt = get_wordnet_lexicon(EN_wordList, relation_type)\n",
    "\n",
    "    # Generate the matrix of neighbor embeddings using EN_neighbors_dict\n",
    "    EN_neighbors_matrix_rt = retrieve_neighbors_embedding_matrix(EN_wordVecMat, EN_wordList, EN_neighbors_dict_rt)\n",
    "\n",
    "    # Perform retrofitting on wordVecMat using neighbors_matrix\n",
    "    EN_retrofitted_wordVecs_rt = retrofitting_wordVecs(EN_wordVecMat, EN_neighbors_matrix_rt, alpha=1, beta=1, nb_iter=10)\n",
    "\n",
    "    # Define batch size\n",
    "    batch_size = 1000\n",
    "\n",
    "    # Calculate the cosine similarity between the original and retrofitted embeddings in batches\n",
    "    EN_cos_similarities = calculate_cosine_similarity_batch(EN_wordVecMat, EN_retrofitted_wordVecs_rt, batch_size)\n",
    "\n",
    "    # Compute the average cosine similarity\n",
    "    avg_cos_similarity = np.mean(EN_cos_similarities)\n",
    "\n",
    "plt.plot(relation_types, EN_avg_cos_similarities, marker='o')\n",
    "plt.xlabel('Relation Types')\n",
    "plt.ylabel('Average Cosine Similarity')\n",
    "plt.title('Retrofitting Performance based on Relation Types')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing down the vectors in ../data/English/output_vectors/output_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "print_word_vecs(EN_retrofitted_wordVecs, EN_output_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Retrofitting the French wiki corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/French/word_embeddings/vecs100-linear-frwiki \n"
     ]
    }
   ],
   "source": [
    "# Retrieving the word vectors in a dictionary (key: word, value: embedding)\n",
    "FR_wordVecs = read_word_vecs(\"../data/French/word_embeddings/vecs100-linear-frwiki\")\n",
    "# Retrieving the pairs of words with human scores\n",
    "FR_lexical_similarity = read_lexicon(\"../data/French/lexicon/rg65_french.txt\")\n",
    "# Creating an output file to print back the updated embeddings\n",
    "FR_output_file = \"../data/French/output_vectors/output_vectors.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the necessary objects for the retrofitting\n",
    "FR_wordList = get_embeddings_words(FR_wordVecs)\n",
    "FR_neighbors_dict = get_wordnet_lexicon(FR_wordList, \"synonyms\") #[\"antonyms\", \"hyponyms\", \"hypernyms\", \"meronyms\", \"holonyms\", \"homonyms\"]\n",
    "FR_wordVecMat = convert_dict_to_matrix(FR_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'corde' and 'sourire': 0.4669326346248422\n",
      "Similarity between 'midi' and 'ficelle': 0.17987154414903447\n",
      "Similarity between 'fruit' and 'fournaise': 0.19855455062830601\n",
      "Similarity between 'autographe' and 'rivage': 0.2359732441183503\n",
      "Similarity between 'automobile' and 'sorcier': 0.2780385970271853\n",
      "Similarity between 'monticule' and 'four': 0.37188339759122474\n",
      "Similarity between 'grimace' and 'instrument': 0.08425105107857007\n",
      "Similarity between 'refuge' and 'fruit': 0.3546915183782402\n",
      "Similarity between 'refuge' and 'moine': 0.44047104586365804\n",
      "Similarity between 'verre' and 'magicien': 0.3524265421212991\n",
      "Similarity between 'coussin' and 'bijou': 0.19221924567126153\n",
      "Similarity between 'moine' and 'esclave': 0.27402356388110366\n",
      "Similarity between 'grimace' and 'gars': 0.29618183124645214\n",
      "Similarity between 'rivage' and 'bois': 0.5382997780515452\n",
      "Similarity between 'moine' and 'oracle': 0.3304813322413485\n",
      "Similarity between 'automobile' and 'coussin': 0.1980486936824828\n",
      "Similarity between 'monticule' and 'rivage': 0.16834333296693407\n",
      "Similarity between 'gars' and 'sorcier': 0.5008716458823733\n",
      "Similarity between 'nourriture' and 'coq': 0.33958425014478544\n",
      "Similarity between 'rivage' and 'trip': 0.22562424366356712\n",
      "Similarity between 'oiseau' and 'bois': 0.3952646255802111\n",
      "Similarity between 'fournaise' and 'instrument': 0.11278213502904569\n",
      "Similarity between 'grue' and 'coq': 0.4490738122926923\n",
      "Similarity between 'colline' and 'bois': 0.4771713191758933\n",
      "Similarity between 'auto' and 'voyage': 0.21082504949883812\n",
      "Similarity between 'verre' and 'bijou': 0.5095296099406674\n",
      "Similarity between 'magicien' and 'oracle': 0.3187606504254582\n",
      "Similarity between 'grue' and 'instrument': 0.3052376801215136\n",
      "Similarity between 'sage' and 'sorcier': 0.21306568001356352\n",
      "Similarity between 'oracle' and 'sage': 0.15601500221893105\n",
      "Similarity between 'oiseau' and 'grue': 0.4289200056825726\n",
      "Similarity between 'oiseau' and 'coq': 0.498666541826329\n",
      "Similarity between 'nourriture' and 'fruit': 0.4034861969988075\n",
      "Similarity between 'refuge' and 'asile': 0.5290790094280808\n",
      "Similarity between 'fournaise' and 'four': 0.36494113852125537\n",
      "Similarity between 'magicien' and 'sorcier': 0.7134576230993717\n",
      "Similarity between 'colline' and 'monticule': 0.19306359538315535\n",
      "Similarity between 'corde' and 'ficelle': 0.5131581271785413\n",
      "Similarity between 'verre' and 'goblet': 0.3176701186085022\n",
      "Similarity between 'grimace' and 'sourire': 0.4351592006369281\n",
      "Similarity between 'serf' and 'esclave': 0.3273814691798148\n",
      "Similarity between 'autographe' and 'signature': 0.27583826725149463\n",
      "Similarity between 'instrument' and 'outil': 0.5741081774516558\n",
      "Similarity between 'coq' and 'coq': 1.0\n",
      "Similarity between 'coussin' and 'oreiller': 0.5961794278396209\n",
      "Similarity between 'automobile' and 'auto': 0.5102698667945689\n",
      "Similarity between 'joyau' and 'bijou': 0.4585484624318887\n"
     ]
    }
   ],
   "source": [
    "# Retrive word pairs from the lexical similarity file\n",
    "with open('../data/French/lexicon/rg65_french.txt', 'r') as file:\n",
    "    FR_lines = file.readlines()\n",
    "# Get their similarities\n",
    "print_lexical_similarities(FR_wordVecs, FR_lines, \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the matrix of neighbor's embeddings\n",
    "FR_neighbors_matrix= retrieve_neighbors_embedding_matrix(FR_wordVecMat, FR_wordList, FR_neighbors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 100)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Visualizing the matrix of neighbor's embedding on a subset\n",
    "FR_subset_wordVecs = {word: FR_wordVecs[word] for word in FR_wordList[:100]}\n",
    "FR_subset_neighbors_dict = {word: FR_neighbors_dict[word] for word in list(FR_neighbors_dict.keys())[:100]}\n",
    "FR_subset_wordVecMat = FR_wordVecMat[:100] \n",
    "FR_subset_wordList = FR_wordList[:100]\n",
    "\n",
    "# Test the function on the subset\n",
    "FR_subset_neighbors_matrix = retrieve_neighbors_embedding_matrix(FR_subset_wordVecMat, FR_subset_wordList, FR_subset_neighbors_dict)\n",
    "\n",
    "# Print the result\n",
    "print(FR_subset_neighbors_matrix)\n",
    "print(type(FR_subset_neighbors_matrix))  \n",
    "print(FR_subset_neighbors_matrix.shape)  \n",
    "print(FR_subset_neighbors_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix of word embeddings\n",
      "<class 'numpy.ndarray'>\n",
      "(130391, 100)\n",
      "2\n",
      "\n",
      "Matrix of neighbors' embeddings\n",
      "<class 'numpy.ndarray'>\n",
      "(130391, 100)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Checking that the matrices we pass as argument of the retrofitting algorithm have the same shape and dimension\n",
    "print(\"Matrix of word embeddings\")\n",
    "print(type(FR_neighbors_matrix))  \n",
    "print(FR_neighbors_matrix.shape)  \n",
    "print(FR_neighbors_matrix.ndim) \n",
    "print(\"\\nMatrix of neighbors' embeddings\")\n",
    "print(type(FR_wordVecMat))  \n",
    "print(FR_wordVecMat.shape)  \n",
    "print(FR_wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrofitting the French word embeddings\n",
    "FR_retrofitted_vecs = retrofitting_wordVecs(FR_wordVecMat, FR_neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'automobile' and 'sorcier' before retrofitting: 0.2780385970271853\n",
      "Similarity between 'automobile' and 'sorcier' after retrofitting: 0.37085750628655917\n",
      "Update: -0.09281890925937386\n",
      "\n",
      "Similarity between 'monticule' and 'four' before retrofitting: 0.37188339759122474\n",
      "Similarity between 'monticule' and 'four' after retrofitting: 0.31096630934587355\n",
      "Update: 0.06091708824535119\n",
      "\n",
      "Similarity between 'grimace' and 'instrument' before retrofitting: 0.08425105107857007\n",
      "Similarity between 'grimace' and 'instrument' after retrofitting: 0.35567062766184043\n",
      "Update: -0.27141957658327037\n",
      "\n",
      "Similarity between 'refuge' and 'fruit' before retrofitting: 0.3546915183782402\n",
      "Similarity between 'refuge' and 'fruit' after retrofitting: 0.46586483241536847\n",
      "Update: -0.11117331403712827\n",
      "\n",
      "Similarity between 'refuge' and 'moine' before retrofitting: 0.44047104586365804\n",
      "Similarity between 'refuge' and 'moine' after retrofitting: 0.27218706285706573\n",
      "Update: 0.1682839830065923\n",
      "\n",
      "Similarity between 'grimace' and 'gars' before retrofitting: 0.29618183124645214\n",
      "Similarity between 'grimace' and 'gars' after retrofitting: 0.11968695855918553\n",
      "Update: 0.1764948726872666\n",
      "\n",
      "Similarity between 'moine' and 'oracle' before retrofitting: 0.3304813322413485\n",
      "Similarity between 'moine' and 'oracle' after retrofitting: 0.3076857543632324\n",
      "Update: 0.02279557787811609\n",
      "\n",
      "Similarity between 'automobile' and 'coussin' before retrofitting: 0.1980486936824828\n",
      "Similarity between 'automobile' and 'coussin' after retrofitting: 0.3216154147024683\n",
      "Update: -0.1235667210199855\n",
      "\n",
      "Similarity between 'gars' and 'sorcier' before retrofitting: 0.5008716458823733\n",
      "Similarity between 'gars' and 'sorcier' after retrofitting: 0.3766810427785889\n",
      "Update: 0.12419060310378444\n",
      "\n",
      "Similarity between 'rivage' and 'trip' before retrofitting: 0.22562424366356712\n",
      "Similarity between 'rivage' and 'trip' after retrofitting: 0.34371218301174983\n",
      "Update: -0.11808793934818271\n",
      "\n",
      "Similarity between 'fournaise' and 'instrument' before retrofitting: 0.11278213502904569\n",
      "Similarity between 'fournaise' and 'instrument' after retrofitting: 0.17137330632392883\n",
      "Update: -0.05859117129488314\n",
      "\n",
      "Similarity between 'auto' and 'voyage' before retrofitting: 0.21082504949883812\n",
      "Similarity between 'auto' and 'voyage' after retrofitting: 0.5263073074031415\n",
      "Update: -0.31548225790430334\n",
      "\n",
      "Similarity between 'magicien' and 'oracle' before retrofitting: 0.3187606504254582\n",
      "Similarity between 'magicien' and 'oracle' after retrofitting: 0.5705684087052068\n",
      "Update: -0.25180775827974855\n",
      "\n",
      "Similarity between 'grue' and 'instrument' before retrofitting: 0.3052376801215136\n",
      "Similarity between 'grue' and 'instrument' after retrofitting: 0.1913603123811777\n",
      "Update: 0.11387736774033588\n",
      "\n",
      "Similarity between 'sage' and 'sorcier' before retrofitting: 0.21306568001356352\n",
      "Similarity between 'sage' and 'sorcier' after retrofitting: 0.11999212108955326\n",
      "Update: 0.09307355892401026\n",
      "\n",
      "Similarity between 'oracle' and 'sage' before retrofitting: 0.15601500221893105\n",
      "Similarity between 'oracle' and 'sage' after retrofitting: 0.19555284909455198\n",
      "Update: -0.039537846875620924\n",
      "\n",
      "Similarity between 'refuge' and 'asile' before retrofitting: 0.5290790094280808\n",
      "Similarity between 'refuge' and 'asile' after retrofitting: 0.42371152552205105\n",
      "Update: 0.10536748390602979\n",
      "\n",
      "Similarity between 'fournaise' and 'four' before retrofitting: 0.36494113852125537\n",
      "Similarity between 'fournaise' and 'four' after retrofitting: 0.2879465816635288\n",
      "Update: 0.07699455685772655\n",
      "\n",
      "Similarity between 'verre' and 'goblet' before retrofitting: 0.3176701186085022\n",
      "Similarity between 'verre' and 'goblet' after retrofitting: 0.3513572673245727\n",
      "Update: -0.03368714871607048\n",
      "\n",
      "Similarity between 'grimace' and 'sourire' before retrofitting: 0.4351592006369281\n",
      "Similarity between 'grimace' and 'sourire' after retrofitting: 0.2342025825798828\n",
      "Update: 0.2009566180570453\n",
      "\n",
      "Similarity between 'autographe' and 'signature' before retrofitting: 0.27583826725149463\n",
      "Similarity between 'autographe' and 'signature' after retrofitting: 0.16037416261122403\n",
      "Update: 0.1154641046402706\n",
      "\n",
      "Similarity between 'instrument' and 'outil' before retrofitting: 0.5741081774516558\n",
      "Similarity between 'instrument' and 'outil' after retrofitting: 0.34894566075467626\n",
      "Update: 0.2251625166969795\n",
      "\n",
      "Similarity between 'automobile' and 'auto' before retrofitting: 0.5102698667945689\n",
      "Similarity between 'automobile' and 'auto' after retrofitting: 0.8988572576683516\n",
      "Update: -0.3885873908737827\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the similarities between word embedding pairs after the retrofitting\n",
    "FR_retrofitted_wordVecs = convert_matrix_to_dict(FR_retrofitted_vecs, FR_wordList)\n",
    "print_similarity_difference(FR_wordVecs, FR_retrofitted_wordVecs, FR_lines, \"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: tune hyperparametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: experiment whether there is a difference in performance depending on the type of semantic relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
