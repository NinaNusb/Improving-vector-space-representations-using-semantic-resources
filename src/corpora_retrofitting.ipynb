{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, matutils\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained Word2Vec model\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "\n",
    "def norm_word(word):\n",
    "  \"\"\"\n",
    "  - input: word\n",
    "  - return: a normalized version of it\n",
    "  Normalization process: includes checking if the word is a number or a punctuation mark and replacing it with special tokens\n",
    "  \"\"\"\n",
    "  if isNumber.search(word.lower()):\n",
    "    return '---num---'\n",
    "  # check if the word consists only of non-alphanumeric characters by removing all non-alphanumeric characters from the word \n",
    "  # and checking if the result is an empty string\n",
    "  elif re.sub(r'\\W+', '', word) == '':\n",
    "    return '---punc---'\n",
    "  else:\n",
    "  # if input word not a number nor a punctuation mark, return a lowercase version of input word\n",
    "    return word.lower()\n",
    "  \n",
    "\n",
    "  \n",
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    first_line = True\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # Skip the first line\n",
    "      if first_line:\n",
    "        first_line =False\n",
    "        continue\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors\n",
    "\n",
    "  ''' Write word vectors to file '''\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "  \"\"\"\n",
    "  - input: a dictionary wordVectors where keys are words and values are their corresponding word vectors\n",
    "           file name outFileName\n",
    "  \"\"\"\n",
    "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "  outFile = open(outFileName, 'w', encoding= 'utf-8')  \n",
    "  for word, values in wordVectors.items():\n",
    "    outFile.write(word+' ')\n",
    "    for val in wordVectors[word]:\n",
    "      # write the word vectors to the ouptut file in the format:\n",
    "      # word1 val1 val2 val3 ...\n",
    "      # word2 val1 val2 val3 ...\n",
    "      # ...\n",
    "      outFile.write('%.4f' %(val)+' ')\n",
    "    outFile.write('\\n')      \n",
    "  outFile.close()\n",
    "\n",
    "''' Read the PPDB word relations as a dictionary '''\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.lower().strip().split()\n",
    "            lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the same format for the toy corpus as for the provided word embeddings\n",
    "def convert_matrix_to_dict(wordVecMat, wordList):\n",
    "    wordVecs = {}\n",
    "\n",
    "    for i, word in enumerate(wordList):\n",
    "        wordVecs[word] = wordVecMat[i]\n",
    "\n",
    "    return wordVecs\n",
    "\n",
    "def convert_dict_to_matrix(wordVecs):\n",
    "    wordVecMat = np.stack(list(wordVecs.values()))\n",
    "    return wordVecMat\n",
    "\n",
    "def vectorize_list(corpus):\n",
    "    corpus_vecs = [model[word] for word in corpus]\n",
    "\n",
    "    return corpus_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same input format as the real corpus\n",
    "toy_corpus = [\"cat\", \"tiger\", \"computer\", \"keyboard\", \"plane\", \"car\", \"doctor\", \"nurse\", \"love\", \"sex\"]\n",
    "toy_corpus_list_vecs = vectorize_list(toy_corpus)\n",
    "toy_wordVecs = convert_matrix_to_dict(toy_corpus_list_vecs, toy_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    similarity = dot_product / norm_product\n",
    "    return similarity\n",
    "\n",
    "def generate_cosine_similarity_matrix(dict_vecs): \n",
    "    num_vectors = len(dict_vecs)\n",
    "    similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "    for i, word1 in enumerate(dict_vecs):\n",
    "        for j, word2 in enumerate(dict_vecs):\n",
    "            similarity_matrix[i, j] = calculate_cosine_similarity(dict_vecs[word1], dict_vecs[word2])\n",
    "    return similarity_matrix\n",
    "\n",
    "def print_vec_similarities(wordList, similarity_matrix):\n",
    "    for word, vec in zip(wordList, similarity_matrix):\n",
    "        print(f'Similarities with \"{word}\":')\n",
    "        for i in range(len(vec)):\n",
    "            similarity = vec[i]\n",
    "            print(f'  - \"{wordList[i]}\": {similarity:.4f}')\n",
    "        print()\n",
    "\n",
    "def print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix):\n",
    "    difference = np.abs(similarity_matrix - retrofitted_similarity_matrix)\n",
    "    print(\"Similarity Difference Matrix:\")\n",
    "    print(difference)\n",
    "\n",
    "def cosine_similarity_matrix(matrix1, matrix2):\n",
    "    dot_product = np.sum(matrix1 * matrix2)\n",
    "    norm_matrix1 = np.linalg.norm(matrix1)\n",
    "    norm_matrix2 = np.linalg.norm(matrix2)\n",
    "    cosine_similarity = dot_product / (norm_matrix1 * norm_matrix2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon(target_words, relation_types):\n",
    "    lexicon = {}\n",
    "\n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"antonyms\" in relation_types:\n",
    "                if syn.lemmas()[0].antonyms():\n",
    "                    related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "            if \"hyponyms\" in relation_types:\n",
    "                for hypo in syn.hyponyms():\n",
    "                    for lemma in hypo.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"hypernyms\" in relation_types:\n",
    "                for hyper in syn.hypernyms():\n",
    "                    for lemma in hyper.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"meronyms\" in relation_types:\n",
    "                for part in syn.part_meronyms():\n",
    "                    for lemma in part.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"holonyms\" in relation_types:\n",
    "                for whole in syn.part_holonyms():\n",
    "                    for lemma in whole.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"homonyms\" in relation_types:\n",
    "                for lemma in syn.lemmas():\n",
    "                    if lemma.name() != word:\n",
    "                        homonyms = wordnet.lemmas(lemma.name())\n",
    "                        for homonym in homonyms:\n",
    "                            related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecMat = convert_dict_to_matrix(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(toy_corpus_list_vecs)) \n",
    "\n",
    "print(type(wordVecMat)) \n",
    "print(wordVecMat.shape)  \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 10)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(similarity_matrix)) \n",
    "print(similarity_matrix.shape)  \n",
    "print(similarity_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for the big corpus to retrive the word list from the keys\n",
    "def get_embeddings_words(wordVecs):\n",
    "    wordList = list(wordVecs.keys()) # TODO: or set?\n",
    "    return wordList\n",
    "\n",
    "wordList = get_embeddings_words(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbors_embedding_matrix(wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        embeddings = [\n",
    "            model.get_vector(neighbor)\n",
    "            for neighbor in neighbors\n",
    "            if model.has_index_for(neighbor)\n",
    "        ]\n",
    "        if len(embeddings) > 0:\n",
    "            average_embedding = np.sum(embeddings, axis=0) / len(embeddings)\n",
    "        else:\n",
    "            # Handle the case where a word has no embeddings for its synonyms\n",
    "            average_embedding = np.zeros(model.vector_size)  # Use a zero vector\n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix\n",
    "\n",
    "   \n",
    "    \n",
    "neighbors_matrix = create_neighbors_embedding_matrix(wordList, \"synonyms\")\n",
    "\n",
    "# récupérer la liste des syn dans wordnet\n",
    "# vectorise chaque syn\n",
    "# BOW des synonymes (sum) pour n'avoir qu'un embedding \n",
    "# BOW_syn_cat\n",
    "# BOW_syn_dog= neighbors_matrix, shape (10, embedding_size) donc same size as wordVecs_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix))  # <class 'numpy.ndarray'>\n",
    "print(neighbors_matrix.shape)  # (m, n)\n",
    "print(neighbors_matrix.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  # <class 'numpy.ndarray'>\n",
    "print(wordVecMat.shape)  # (m, n)\n",
    "print(wordVecMat.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00676925  0.17245371 -0.32560504 -0.02995695  0.24918167  0.06591797\n",
      "  0.07754347  0.02062197  0.12026186 -0.24899179  0.11663705 -0.43598995\n",
      " -0.0165247  -0.43618888  0.05141873 -0.2046328   0.09973597  0.0461245\n",
      " -0.4420053   0.08787028  0.26338252 -0.1518453   0.11536521 -0.14642108\n",
      " -0.04931188  0.32405486 -0.15808557  0.31547716  0.40427201 -0.007934\n",
      " -0.00195312 -0.20903128 -0.03433369 -0.0849519   0.01340795  0.15198545\n",
      " -0.07754234  0.04350902  0.00148463  0.24564164  0.00093107  0.03174506\n",
      " -0.14347048  0.13828702  0.08990253 -0.03038646  0.37447442 -0.05503337\n",
      "  0.00611821  0.00164738 -0.15880896  0.13665545  0.34953252  0.14862174\n",
      " -0.0103189  -0.14141733  0.15832859 -0.30018898  0.35803392  0.18776052\n",
      "  0.28351056  0.18667716 -0.01274052  0.19207764  0.04131345  0.04772498\n",
      "  0.20808016  0.02882668 -0.10890771 -0.12867793  0.40634721 -0.03548855\n",
      " -0.15468343 -0.01318077 -0.11528298  0.38514766  0.11844098 -0.08239746\n",
      " -0.02005401 -0.06692618  0.08503554 -0.00346544  0.1995228  -0.07893711\n",
      " -0.34383251  0.04050474 -0.2636391  -0.14694101 -0.1783899  -0.0918257\n",
      " -0.0131429   0.04139088 -0.06987395 -0.25662345 -0.17748967 -0.27476671\n",
      " -0.01672363 -0.17666287 -0.33676034 -0.18375199 -0.24108435 -0.02301817\n",
      " -0.0048376   0.25613178  0.07612101 -0.20470513  0.0953064  -0.03844798\n",
      "  0.04892759 -0.11653646 -0.07707384  0.29826298  0.11636692  0.32834201\n",
      " -0.31238471 -0.00066913 -0.02505154 -0.23873901 -0.22574163 -0.04350577\n",
      " -0.03468753 -0.05264395 -0.30785455  0.02505323 -0.34844179  0.11226626\n",
      "  0.10000073  0.1189044   0.04702872 -0.14758527  0.13923419  0.04321967\n",
      " -0.15519799 -0.06542969 -0.02879789 -0.11844042 -0.02837584  0.09594444\n",
      "  0.10183038  0.10198523 -0.06081022  0.02417896 -0.15294054  0.04794516\n",
      "  0.06066442  0.15922716 -0.19703731  0.17048589 -0.12367983 -0.15320898\n",
      "  0.22272971  0.09056261 -0.31849727 -0.08702935 -0.13079947 -0.05045121\n",
      "  0.09113679  0.05342385  0.03645833  0.22512252 -0.10272612 -0.05701814\n",
      "  0.09566696 -0.13046604 -0.12130398  0.00603117 -0.04856138  0.21248373\n",
      "  0.17837637  0.02974899 -0.08555999 -0.03059218 -0.04345082  0.23660165\n",
      " -0.08013295  0.09815696  0.07034867 -0.12642416 -0.242515    0.27940539\n",
      " -0.16617132  0.01541816 -0.00099126  0.0524677  -0.03739194  0.07791251\n",
      "  0.20973601  0.3004286   0.12838844  0.06714884  0.02089154 -0.16434733\n",
      "  0.12680845  0.06278935 -0.01593244  0.184226    0.07969835 -0.18987359\n",
      " -0.11193918  0.18708067  0.06552409 -0.27893744 -0.0675354  -0.05583897\n",
      "  0.04787643  0.11910897 -0.01438636 -0.13045473  0.10323758 -0.26696325\n",
      " -0.40234262 -0.02973316 -0.0515894  -0.08254327 -0.11705977 -0.0447789\n",
      "  0.16213056 -0.31804127 -0.10855222  0.12037037  0.18612897  0.11705413\n",
      " -0.22371081 -0.27236599 -0.2145137  -0.07454851  0.07460587 -0.07304269\n",
      "  0.22288344  0.00952374  0.10791355  0.03955135 -0.03007846  0.04184525\n",
      " -0.28511386  0.05631058  0.27960488  0.02073415 -0.08864961  0.066971\n",
      "  0.23477738 -0.20298824  0.03927584  0.03217344  0.33202221  0.05400481\n",
      "  0.05493726 -0.036039    0.22249632 -0.13921215 -0.33608415  0.18813239\n",
      " -0.28481038  0.02863178 -0.04690326  0.27920871 -0.1286395   0.1268627\n",
      " -0.15716192  0.07503933 -0.08402846  0.04506429 -0.04430474 -0.1314799\n",
      "  0.06542573  0.24106775 -0.10216381  0.02992079 -0.27746017 -0.02798801\n",
      " -0.07106696  0.04219563 -0.15462466  0.13976994  0.05472141  0.09482377\n",
      "  0.1267994   0.16184228  0.17293295 -0.14490651  0.2610078   0.05841742\n",
      " -0.20719062  0.28466684  0.13873743 -0.08083654 -0.09813182  0.04846644\n",
      "  0.08657498  0.13033097 -0.25310149  0.11868851 -0.1590384   0.03733656\n",
      "  0.42320421 -0.01760412  0.18546778  0.49357605 -0.276461    0.01063255]\n"
     ]
    }
   ],
   "source": [
    "difference = toy_corpus_list_vecs[0] - neighbors_matrix[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs(wordVecMat, neighbors_mean_matrix, alpha, beta, nb_iter):\n",
    "    # Create a deep copy of wordVecMat \n",
    "    newWordVecMat = np.copy(wordVecMat, order='K')\n",
    "    updates = []\n",
    "    \n",
    "    for _ in range(nb_iter):\n",
    "        # Calculate the number of neighbors for each word\n",
    "        # numNeighbors = np.sum(neighbors_mean_matrix != 0, axis=1)\n",
    "        \n",
    "        # Update the word embeddings using retrofitting formula\n",
    "        newWordVecMat = (alpha * newWordVecMat + beta * neighbors_mean_matrix) / (alpha + beta)\n",
    "\n",
    "        # Calculate the updates\n",
    "        update = newWordVecMat - wordVecMat\n",
    "        updates.append(update)\n",
    "\n",
    "        # Update the wordVecMat for the next iteration\n",
    "        wordVecMat = newWordVecMat\n",
    "\n",
    "        # Stoping criterion\n",
    "        if np.linalg.norm(updates) < 1e-2:\n",
    "            break # TODO: return the embedding\n",
    "\n",
    "    # Convert the matrix back to a dictionary of word vectors\n",
    "    # retrofitted_wordVecs = dict(zip(wordList, newWordVecMat))\n",
    "\n",
    "    return newWordVecMat, updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = get_wordnet_lexicon(wordList, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'khat': ['cat'],\n",
       " 'give_suck': ['nurse'],\n",
       " 'regurgitate': ['cat'],\n",
       " 'calculator': ['computer'],\n",
       " 'big_cat': ['cat'],\n",
       " 'CT': ['cat'],\n",
       " 'wind_up': ['sex'],\n",
       " 'doctor_up': ['doctor'],\n",
       " 'fuck': ['love'],\n",
       " 'physician': ['doctor'],\n",
       " 'making_love': ['love'],\n",
       " 'sexual_practice': ['sex'],\n",
       " 'gender': ['sex'],\n",
       " 'electronic_computer': ['computer'],\n",
       " 'information_processing_system': ['computer'],\n",
       " 'nursemaid': ['nurse'],\n",
       " 'Doctor_of_the_Church': ['doctor'],\n",
       " 'roll_in_the_hay': ['love'],\n",
       " 'sophisticate': ['doctor'],\n",
       " 'railway_car': ['car'],\n",
       " 'sex': ['sexual_urge',\n",
       "  'sexual_activity',\n",
       "  'excite',\n",
       "  'turn_on',\n",
       "  'sexual_practice',\n",
       "  'gender',\n",
       "  'arouse',\n",
       "  'sex_activity',\n",
       "  'wind_up',\n",
       "  'sexuality'],\n",
       " 'cast': ['cat'],\n",
       " 'Dr.': ['doctor'],\n",
       " 'doctor': ['doc',\n",
       "  'mend',\n",
       "  'physician',\n",
       "  'sophisticate',\n",
       "  'furbish_up',\n",
       "  'touch_on',\n",
       "  'Doctor',\n",
       "  'medico',\n",
       "  'fix',\n",
       "  'Dr.',\n",
       "  'repair',\n",
       "  'restore',\n",
       "  'MD',\n",
       "  'bushel',\n",
       "  'Doctor_of_the_Church',\n",
       "  'doctor_up'],\n",
       " 'regorge': ['cat'],\n",
       " 'CAT': ['cat'],\n",
       " 'honey': ['love'],\n",
       " 'doc': ['doctor'],\n",
       " \"cat-o'-nine-tails\": ['cat'],\n",
       " 'hold': ['nurse'],\n",
       " 'excite': ['sex'],\n",
       " 'computer': ['data_processor',\n",
       "  'estimator',\n",
       "  'information_processing_system',\n",
       "  'electronic_computer',\n",
       "  'figurer',\n",
       "  'reckoner',\n",
       "  'computing_machine',\n",
       "  'calculator',\n",
       "  'computing_device'],\n",
       " 'bonk': ['love'],\n",
       " 'arouse': ['sex'],\n",
       " 'medico': ['doctor'],\n",
       " 'true_cat': ['cat'],\n",
       " 'puke': ['cat'],\n",
       " 'sexual_love': ['love'],\n",
       " 'reckoner': ['computer'],\n",
       " 'bang': ['love'],\n",
       " 'computing_machine': ['computer'],\n",
       " 'sexual_urge': ['sex'],\n",
       " 'harbour': ['nurse'],\n",
       " 'retch': ['cat'],\n",
       " 'hump': ['love'],\n",
       " 'woodworking_plane': ['plane'],\n",
       " 'have_it_off': ['love'],\n",
       " 'machine': ['car'],\n",
       " 'planing_machine': ['plane'],\n",
       " 'lactate': ['nurse'],\n",
       " 'bozo': ['cat'],\n",
       " 'throw_up': ['cat'],\n",
       " 'jazz': ['love'],\n",
       " 'Arabian_tea': ['cat'],\n",
       " 'nanny': ['nurse'],\n",
       " 'honk': ['cat'],\n",
       " 'cat': ['khat',\n",
       "  'retch',\n",
       "  'spew',\n",
       "  'chuck',\n",
       "  'regurgitate',\n",
       "  'big_cat',\n",
       "  'CT',\n",
       "  'bozo',\n",
       "  'throw_up',\n",
       "  'Arabian_tea',\n",
       "  'computed_tomography',\n",
       "  'honk',\n",
       "  'be_sick',\n",
       "  'barf',\n",
       "  'upchuck',\n",
       "  'computerized_tomography',\n",
       "  'computed_axial_tomography',\n",
       "  'guy',\n",
       "  'purge',\n",
       "  'spue',\n",
       "  'vomit',\n",
       "  'cast',\n",
       "  'Caterpillar',\n",
       "  'regorge',\n",
       "  'sick',\n",
       "  'computerized_axial_tomography',\n",
       "  'CAT',\n",
       "  'disgorge',\n",
       "  'vomit_up',\n",
       "  \"cat-o'-nine-tails\",\n",
       "  'African_tea',\n",
       "  'hombre',\n",
       "  'kat',\n",
       "  'qat',\n",
       "  'true_cat',\n",
       "  'puke',\n",
       "  'quat'],\n",
       " 'gondola': ['car'],\n",
       " 'breastfeed': ['nurse'],\n",
       " 'mend': ['doctor'],\n",
       " 'suck': ['nurse'],\n",
       " 'cable_car': ['car'],\n",
       " 'guy': ['cat'],\n",
       " 'car': ['auto',\n",
       "  'motorcar',\n",
       "  'automobile',\n",
       "  'railway_car',\n",
       "  'railroad_car',\n",
       "  'cable_car',\n",
       "  'elevator_car',\n",
       "  'machine',\n",
       "  'railcar',\n",
       "  'gondola'],\n",
       " 'figurer': ['computer'],\n",
       " 'Caterpillar': ['cat'],\n",
       " 'Panthera_tigris': ['tiger'],\n",
       " 'sleep_together': ['love'],\n",
       " 'computing_device': ['computer'],\n",
       " 'sick': ['cat'],\n",
       " 'disgorge': ['cat'],\n",
       " 'love': ['erotic_love',\n",
       "  'have_it_away',\n",
       "  'lie_with',\n",
       "  'hump',\n",
       "  'have_it_off',\n",
       "  'get_laid',\n",
       "  'have_a_go_at_it',\n",
       "  'do_it',\n",
       "  'fuck',\n",
       "  'dearest',\n",
       "  'jazz',\n",
       "  'making_love',\n",
       "  'have_sex',\n",
       "  'passion',\n",
       "  'roll_in_the_hay',\n",
       "  'beloved',\n",
       "  'dear',\n",
       "  'love_life',\n",
       "  'know',\n",
       "  'sleep_together',\n",
       "  'have_intercourse',\n",
       "  'honey',\n",
       "  'get_it_on',\n",
       "  'enjoy',\n",
       "  'make_love',\n",
       "  'bonk',\n",
       "  'make_out',\n",
       "  'lovemaking',\n",
       "  'screw',\n",
       "  'sexual_love',\n",
       "  'be_intimate',\n",
       "  'bang',\n",
       "  'eff',\n",
       "  'sleep_with',\n",
       "  'bed'],\n",
       " 'vomit_up': ['cat'],\n",
       " 'get_it_on': ['love'],\n",
       " 'enjoy': ['love'],\n",
       " 'qat': ['cat'],\n",
       " 'lovemaking': ['love'],\n",
       " 'entertain': ['nurse'],\n",
       " 'screw': ['love'],\n",
       " 'nurse': ['wet-nurse',\n",
       "  'lactate',\n",
       "  'hold',\n",
       "  'harbour',\n",
       "  'suck',\n",
       "  'harbor',\n",
       "  'entertain',\n",
       "  'suckle',\n",
       "  'nursemaid',\n",
       "  'nanny',\n",
       "  'give_suck',\n",
       "  'breastfeed'],\n",
       " 'aeroplane': ['plane'],\n",
       " 'bushel': ['doctor'],\n",
       " 'bed': ['love'],\n",
       " 'auto': ['car'],\n",
       " 'plane': ['planing_machine',\n",
       "  'flat',\n",
       "  'level',\n",
       "  'sheet',\n",
       "  \"carpenter's_plane\",\n",
       "  'skim',\n",
       "  'airplane',\n",
       "  'woodworking_plane',\n",
       "  'planer',\n",
       "  'shave',\n",
       "  'aeroplane'],\n",
       " 'erotic_love': ['love'],\n",
       " 'level': ['plane'],\n",
       " 'spew': ['cat'],\n",
       " 'turn_on': ['sex'],\n",
       " 'do_it': ['love'],\n",
       " 'flat': ['plane'],\n",
       " 'data_processor': ['computer'],\n",
       " 'railroad_car': ['car'],\n",
       " 'Doctor': ['doctor'],\n",
       " 'suckle': ['nurse'],\n",
       " 'have_sex': ['love'],\n",
       " 'repair': ['doctor'],\n",
       " 'be_sick': ['cat'],\n",
       " 'sexual_activity': ['sex'],\n",
       " 'automobile': ['car'],\n",
       " 'computerized_tomography': ['cat'],\n",
       " 'computed_axial_tomography': ['cat'],\n",
       " 'purge': ['cat'],\n",
       " 'beloved': ['love'],\n",
       " 'spue': ['cat'],\n",
       " 'dear': ['love'],\n",
       " 'love_life': ['love'],\n",
       " 'know': ['love'],\n",
       " 'have_intercourse': ['love'],\n",
       " 'sexuality': ['sex'],\n",
       " 'wet-nurse': ['nurse'],\n",
       " 'motorcar': ['car'],\n",
       " 'African_tea': ['cat'],\n",
       " 'hombre': ['cat'],\n",
       " 'kat': ['cat'],\n",
       " 'fix': ['doctor'],\n",
       " 'be_intimate': ['love'],\n",
       " 'planer': ['plane'],\n",
       " 'sex_activity': ['sex'],\n",
       " 'railcar': ['car'],\n",
       " 'sleep_with': ['love'],\n",
       " 'have_it_away': ['love'],\n",
       " 'lie_with': ['love'],\n",
       " \"carpenter's_plane\": ['plane'],\n",
       " 'skim': ['plane'],\n",
       " 'chuck': ['cat'],\n",
       " 'elevator_car': ['car'],\n",
       " 'keyboard': [],\n",
       " 'shave': ['plane'],\n",
       " 'get_laid': ['love'],\n",
       " 'have_a_go_at_it': ['love'],\n",
       " 'dearest': ['love'],\n",
       " 'estimator': ['computer'],\n",
       " 'furbish_up': ['doctor'],\n",
       " 'sheet': ['plane'],\n",
       " 'harbor': ['nurse'],\n",
       " 'computed_tomography': ['cat'],\n",
       " 'passion': ['love'],\n",
       " 'restore': ['doctor'],\n",
       " 'barf': ['cat'],\n",
       " 'upchuck': ['cat'],\n",
       " 'touch_on': ['doctor'],\n",
       " 'vomit': ['cat'],\n",
       " 'airplane': ['plane'],\n",
       " 'MD': ['doctor'],\n",
       " 'computerized_axial_tomography': ['cat'],\n",
       " 'tiger': ['Panthera_tigris'],\n",
       " 'make_love': ['love'],\n",
       " 'make_out': ['love'],\n",
       " 'quat': ['cat'],\n",
       " 'eff': ['love']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_graph_from_synonyms(synonyms_dict):\n",
    "    graph = {}\n",
    "    \n",
    "    # Create a set of all unique words in the dictionary\n",
    "    words = set(synonyms_dict.keys()).union(*synonyms_dict.values())\n",
    "    \n",
    "    # Initialize an empty adjacency dictionary for each word\n",
    "    for word in words:\n",
    "        graph[word] = set()\n",
    "    \n",
    "    # Iterate through the synonyms dictionary\n",
    "    for word, synonyms in synonyms_dict.items():\n",
    "        # Add synonyms to the adjacency set for the word\n",
    "        graph[word].update(synonyms)\n",
    "        \n",
    "        # Add the word as a synonym to each synonym's adjacency set\n",
    "        for synonym in synonyms:\n",
    "            graph[synonym].add(word)\n",
    "    \n",
    "    # Convert the adjacency sets to lists\n",
    "    graph = {word: list(adjacency_set) for word, adjacency_set in graph.items()}\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = generate_graph_from_synonyms(lexicon)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_article(Q, Q_hat, graph, alpha, beta, num_iterations=10):\n",
    "    num_words = Q.shape[0]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        Q_new = np.zeros_like(Q)\n",
    "        for i in range(num_words):\n",
    "            neighbors = graph[i]\n",
    "            numerator = np.sum(beta[i, j] * Q[j] for j in neighbors) + alpha[i] * Q_hat[i]\n",
    "            denominator = np.sum(beta[i, j] for j in neighbors) + alpha[i]\n",
    "            Q_new[i] = numerator / denominator\n",
    "        Q = Q_new\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_toy_vecs, updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newVecs = retrofitting_wordVecs_article(wordVecMat, neighbors_matrix, graph, alpha=1, beta=1, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6\n",
      "Number of edges: 5\n",
      "Neighbors of cat: ['kitten', 'animal', 'pet']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_keep = [\"cat\", \"kitten\", \"dog\", \"puppy\", \"animal\", \"pet\"]\n",
    "# Construct an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_nodes_from(words_to_keep)\n",
    "\n",
    "# Add edges between related words\n",
    "graph.add_edges_from([('cat', 'kitten'), ('dog', 'puppy'), ('cat', 'animal'), ('dog', 'animal'), ('cat', 'pet')])\n",
    "\n",
    "# Print the graph information\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Access neighbors of a word\n",
    "word = 'cat'\n",
    "neighbors = graph.neighbors(word)\n",
    "print(\"Neighbors of\", word + \":\", list(neighbors))\n",
    "\n",
    "# Create the layout for the graph\n",
    "layout = nx.spring_layout(graph)\n",
    "\n",
    "# Draw the nodes\n",
    "nx.draw_networkx_nodes(graph, pos=layout, node_color='lightblue', node_size=500)\n",
    "\n",
    "# Draw the edges\n",
    "nx.draw_networkx_edges(graph, pos=layout, edge_color='gray')\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(graph, pos=layout, font_color='black')\n",
    "\n",
    "# Set plot properties\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00338463, -0.08622685,  0.16280252, ..., -0.24678802,\n",
       "          0.1382305 , -0.00531627],\n",
       "        [ 0.08007812, -0.06433105,  0.02783203, ..., -0.08123779,\n",
       "          0.03717041, -0.03466797],\n",
       "        [ 0.00255203,  0.02276611, -0.13401031, ..., -0.07601929,\n",
       "          0.05496216,  0.07133484],\n",
       "        ...,\n",
       "        [ 0.04763455,  0.11241319, -0.07042948, ..., -0.00129022,\n",
       "         -0.09945594, -0.13053046],\n",
       "        [-0.03367829,  0.04928064, -0.00994873, ...,  0.08418322,\n",
       "          0.06436348,  0.01234341],\n",
       "        [ 0.04439545, -0.02075195,  0.11517334, ..., -0.06329346,\n",
       "          0.06408691, -0.06994629]]),\n",
       " array([[-0.00169231, -0.04311343,  0.08140126, ..., -0.12339401,\n",
       "          0.06911525, -0.00265814],\n",
       "        [ 0.04003906, -0.03216553,  0.01391602, ..., -0.0406189 ,\n",
       "          0.01858521, -0.01733398],\n",
       "        [ 0.00127602,  0.01138306, -0.06700516, ..., -0.03800964,\n",
       "          0.02748108,  0.03566742],\n",
       "        ...,\n",
       "        [ 0.02381727,  0.0562066 , -0.03521474, ..., -0.00064511,\n",
       "         -0.04972797, -0.06526523],\n",
       "        [-0.01683915,  0.02464032, -0.00497437, ...,  0.04209161,\n",
       "          0.03218174,  0.0061717 ],\n",
       "        [ 0.02219772, -0.01037598,  0.05758667, ..., -0.03164673,\n",
       "          0.03204346, -0.03497314]]),\n",
       " array([[-0.00084616, -0.02155671,  0.04070063, ..., -0.06169701,\n",
       "          0.03455763, -0.00132907],\n",
       "        [ 0.02001953, -0.01608276,  0.00695801, ..., -0.02030945,\n",
       "          0.0092926 , -0.00866699],\n",
       "        [ 0.00063801,  0.00569153, -0.03350258, ..., -0.01900482,\n",
       "          0.01374054,  0.01783371],\n",
       "        ...,\n",
       "        [ 0.01190864,  0.0281033 , -0.01760737, ..., -0.00032255,\n",
       "         -0.02486398, -0.03263262],\n",
       "        [-0.00841957,  0.01232016, -0.00248718, ...,  0.0210458 ,\n",
       "          0.01609087,  0.00308585],\n",
       "        [ 0.01109886, -0.00518799,  0.02879333, ..., -0.01582336,\n",
       "          0.01602173, -0.01748657]]),\n",
       " array([[-0.00042308, -0.01077836,  0.02035031, ..., -0.0308485 ,\n",
       "          0.01727881, -0.00066453],\n",
       "        [ 0.01000977, -0.00804138,  0.003479  , ..., -0.01015472,\n",
       "          0.0046463 , -0.0043335 ],\n",
       "        [ 0.000319  ,  0.00284576, -0.01675129, ..., -0.00950241,\n",
       "          0.00687027,  0.00891685],\n",
       "        ...,\n",
       "        [ 0.00595432,  0.01405165, -0.00880369, ..., -0.00016128,\n",
       "         -0.01243199, -0.01631631],\n",
       "        [-0.00420979,  0.00616008, -0.00124359, ...,  0.0105229 ,\n",
       "          0.00804543,  0.00154293],\n",
       "        [ 0.00554943, -0.00259399,  0.01439667, ..., -0.00791168,\n",
       "          0.00801086, -0.00874329]]),\n",
       " array([[-2.11539096e-04, -5.38917829e-03,  1.01751575e-02, ...,\n",
       "         -1.54242516e-02,  8.63940627e-03, -3.32267140e-04],\n",
       "        [ 5.00488281e-03, -4.02069092e-03,  1.73950195e-03, ...,\n",
       "         -5.07736206e-03,  2.32315063e-03, -2.16674805e-03],\n",
       "        [ 1.59502029e-04,  1.42288208e-03, -8.37564468e-03, ...,\n",
       "         -4.75120544e-03,  3.43513489e-03,  4.45842743e-03],\n",
       "        ...,\n",
       "        [ 2.97715928e-03,  7.02582463e-03, -4.40184260e-03, ...,\n",
       "         -8.06384487e-05, -6.21599623e-03, -8.15815385e-03],\n",
       "        [-2.10489333e-03,  3.08004022e-03, -6.21795654e-04, ...,\n",
       "          5.26145101e-03,  4.02271748e-03,  7.71462917e-04],\n",
       "        [ 2.77471542e-03, -1.29699707e-03,  7.19833374e-03, ...,\n",
       "         -3.95584106e-03,  4.00543213e-03, -4.37164307e-03]]),\n",
       " array([[-1.05769548e-04, -2.69458914e-03,  5.08757873e-03, ...,\n",
       "         -7.71212578e-03,  4.31970314e-03, -1.66133570e-04],\n",
       "        [ 2.50244141e-03, -2.01034546e-03,  8.69750977e-04, ...,\n",
       "         -2.53868103e-03,  1.16157532e-03, -1.08337402e-03],\n",
       "        [ 7.97510147e-05,  7.11441040e-04, -4.18782234e-03, ...,\n",
       "         -2.37560272e-03,  1.71756744e-03,  2.22921371e-03],\n",
       "        ...,\n",
       "        [ 1.48857964e-03,  3.51291231e-03, -2.20092130e-03, ...,\n",
       "         -4.03192244e-05, -3.10799811e-03, -4.07907693e-03],\n",
       "        [-1.05244666e-03,  1.54002011e-03, -3.10897827e-04, ...,\n",
       "          2.63072550e-03,  2.01135874e-03,  3.85731459e-04],\n",
       "        [ 1.38735771e-03, -6.48498535e-04,  3.59916687e-03, ...,\n",
       "         -1.97792053e-03,  2.00271606e-03, -2.18582153e-03]]),\n",
       " array([[-5.28847740e-05, -1.34729457e-03,  2.54378936e-03, ...,\n",
       "         -3.85606289e-03,  2.15985157e-03, -8.30667850e-05],\n",
       "        [ 1.25122070e-03, -1.00517273e-03,  4.34875488e-04, ...,\n",
       "         -1.26934052e-03,  5.80787659e-04, -5.41687012e-04],\n",
       "        [ 3.98755074e-05,  3.55720520e-04, -2.09391117e-03, ...,\n",
       "         -1.18780136e-03,  8.58783722e-04,  1.11460686e-03],\n",
       "        ...,\n",
       "        [ 7.44289820e-04,  1.75645616e-03, -1.10046065e-03, ...,\n",
       "         -2.01596122e-05, -1.55399906e-03, -2.03953846e-03],\n",
       "        [-5.26223332e-04,  7.70010054e-04, -1.55448914e-04, ...,\n",
       "          1.31536275e-03,  1.00567937e-03,  1.92865729e-04],\n",
       "        [ 6.93678856e-04, -3.24249268e-04,  1.79958344e-03, ...,\n",
       "         -9.88960266e-04,  1.00135803e-03, -1.09291077e-03]]),\n",
       " array([[-2.64423870e-05, -6.73647286e-04,  1.27189468e-03, ...,\n",
       "         -1.92803144e-03,  1.07992578e-03, -4.15333925e-05],\n",
       "        [ 6.25610352e-04, -5.02586365e-04,  2.17437744e-04, ...,\n",
       "         -6.34670258e-04,  2.90393829e-04, -2.70843506e-04],\n",
       "        [ 1.99377537e-05,  1.77860260e-04, -1.04695559e-03, ...,\n",
       "         -5.93900681e-04,  4.29391861e-04,  5.57303429e-04],\n",
       "        ...,\n",
       "        [ 3.72144910e-04,  8.78228078e-04, -5.50230325e-04, ...,\n",
       "         -1.00798061e-05, -7.76999528e-04, -1.01976923e-03],\n",
       "        [-2.63111666e-04,  3.85005027e-04, -7.77244568e-05, ...,\n",
       "          6.57681376e-04,  5.02839684e-04,  9.64328647e-05],\n",
       "        [ 3.46839428e-04, -1.62124634e-04,  8.99791718e-04, ...,\n",
       "         -4.94480133e-04,  5.00679016e-04, -5.46455383e-04]]),\n",
       " array([[-1.32211935e-05, -3.36823643e-04,  6.35947341e-04, ...,\n",
       "         -9.64015722e-04,  5.39962892e-04, -2.07666963e-05],\n",
       "        [ 3.12805176e-04, -2.51293182e-04,  1.08718872e-04, ...,\n",
       "         -3.17335129e-04,  1.45196915e-04, -1.35421753e-04],\n",
       "        [ 9.96887684e-06,  8.89301300e-05, -5.23477793e-04, ...,\n",
       "         -2.96950340e-04,  2.14695930e-04,  2.78651714e-04],\n",
       "        ...,\n",
       "        [ 1.86072455e-04,  4.39114039e-04, -2.75115162e-04, ...,\n",
       "         -5.03990304e-06, -3.88499764e-04, -5.09884616e-04],\n",
       "        [-1.31555833e-04,  1.92502514e-04, -3.88622284e-05, ...,\n",
       "          3.28840688e-04,  2.51419842e-04,  4.82164323e-05],\n",
       "        [ 1.73419714e-04, -8.10623169e-05,  4.49895859e-04, ...,\n",
       "         -2.47240067e-04,  2.50339508e-04, -2.73227692e-04]]),\n",
       " array([[-6.61059676e-06, -1.68411822e-04,  3.17973670e-04, ...,\n",
       "         -4.82007861e-04,  2.69981446e-04, -1.03833481e-05],\n",
       "        [ 1.56402588e-04, -1.25646591e-04,  5.43594360e-05, ...,\n",
       "         -1.58667564e-04,  7.25984573e-05, -6.77108765e-05],\n",
       "        [ 4.98443842e-06,  4.44650650e-05, -2.61738896e-04, ...,\n",
       "         -1.48475170e-04,  1.07347965e-04,  1.39325857e-04],\n",
       "        ...,\n",
       "        [ 9.30362276e-05,  2.19557020e-04, -1.37557581e-04, ...,\n",
       "         -2.51995152e-06, -1.94249882e-04, -2.54942308e-04],\n",
       "        [-6.57779165e-05,  9.62512568e-05, -1.94311142e-05, ...,\n",
       "          1.64420344e-04,  1.25709921e-04,  2.41082162e-05],\n",
       "        [ 8.67098570e-05, -4.05311584e-05,  2.24947929e-04, ...,\n",
       "         -1.23620033e-04,  1.25169754e-04, -1.36613846e-04]])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrofitted_toy_matrix = convert_dict_to_matrix(retrofitted_toy_vecs)\n",
    "retrofitted_similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, retrofitted_similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172961950302124"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrofitted_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"car\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"love\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"car\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"love\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"car\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"love\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"computer\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"car\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"love\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"love\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"plane\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"love\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"car\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"love\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"car\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"car\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "  - \"car\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "  - \"love\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "def print_vec_difference(wordList, similarity_matrix1, similarity_matrix2):\n",
    "    for i, word in enumerate(wordList):\n",
    "        print(f\"\\nSimilarities with \\\"{word}\\\":\")\n",
    "        for j, neighbor in enumerate(wordList):\n",
    "            similarity1 = similarity_matrix1[i, j]\n",
    "            similarity2 = similarity_matrix2[i, j]\n",
    "            difference = similarity2 - similarity1  # Calculate the difference\n",
    "            print(f\"  - \\\"{neighbor}\\\": {similarity1:.4f} -> {similarity2:.4f} (Difference: {difference:.4f})\")\n",
    "\n",
    "print_vec_difference(toy_corpus, similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Difference Matrix:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between wordVecMat and retrofitted_toy_vec\n",
    "# similarity_score = cosine_similarity_matrix(wordVecMat, retrofitted_toy_vecs)\n",
    "# print(\"Cosine Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average embedding update: 0.12658860989283166\n"
     ]
    }
   ],
   "source": [
    "def measure_embedding_updates(original_matrix, retrofitted_matrix):\n",
    "    absolute_diff = np.abs(original_matrix - retrofitted_matrix)\n",
    "    mean_absolute_diff = np.mean(absolute_diff)\n",
    "    return mean_absolute_diff\n",
    "\n",
    "# Example usage\n",
    "update_measure = measure_embedding_updates(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Average embedding update:\", update_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation score: 0.42055888661904023\n",
      "Pearson correlation score: 0.4232245375810048\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def spearman_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = spearmanr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "def pearson_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "similarity_score = spearman_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Spearman correlation score:\", similarity_score)\n",
    "similarity_score = pearson_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Pearson correlation score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 0.1, 'nb_iter': 1}\n",
      "Best Spearman correlation score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load human evaluation scores\n",
    "eval_file_path = r\"C:\\Users\\ninan\\OneDrive\\Bureau\\Université Paris Cité\\S2\\NLP project\\Improving-vector-space-representations-using-semantic-resources\\data\\English\\lexicon\\ws353_lexical_similarity.txt\"\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Find best values for hyperparameters\n",
    "best_similarity_score = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "iteration_count = 0\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1, 16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            cosine_sim = cosine_similarity(wordVecMat, retrofitted_toy_vec)\n",
    "\n",
    "            # Calculate Spearman correlation against human evaluation scores\n",
    "            eval_scores_list = []\n",
    "            cosine_sim_list = []\n",
    "            for (word1, word2), score in eval_scores.items():\n",
    "                if word1 in wordList and word2 in wordList:\n",
    "                    word1_index = wordList.index(word1)\n",
    "                    word2_index = wordList.index(word2)\n",
    "                    eval_scores_list.append(score)\n",
    "                    cosine_sim_list.append(cosine_sim[word1_index, word2_index])\n",
    "\n",
    "            # Check if there are valid pairs for comparison\n",
    "            if len(eval_scores_list) > 0 and len(cosine_sim_list) > 0:\n",
    "                correlation, _ = spearmanr(eval_scores_list, cosine_sim_list)\n",
    "                # print(\"alpha =\", alpha, \"beta =\", beta, \"nb_iter =\", nb_iter, \"correlation =\", correlation)\n",
    "\n",
    "                # Update best similarity score and parameters if improved\n",
    "                if correlation > best_similarity_score:\n",
    "                    best_similarity_score = correlation\n",
    "                    best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "            iteration_count += 1\n",
    "            if iteration_count >= 100:\n",
    "                break\n",
    "        if iteration_count >= 100:\n",
    "            break\n",
    "    if iteration_count >= 100:\n",
    "        break\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best Spearman correlation score:\", best_similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 1.1000000000000003, 'nb_iter': 15}\n",
      "Best embedding update: 0.12671235242449622\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters\n",
    "best_embed_update = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1,16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            embed_update = measure_embedding_updates(wordVecMat, retrofitted_toy_vec)\n",
    "            # print(\" alpha =\", alpha, \" beta=\", beta, \"nb_iter =\", nb_iter, \" similarity score =\", similarity_score)\n",
    "            if embed_update > best_embed_update:\n",
    "                best_embed_update = embed_update\n",
    "                best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best embedding update:\", best_embed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5134\n",
      "  - \"computer\": 0.2147\n",
      "  - \"keyboard\": 0.2270\n",
      "  - \"plane\": 0.2878\n",
      "  - \"car\": 0.2492\n",
      "  - \"doctor\": 0.2437\n",
      "  - \"nurse\": 0.3233\n",
      "  - \"love\": 0.3254\n",
      "  - \"sex\": 0.2202\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5134\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0783\n",
      "  - \"keyboard\": 0.1118\n",
      "  - \"plane\": 0.1769\n",
      "  - \"car\": 0.1518\n",
      "  - \"doctor\": 0.0866\n",
      "  - \"nurse\": 0.1714\n",
      "  - \"love\": 0.1518\n",
      "  - \"sex\": 0.2417\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.2147\n",
      "  - \"tiger\": 0.0783\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.4058\n",
      "  - \"plane\": 0.2883\n",
      "  - \"car\": 0.3039\n",
      "  - \"doctor\": 0.2093\n",
      "  - \"nurse\": 0.2180\n",
      "  - \"love\": 0.1358\n",
      "  - \"sex\": 0.1602\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2270\n",
      "  - \"tiger\": 0.1118\n",
      "  - \"computer\": 0.4058\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1872\n",
      "  - \"car\": 0.1700\n",
      "  - \"doctor\": 0.1131\n",
      "  - \"nurse\": 0.1637\n",
      "  - \"love\": 0.2198\n",
      "  - \"sex\": 0.1140\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.2878\n",
      "  - \"tiger\": 0.1769\n",
      "  - \"computer\": 0.2883\n",
      "  - \"keyboard\": 0.1872\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.4366\n",
      "  - \"doctor\": 0.2202\n",
      "  - \"nurse\": 0.1756\n",
      "  - \"love\": 0.1935\n",
      "  - \"sex\": 0.0994\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2492\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.3039\n",
      "  - \"keyboard\": 0.1700\n",
      "  - \"plane\": 0.4366\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1865\n",
      "  - \"nurse\": 0.1453\n",
      "  - \"love\": 0.1766\n",
      "  - \"sex\": 0.1273\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.2437\n",
      "  - \"tiger\": 0.0866\n",
      "  - \"computer\": 0.2093\n",
      "  - \"keyboard\": 0.1131\n",
      "  - \"plane\": 0.2202\n",
      "  - \"car\": 0.1865\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6105\n",
      "  - \"love\": 0.1844\n",
      "  - \"sex\": 0.1923\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.3233\n",
      "  - \"tiger\": 0.1714\n",
      "  - \"computer\": 0.2180\n",
      "  - \"keyboard\": 0.1637\n",
      "  - \"plane\": 0.1756\n",
      "  - \"car\": 0.1453\n",
      "  - \"doctor\": 0.6105\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.2675\n",
      "  - \"sex\": 0.3084\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.3254\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.1358\n",
      "  - \"keyboard\": 0.2198\n",
      "  - \"plane\": 0.1935\n",
      "  - \"car\": 0.1766\n",
      "  - \"doctor\": 0.1844\n",
      "  - \"nurse\": 0.2675\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.3760\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2202\n",
      "  - \"tiger\": 0.2417\n",
      "  - \"computer\": 0.1602\n",
      "  - \"keyboard\": 0.1140\n",
      "  - \"plane\": 0.0994\n",
      "  - \"car\": 0.1273\n",
      "  - \"doctor\": 0.1923\n",
      "  - \"nurse\": 0.3084\n",
      "  - \"love\": 0.3760\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_retrofitted_toy_matrix, new_updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=0.1, beta=0.1, nb_iter=1)\n",
    "new_retrofitted_toy_dict = convert_matrix_to_dict(new_retrofitted_toy_matrix, wordList)\n",
    "new_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(new_retrofitted_toy_dict)\n",
    "print_vec_similarities(toy_corpus, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between original and after tuning hyperparam\n",
    "print_vec_difference(toy_corpus, similarity_matrix, new_retrofitted_similarity_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between retrofitted embeddings and after tuning hyperaparams\n",
    "print_vec_difference(toy_corpus, retrofitted_similarity_matrix, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>Before: 0.29245239862991185, After: 1.00000000...</td>\n",
       "      <td>Before: 0.35037322527996934, After: 0.20200897...</td>\n",
       "      <td>Before: 0.06136659928459301, After: 0.19719178...</td>\n",
       "      <td>Before: 0.18344955625364173, After: 0.20547455...</td>\n",
       "      <td>Before: 0.21134097025538556, After: 0.39445950...</td>\n",
       "      <td>Before: 0.136072027917602, After: 0.2634861035...</td>\n",
       "      <td>Before: 0.16547475026405636, After: 0.34338708...</td>\n",
       "      <td>Before: 0.24690899138830727, After: 0.54854860...</td>\n",
       "      <td>Before: 0.2989067535773432, After: 0.594053102...</td>\n",
       "      <td>Before: 0.1093022564011111, After: 0.259890845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Before: 0.17347637872059773, After: 0.20200897...</td>\n",
       "      <td>Before: 0.48802072485209846, After: 1.00000000...</td>\n",
       "      <td>Before: 0.02942476361382193, After: 0.09025702...</td>\n",
       "      <td>Before: 0.06542581824273716, After: 0.18313975...</td>\n",
       "      <td>Before: 0.15090617196611955, After: 0.07307479...</td>\n",
       "      <td>Before: 0.16119598769364896, After: 0.10033040...</td>\n",
       "      <td>Before: 0.0774108002811773, After: 0.089083542...</td>\n",
       "      <td>Before: 0.1697249630498177, After: 0.202597136...</td>\n",
       "      <td>Before: 0.17516455047450735, After: 0.19102605...</td>\n",
       "      <td>Before: 0.14518818082220147, After: 0.18807845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>Before: 0.18984798734723213, After: 0.19719178...</td>\n",
       "      <td>Before: 0.05360514929979338, After: 0.09025702...</td>\n",
       "      <td>Before: 0.3047689400402037, After: 1.0</td>\n",
       "      <td>Before: 0.39639163439495995, After: 0.23934215...</td>\n",
       "      <td>Before: 0.28314903703275535, After: 0.40858220...</td>\n",
       "      <td>Before: 0.26826894486108244, After: 0.22732308...</td>\n",
       "      <td>Before: 0.18039329196329013, After: 0.20986951...</td>\n",
       "      <td>Before: 0.09297679298707379, After: 0.12068024...</td>\n",
       "      <td>Before: 0.1168711356729625, After: 0.234808759...</td>\n",
       "      <td>Before: 0.1158779845883439, After: 0.076953257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>Before: 0.20546589125510897, After: 0.20547455...</td>\n",
       "      <td>Before: 0.18314156317766062, After: 0.18313975...</td>\n",
       "      <td>Before: 0.2393287663091698, After: 0.239342157...</td>\n",
       "      <td>Before: 0.9999999999999996, After: 1.0</td>\n",
       "      <td>Before: 0.28971014677665063, After: 0.28970944...</td>\n",
       "      <td>Before: 0.15750632650840493, After: 0.15750846...</td>\n",
       "      <td>Before: 0.13804955762057758, After: 0.13804958...</td>\n",
       "      <td>Before: 0.16678031434047627, After: 0.16678347...</td>\n",
       "      <td>Before: 0.27407501845767246, After: 0.27407454...</td>\n",
       "      <td>Before: 0.10639718565916091, After: 0.10639914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>Before: 0.16761576142114898, After: 0.39445950...</td>\n",
       "      <td>Before: 0.06730278214710199, After: 0.07307479...</td>\n",
       "      <td>Before: 0.06606645196552532, After: 0.40858220...</td>\n",
       "      <td>Before: 0.10055138151211143, After: 0.28970944...</td>\n",
       "      <td>Before: 0.38405259310022044, After: 1.00000000...</td>\n",
       "      <td>Before: 0.3219357387657039, After: 0.354037032...</td>\n",
       "      <td>Before: 0.15146728859985834, After: 0.21833826...</td>\n",
       "      <td>Before: 0.10589313234551631, After: 0.28236372...</td>\n",
       "      <td>Before: 0.1936940498815496, After: 0.328525840...</td>\n",
       "      <td>Before: 0.05697047025775614, After: 0.11862340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>Before: 0.15859645192729996, After: 0.26348610...</td>\n",
       "      <td>Before: -0.049076379792710186, After: 0.100330...</td>\n",
       "      <td>Before: 0.13968323112249992, After: 0.22732308...</td>\n",
       "      <td>Before: 0.14983822223318854, After: 0.15750846...</td>\n",
       "      <td>Before: 0.2597415410728325, After: 0.354037032...</td>\n",
       "      <td>Before: 0.6158574248530795, After: 1.000000000...</td>\n",
       "      <td>Before: 0.13778205919388814, After: 0.19190468...</td>\n",
       "      <td>Before: 0.0865221800713605, After: 0.160778501...</td>\n",
       "      <td>Before: 0.22133439390681858, After: 0.24947266...</td>\n",
       "      <td>Before: 0.059270287407368415, After: 0.0662935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>Before: 0.25878907406446877, After: 0.34338708...</td>\n",
       "      <td>Before: 0.017639064485218965, After: 0.0890835...</td>\n",
       "      <td>Before: 0.0978054983995635, After: 0.209869514...</td>\n",
       "      <td>Before: 0.08500327165730943, After: 0.13804958...</td>\n",
       "      <td>Before: 0.13439994429915442, After: 0.21833826...</td>\n",
       "      <td>Before: 0.09431570687955, After: 0.19190468704...</td>\n",
       "      <td>Before: 0.6128107065755533, After: 1.0</td>\n",
       "      <td>Before: 0.27845097194129365, After: 0.34448646...</td>\n",
       "      <td>Before: 0.19325643013428553, After: 0.33078374...</td>\n",
       "      <td>Before: 0.0745189116843016, After: 0.175547118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>Before: 0.18217682480604822, After: 0.54854860...</td>\n",
       "      <td>Before: 0.07222178145580241, After: 0.20259713...</td>\n",
       "      <td>Before: 0.11697573887301807, After: 0.12068024...</td>\n",
       "      <td>Before: 0.12199094008346709, After: 0.16678347...</td>\n",
       "      <td>Before: 0.12790409339777273, After: 0.28236372...</td>\n",
       "      <td>Before: 0.07363428182232754, After: 0.16077850...</td>\n",
       "      <td>Before: 0.4308149649767604, After: 0.344486463...</td>\n",
       "      <td>Before: 0.378466332225932, After: 1.0000000000...</td>\n",
       "      <td>Before: 0.1708752362535986, After: 0.544714533...</td>\n",
       "      <td>Before: 0.1264203000118017, After: 0.409129275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>Before: 0.241072229246228, After: 0.5940531024...</td>\n",
       "      <td>Before: 0.10199943514005788, After: 0.19102605...</td>\n",
       "      <td>Before: 0.0730022470894344, After: 0.234808759...</td>\n",
       "      <td>Before: 0.15911448638969528, After: 0.27407454...</td>\n",
       "      <td>Before: 0.09505575751009387, After: 0.32852584...</td>\n",
       "      <td>Before: 0.11200247669649024, After: 0.24947266...</td>\n",
       "      <td>Before: 0.14771102908578468, After: 0.33078374...</td>\n",
       "      <td>Before: 0.3033847603340788, After: 0.544714533...</td>\n",
       "      <td>Before: 0.6110191309495465, After: 0.999999999...</td>\n",
       "      <td>Before: 0.30399420253175347, After: 0.36164712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>Before: 0.225917972105598, After: 0.2598908452...</td>\n",
       "      <td>Before: 0.1655264826766013, After: 0.188078452...</td>\n",
       "      <td>Before: 0.036750539503579295, After: 0.0769532...</td>\n",
       "      <td>Before: 0.09429740737651135, After: 0.10639914...</td>\n",
       "      <td>Before: 0.10212970436490482, After: 0.11862340...</td>\n",
       "      <td>Before: 0.13403080874265905, After: 0.06629354...</td>\n",
       "      <td>Before: 0.1436405909297276, After: 0.175547118...</td>\n",
       "      <td>Before: 0.26868181343357167, After: 0.40912927...</td>\n",
       "      <td>Before: 0.3049306009871644, After: 0.361647126...</td>\n",
       "      <td>Before: 0.4896246955281065, After: 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        cat  \\\n",
       "cat       Before: 0.29245239862991185, After: 1.00000000...   \n",
       "tiger     Before: 0.17347637872059773, After: 0.20200897...   \n",
       "computer  Before: 0.18984798734723213, After: 0.19719178...   \n",
       "keyboard  Before: 0.20546589125510897, After: 0.20547455...   \n",
       "plane     Before: 0.16761576142114898, After: 0.39445950...   \n",
       "car       Before: 0.15859645192729996, After: 0.26348610...   \n",
       "doctor    Before: 0.25878907406446877, After: 0.34338708...   \n",
       "nurse     Before: 0.18217682480604822, After: 0.54854860...   \n",
       "love      Before: 0.241072229246228, After: 0.5940531024...   \n",
       "sex       Before: 0.225917972105598, After: 0.2598908452...   \n",
       "\n",
       "                                                      tiger  \\\n",
       "cat       Before: 0.35037322527996934, After: 0.20200897...   \n",
       "tiger     Before: 0.48802072485209846, After: 1.00000000...   \n",
       "computer  Before: 0.05360514929979338, After: 0.09025702...   \n",
       "keyboard  Before: 0.18314156317766062, After: 0.18313975...   \n",
       "plane     Before: 0.06730278214710199, After: 0.07307479...   \n",
       "car       Before: -0.049076379792710186, After: 0.100330...   \n",
       "doctor    Before: 0.017639064485218965, After: 0.0890835...   \n",
       "nurse     Before: 0.07222178145580241, After: 0.20259713...   \n",
       "love      Before: 0.10199943514005788, After: 0.19102605...   \n",
       "sex       Before: 0.1655264826766013, After: 0.188078452...   \n",
       "\n",
       "                                                   computer  \\\n",
       "cat       Before: 0.06136659928459301, After: 0.19719178...   \n",
       "tiger     Before: 0.02942476361382193, After: 0.09025702...   \n",
       "computer             Before: 0.3047689400402037, After: 1.0   \n",
       "keyboard  Before: 0.2393287663091698, After: 0.239342157...   \n",
       "plane     Before: 0.06606645196552532, After: 0.40858220...   \n",
       "car       Before: 0.13968323112249992, After: 0.22732308...   \n",
       "doctor    Before: 0.0978054983995635, After: 0.209869514...   \n",
       "nurse     Before: 0.11697573887301807, After: 0.12068024...   \n",
       "love      Before: 0.0730022470894344, After: 0.234808759...   \n",
       "sex       Before: 0.036750539503579295, After: 0.0769532...   \n",
       "\n",
       "                                                   keyboard  \\\n",
       "cat       Before: 0.18344955625364173, After: 0.20547455...   \n",
       "tiger     Before: 0.06542581824273716, After: 0.18313975...   \n",
       "computer  Before: 0.39639163439495995, After: 0.23934215...   \n",
       "keyboard             Before: 0.9999999999999996, After: 1.0   \n",
       "plane     Before: 0.10055138151211143, After: 0.28970944...   \n",
       "car       Before: 0.14983822223318854, After: 0.15750846...   \n",
       "doctor    Before: 0.08500327165730943, After: 0.13804958...   \n",
       "nurse     Before: 0.12199094008346709, After: 0.16678347...   \n",
       "love      Before: 0.15911448638969528, After: 0.27407454...   \n",
       "sex       Before: 0.09429740737651135, After: 0.10639914...   \n",
       "\n",
       "                                                      plane  \\\n",
       "cat       Before: 0.21134097025538556, After: 0.39445950...   \n",
       "tiger     Before: 0.15090617196611955, After: 0.07307479...   \n",
       "computer  Before: 0.28314903703275535, After: 0.40858220...   \n",
       "keyboard  Before: 0.28971014677665063, After: 0.28970944...   \n",
       "plane     Before: 0.38405259310022044, After: 1.00000000...   \n",
       "car       Before: 0.2597415410728325, After: 0.354037032...   \n",
       "doctor    Before: 0.13439994429915442, After: 0.21833826...   \n",
       "nurse     Before: 0.12790409339777273, After: 0.28236372...   \n",
       "love      Before: 0.09505575751009387, After: 0.32852584...   \n",
       "sex       Before: 0.10212970436490482, After: 0.11862340...   \n",
       "\n",
       "                                                        car  \\\n",
       "cat       Before: 0.136072027917602, After: 0.2634861035...   \n",
       "tiger     Before: 0.16119598769364896, After: 0.10033040...   \n",
       "computer  Before: 0.26826894486108244, After: 0.22732308...   \n",
       "keyboard  Before: 0.15750632650840493, After: 0.15750846...   \n",
       "plane     Before: 0.3219357387657039, After: 0.354037032...   \n",
       "car       Before: 0.6158574248530795, After: 1.000000000...   \n",
       "doctor    Before: 0.09431570687955, After: 0.19190468704...   \n",
       "nurse     Before: 0.07363428182232754, After: 0.16077850...   \n",
       "love      Before: 0.11200247669649024, After: 0.24947266...   \n",
       "sex       Before: 0.13403080874265905, After: 0.06629354...   \n",
       "\n",
       "                                                     doctor  \\\n",
       "cat       Before: 0.16547475026405636, After: 0.34338708...   \n",
       "tiger     Before: 0.0774108002811773, After: 0.089083542...   \n",
       "computer  Before: 0.18039329196329013, After: 0.20986951...   \n",
       "keyboard  Before: 0.13804955762057758, After: 0.13804958...   \n",
       "plane     Before: 0.15146728859985834, After: 0.21833826...   \n",
       "car       Before: 0.13778205919388814, After: 0.19190468...   \n",
       "doctor               Before: 0.6128107065755533, After: 1.0   \n",
       "nurse     Before: 0.4308149649767604, After: 0.344486463...   \n",
       "love      Before: 0.14771102908578468, After: 0.33078374...   \n",
       "sex       Before: 0.1436405909297276, After: 0.175547118...   \n",
       "\n",
       "                                                      nurse  \\\n",
       "cat       Before: 0.24690899138830727, After: 0.54854860...   \n",
       "tiger     Before: 0.1697249630498177, After: 0.202597136...   \n",
       "computer  Before: 0.09297679298707379, After: 0.12068024...   \n",
       "keyboard  Before: 0.16678031434047627, After: 0.16678347...   \n",
       "plane     Before: 0.10589313234551631, After: 0.28236372...   \n",
       "car       Before: 0.0865221800713605, After: 0.160778501...   \n",
       "doctor    Before: 0.27845097194129365, After: 0.34448646...   \n",
       "nurse     Before: 0.378466332225932, After: 1.0000000000...   \n",
       "love      Before: 0.3033847603340788, After: 0.544714533...   \n",
       "sex       Before: 0.26868181343357167, After: 0.40912927...   \n",
       "\n",
       "                                                       love  \\\n",
       "cat       Before: 0.2989067535773432, After: 0.594053102...   \n",
       "tiger     Before: 0.17516455047450735, After: 0.19102605...   \n",
       "computer  Before: 0.1168711356729625, After: 0.234808759...   \n",
       "keyboard  Before: 0.27407501845767246, After: 0.27407454...   \n",
       "plane     Before: 0.1936940498815496, After: 0.328525840...   \n",
       "car       Before: 0.22133439390681858, After: 0.24947266...   \n",
       "doctor    Before: 0.19325643013428553, After: 0.33078374...   \n",
       "nurse     Before: 0.1708752362535986, After: 0.544714533...   \n",
       "love      Before: 0.6110191309495465, After: 0.999999999...   \n",
       "sex       Before: 0.3049306009871644, After: 0.361647126...   \n",
       "\n",
       "                                                        sex  \n",
       "cat       Before: 0.1093022564011111, After: 0.259890845...  \n",
       "tiger     Before: 0.14518818082220147, After: 0.18807845...  \n",
       "computer  Before: 0.1158779845883439, After: 0.076953257...  \n",
       "keyboard  Before: 0.10639718565916091, After: 0.10639914...  \n",
       "plane     Before: 0.05697047025775614, After: 0.11862340...  \n",
       "car       Before: 0.059270287407368415, After: 0.0662935...  \n",
       "doctor    Before: 0.0745189116843016, After: 0.175547118...  \n",
       "nurse     Before: 0.1264203000118017, After: 0.409129275...  \n",
       "love      Before: 0.30399420253175347, After: 0.36164712...  \n",
       "sex                  Before: 0.4896246955281065, After: 1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score before retrofitting\n",
    "        similarity_before = cosine_sim[word1_index, word2_index]\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Before: {similarity_before}, After: {similarity_after}\"\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Retrofitting: 0.20, Human: 0.73</td>\n",
       "      <td>Retrofitting: 1.00, Human: 1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.24, Human: 0.76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.35, Human: 0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.34, Human: 0.70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.36, Human: 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cat                            tiger  \\\n",
       "cat                                  None                             None   \n",
       "tiger     Retrofitting: 0.20, Human: 0.73  Retrofitting: 1.00, Human: 1.00   \n",
       "computer                             None                             None   \n",
       "keyboard                             None                             None   \n",
       "plane                                None                             None   \n",
       "car                                  None                             None   \n",
       "doctor                               None                             None   \n",
       "nurse                                None                             None   \n",
       "love                                 None                             None   \n",
       "sex                                  None                             None   \n",
       "\n",
       "         computer                         keyboard plane  \\\n",
       "cat          None                             None  None   \n",
       "tiger        None                             None  None   \n",
       "computer     None  Retrofitting: 0.24, Human: 0.76  None   \n",
       "keyboard     None                             None  None   \n",
       "plane        None                             None  None   \n",
       "car          None                             None  None   \n",
       "doctor       None                             None  None   \n",
       "nurse        None                             None  None   \n",
       "love         None                             None  None   \n",
       "sex          None                             None  None   \n",
       "\n",
       "                                      car doctor  \\\n",
       "cat                                  None   None   \n",
       "tiger                                None   None   \n",
       "computer                             None   None   \n",
       "keyboard                             None   None   \n",
       "plane     Retrofitting: 0.35, Human: 0.58   None   \n",
       "car                                  None   None   \n",
       "doctor                               None   None   \n",
       "nurse                                None   None   \n",
       "love                                 None   None   \n",
       "sex                                  None   None   \n",
       "\n",
       "                                    nurse  love  \\\n",
       "cat                                  None  None   \n",
       "tiger                                None  None   \n",
       "computer                             None  None   \n",
       "keyboard                             None  None   \n",
       "plane                                None  None   \n",
       "car                                  None  None   \n",
       "doctor    Retrofitting: 0.34, Human: 0.70  None   \n",
       "nurse                                None  None   \n",
       "love                                 None  None   \n",
       "sex                                  None  None   \n",
       "\n",
       "                                      sex  \n",
       "cat                                  None  \n",
       "tiger                                None  \n",
       "computer                             None  \n",
       "keyboard                             None  \n",
       "plane                                None  \n",
       "car                                  None  \n",
       "doctor                               None  \n",
       "nurse                                None  \n",
       "love      Retrofitting: 0.36, Human: 0.68  \n",
       "sex                                  None  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation scores from the file\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as eval_file:\n",
    "    for line in eval_file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Retrieve the evaluation score for the word pair\n",
    "        score = eval_scores.get((word1, word2))\n",
    "\n",
    "        # Scale the human score between 0 and 1\n",
    "        if score is not None:\n",
    "            scaled_score = score / 10.0\n",
    "        else:\n",
    "            scaled_score = None\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Retrofitting: {similarity_after:.2f}, Human: {scaled_score:.2f}\" if scaled_score is not None else None\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n"
     ]
    }
   ],
   "source": [
    "wordVecs_gensim = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "lexical_similarity = read_lexicon(\"../data/English/lexicon/ws353_lexical_similarity.txt\")\n",
    "output_file = \"../data/English/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def retrieve_neighbors_embedding_matrix(wordVecs, wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "    \n",
    "    # Create a set of unique neighbors\n",
    "    unique_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors)\n",
    "    \n",
    "    # Get the embedding size\n",
    "    embedding_size = 250 #wordVecs[next(iter(wordVecs))].shape[0]\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for neighbor in unique_neighbors:\n",
    "        embeddings = [\n",
    "            wordVecs[word]\n",
    "            for word, neighbors in neighbors_dict.items()\n",
    "            if neighbor in neighbors and word in wordVecs\n",
    "        ]\n",
    "        if embeddings:\n",
    "            average_embedding = np.mean(embeddings, axis=0)\n",
    "        else:\n",
    "            average_embedding = np.zeros((embedding_size,))\n",
    "\n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList_gensim = get_embeddings_words(wordVecs_gensim)\n",
    "wordVecMat_gensim = convert_dict_to_matrix(wordVecs_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ninan\\AppData\\Local\\Temp\\ipykernel_6288\\1790477722.py:19: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if neighbor in neighbors and word in wordVecs\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neighbors_matrix_gensim \u001b[39m=\u001b[39m retrieve_neighbors_embedding_matrix(wordVecMat_gensim, wordList_gensim, \u001b[39m\"\u001b[39;49m\u001b[39msynonyms\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[70], line 16\u001b[0m, in \u001b[0;36mretrieve_neighbors_embedding_matrix\u001b[1;34m(wordVecs, wordList, relation_type)\u001b[0m\n\u001b[0;32m     14\u001b[0m average_embeddings \u001b[39m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m neighbor \u001b[39min\u001b[39;00m unique_neighbors:\n\u001b[1;32m---> 16\u001b[0m     embeddings \u001b[39m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m         wordVecs[word]\n\u001b[0;32m     18\u001b[0m         \u001b[39mfor\u001b[39;00m word, neighbors \u001b[39min\u001b[39;00m neighbors_dict\u001b[39m.\u001b[39mitems()\n\u001b[0;32m     19\u001b[0m         \u001b[39mif\u001b[39;00m neighbor \u001b[39min\u001b[39;00m neighbors \u001b[39mand\u001b[39;00m word \u001b[39min\u001b[39;00m wordVecs\n\u001b[0;32m     20\u001b[0m     ]\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m embeddings:\n\u001b[0;32m     22\u001b[0m         average_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(embeddings, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[70], line 19\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     14\u001b[0m average_embeddings \u001b[39m=\u001b[39m []\n\u001b[0;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m neighbor \u001b[39min\u001b[39;00m unique_neighbors:\n\u001b[0;32m     16\u001b[0m     embeddings \u001b[39m=\u001b[39m [\n\u001b[0;32m     17\u001b[0m         wordVecs[word]\n\u001b[0;32m     18\u001b[0m         \u001b[39mfor\u001b[39;00m word, neighbors \u001b[39min\u001b[39;00m neighbors_dict\u001b[39m.\u001b[39mitems()\n\u001b[1;32m---> 19\u001b[0m         \u001b[39mif\u001b[39;00m neighbor \u001b[39min\u001b[39;00m neighbors \u001b[39mand\u001b[39;00m word \u001b[39min\u001b[39;00m wordVecs\n\u001b[0;32m     20\u001b[0m     ]\n\u001b[0;32m     21\u001b[0m     \u001b[39mif\u001b[39;00m embeddings:\n\u001b[0;32m     22\u001b[0m         average_embedding \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(embeddings, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "neighbors_matrix_gensim = retrieve_neighbors_embedding_matrix(wordVecMat_gensim, wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 249)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix_gensim))  \n",
    "print(neighbors_matrix_gensim.shape)  \n",
    "print(neighbors_matrix_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat_gensim))  \n",
    "print(wordVecMat_gensim.shape) \n",
    "print(wordVecMat_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  \n",
    "print(wordVecMat.shape) \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_gensim = get_wordnet_lexicon(wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)\n",
    "# retrofitted_similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (125776,250) (125776,300) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m retrofitted_wordVecs_gensim, updates_gensim \u001b[39m=\u001b[39m retrofitting_wordVecs(wordVecMat_gensim, neighbors_matrix_gensim, alpha\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, nb_iter\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[17], line 11\u001b[0m, in \u001b[0;36mretrofitting_wordVecs\u001b[1;34m(wordVecMat, neighbors_mean_matrix, alpha, beta, nb_iter)\u001b[0m\n\u001b[0;32m      4\u001b[0m updates \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(nb_iter):\n\u001b[0;32m      7\u001b[0m     \u001b[39m# Calculate the number of neighbors for each word\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     \u001b[39m# numNeighbors = np.sum(neighbors_mean_matrix != 0, axis=1)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \n\u001b[0;32m     10\u001b[0m     \u001b[39m# Update the word embeddings using retrofitting formula\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     newWordVecMat \u001b[39m=\u001b[39m (alpha \u001b[39m*\u001b[39;49m newWordVecMat \u001b[39m+\u001b[39;49m beta \u001b[39m*\u001b[39;49m neighbors_mean_matrix) \u001b[39m/\u001b[39m (alpha \u001b[39m+\u001b[39m beta)\n\u001b[0;32m     13\u001b[0m     \u001b[39m# Calculate the updates\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     update \u001b[39m=\u001b[39m newWordVecMat \u001b[39m-\u001b[39m wordVecMat\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (125776,250) (125776,300) "
     ]
    }
   ],
   "source": [
    "retrofitted_wordVecs_gensim, updates_gensim = retrofitting_wordVecs(wordVecMat_gensim, neighbors_matrix_gensim, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between original and retrofitted embeddings\n",
    "cos_similarities = cosine_similarity(wordVecMat_gensim, retrofitted_wordVecs_gensim)\n",
    "\n",
    "# Compute the average cosine similarity\n",
    "avg_cos_similarity = np.mean(cos_similarities)\n",
    "\n",
    "print(f\"Average cosine similarity: {avg_cos_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_vec_difference(wordVecs_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_matrix_gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m print_vec_difference(wordList_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity_matrix_gensim' is not defined"
     ]
    }
   ],
   "source": [
    "print_vec_difference(wordList_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
