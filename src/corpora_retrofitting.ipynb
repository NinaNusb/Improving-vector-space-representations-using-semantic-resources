{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, matutils\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained Word2Vec model\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "\n",
    "def norm_word(word):\n",
    "  \"\"\"\n",
    "  - input: word\n",
    "  - return: a normalized version of it\n",
    "  Normalization process: includes checking if the word is a number or a punctuation mark and replacing it with special tokens\n",
    "  \"\"\"\n",
    "  if isNumber.search(word.lower()):\n",
    "    return '---num---'\n",
    "  # check if the word consists only of non-alphanumeric characters by removing all non-alphanumeric characters from the word \n",
    "  # and checking if the result is an empty string\n",
    "  elif re.sub(r'\\W+', '', word) == '':\n",
    "    return '---punc---'\n",
    "  else:\n",
    "  # if input word not a number nor a punctuation mark, return a lowercase version of input word\n",
    "    return word.lower()\n",
    "  \n",
    "\n",
    "  \n",
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    first_line = True\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # Skip the first line\n",
    "      if first_line:\n",
    "        first_line =False\n",
    "        continue\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors\n",
    "\n",
    "  ''' Write word vectors to file '''\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "  \"\"\"\n",
    "  - input: a dictionary wordVectors where keys are words and values are their corresponding word vectors\n",
    "           file name outFileName\n",
    "  \"\"\"\n",
    "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "  outFile = open(outFileName, 'w', encoding= 'utf-8')  \n",
    "  for word, values in wordVectors.items():\n",
    "    outFile.write(word+' ')\n",
    "    for val in wordVectors[word]:\n",
    "      # write the word vectors to the ouptut file in the format:\n",
    "      # word1 val1 val2 val3 ...\n",
    "      # word2 val1 val2 val3 ...\n",
    "      # ...\n",
    "      outFile.write('%.4f' %(val)+' ')\n",
    "    outFile.write('\\n')      \n",
    "  outFile.close()\n",
    "\n",
    "''' Read the PPDB word relations as a dictionary '''\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.lower().strip().split()\n",
    "            lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the same format for the toy corpus as for the provided word embeddings\n",
    "def convert_matrix_to_dict(wordVecMat, wordList):\n",
    "    wordVecs = {}\n",
    "\n",
    "    for i, word in enumerate(wordList):\n",
    "        wordVecs[word] = wordVecMat[i]\n",
    "\n",
    "    return wordVecs\n",
    "\n",
    "def convert_dict_to_matrix(wordVecs):\n",
    "    wordVecMat = np.stack(list(wordVecs.values()))\n",
    "    return wordVecMat\n",
    "\n",
    "def vectorize_list(corpus):\n",
    "    corpus_vecs = [model[word] for word in corpus]\n",
    "\n",
    "    return corpus_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same input format as the real corpus\n",
    "toy_corpus = [\"cat\", \"tiger\", \"computer\", \"keyboard\", \"plane\", \"car\", \"doctor\", \"nurse\", \"love\", \"sex\"]\n",
    "toy_corpus_list_vecs = vectorize_list(toy_corpus)\n",
    "toy_wordVecs = convert_matrix_to_dict(toy_corpus_list_vecs, toy_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    similarity = dot_product / norm_product\n",
    "    return similarity\n",
    "\n",
    "def generate_cosine_similarity_matrix(dict_vecs): \n",
    "    num_vectors = len(dict_vecs)\n",
    "    similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "    for i, word1 in enumerate(dict_vecs):\n",
    "        for j, word2 in enumerate(dict_vecs):\n",
    "            similarity_matrix[i, j] = calculate_cosine_similarity(dict_vecs[word1], dict_vecs[word2])\n",
    "    return similarity_matrix\n",
    "\n",
    "def print_vec_similarities(wordList, similarity_matrix):\n",
    "    for word, vec in zip(wordList, similarity_matrix):\n",
    "        print(f'Similarities with \"{word}\":')\n",
    "        for i in range(len(vec)):\n",
    "            similarity = vec[i]\n",
    "            print(f'  - \"{wordList[i]}\": {similarity:.4f}')\n",
    "        print()\n",
    "\n",
    "def print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix):\n",
    "    difference = np.abs(similarity_matrix - retrofitted_similarity_matrix)\n",
    "    print(\"Similarity Difference Matrix:\")\n",
    "    print(difference)\n",
    "\n",
    "def cosine_similarity_matrix(matrix1, matrix2):\n",
    "    dot_product = np.sum(matrix1 * matrix2)\n",
    "    norm_matrix1 = np.linalg.norm(matrix1)\n",
    "    norm_matrix2 = np.linalg.norm(matrix2)\n",
    "    cosine_similarity = dot_product / (norm_matrix1 * norm_matrix2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon(target_words, relation_types, lang):\n",
    "    lexicon = {}\n",
    "\n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word, lang)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas(lang):\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"antonyms\" in relation_types:\n",
    "                if syn.lemmas(lang)[0].antonyms():\n",
    "                    related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "            if \"hyponyms\" in relation_types:\n",
    "                for hypo in syn.hyponyms():\n",
    "                    for lemma in hypo.lemmas(lang):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"hypernyms\" in relation_types:\n",
    "                for hyper in syn.hypernyms():\n",
    "                    for lemma in hyper.lemmas(lang):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"meronyms\" in relation_types:\n",
    "                for part in syn.part_meronyms():\n",
    "                    for lemma in part.lemmas(lang):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"holonyms\" in relation_types:\n",
    "                for whole in syn.part_holonyms():\n",
    "                    for lemma in whole.lemmas(lang):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"homonyms\" in relation_types:\n",
    "                for lemma in syn.lemmas(lang):\n",
    "                    if lemma.name() != word:\n",
    "                        homonyms = wordnet.lemmas(lemma.name())\n",
    "                        for homonym in homonyms:\n",
    "                            related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecMat = convert_dict_to_matrix(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(toy_corpus_list_vecs)) \n",
    "\n",
    "print(type(wordVecMat)) \n",
    "print(wordVecMat.shape)  \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 10)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(similarity_matrix)) \n",
    "print(similarity_matrix.shape)  \n",
    "print(similarity_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for the big corpus to retrive the word list from the keys\n",
    "def get_embeddings_words(wordVecs):\n",
    "    wordList = list(wordVecs.keys()) # TODO: or set?\n",
    "    return wordList\n",
    "\n",
    "wordList = get_embeddings_words(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbors_embedding_matrix(wordList, relation_type, lang):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type, lang)\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        embeddings = [\n",
    "            model.get_vector(neighbor)\n",
    "            for neighbor in neighbors\n",
    "            if model.has_index_for(neighbor)\n",
    "        ]\n",
    "        if len(embeddings) > 0:\n",
    "            average_embedding = np.sum(embeddings, axis=0) / len(embeddings)\n",
    "        else:\n",
    "            # Handle the case where a word has no embeddings for its synonyms\n",
    "            average_embedding = np.zeros(model.vector_size)  # Use a zero vector\n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix\n",
    "\n",
    "   \n",
    "    \n",
    "neighbors_matrix = create_neighbors_embedding_matrix(wordList, \"synonyms\", \"en\")\n",
    "\n",
    "# récupérer la liste des syn dans wordnet\n",
    "# vectorise chaque syn\n",
    "# BOW des synonymes (sum) pour n'avoir qu'un embedding \n",
    "# BOW_syn_cat\n",
    "# BOW_syn_dog= neighbors_matrix, shape (10, embedding_size) donc same size as wordVecs_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix))  # <class 'numpy.ndarray'>\n",
    "print(neighbors_matrix.shape)  # (m, n)\n",
    "print(neighbors_matrix.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  # <class 'numpy.ndarray'>\n",
    "print(wordVecMat.shape)  # (m, n)\n",
    "print(wordVecMat.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00676925  0.17245371 -0.32560504 -0.02995695  0.24918167  0.06591797\n",
      "  0.07754347  0.02062197  0.12026186 -0.24899179  0.11663705 -0.43598995\n",
      " -0.0165247  -0.43618888  0.05141873 -0.2046328   0.09973597  0.0461245\n",
      " -0.4420053   0.08787028  0.26338252 -0.1518453   0.11536521 -0.14642108\n",
      " -0.04931188  0.32405486 -0.15808557  0.31547716  0.40427201 -0.007934\n",
      " -0.00195312 -0.20903128 -0.03433369 -0.0849519   0.01340795  0.15198545\n",
      " -0.07754234  0.04350902  0.00148463  0.24564164  0.00093107  0.03174506\n",
      " -0.14347048  0.13828702  0.08990253 -0.03038646  0.37447442 -0.05503337\n",
      "  0.00611821  0.00164738 -0.15880896  0.13665545  0.34953252  0.14862174\n",
      " -0.0103189  -0.14141733  0.15832859 -0.30018898  0.35803392  0.18776052\n",
      "  0.28351056  0.18667716 -0.01274052  0.19207764  0.04131345  0.04772498\n",
      "  0.20808016  0.02882668 -0.10890771 -0.12867793  0.40634721 -0.03548855\n",
      " -0.15468343 -0.01318077 -0.11528298  0.38514766  0.11844098 -0.08239746\n",
      " -0.02005401 -0.06692618  0.08503554 -0.00346544  0.1995228  -0.07893711\n",
      " -0.34383251  0.04050474 -0.2636391  -0.14694101 -0.1783899  -0.0918257\n",
      " -0.0131429   0.04139088 -0.06987395 -0.25662345 -0.17748967 -0.27476671\n",
      " -0.01672363 -0.17666287 -0.33676034 -0.18375199 -0.24108435 -0.02301817\n",
      " -0.0048376   0.25613178  0.07612101 -0.20470513  0.0953064  -0.03844798\n",
      "  0.04892759 -0.11653646 -0.07707384  0.29826298  0.11636692  0.32834201\n",
      " -0.31238471 -0.00066913 -0.02505154 -0.23873901 -0.22574163 -0.04350577\n",
      " -0.03468753 -0.05264395 -0.30785455  0.02505323 -0.34844179  0.11226626\n",
      "  0.10000073  0.1189044   0.04702872 -0.14758527  0.13923419  0.04321967\n",
      " -0.15519799 -0.06542969 -0.02879789 -0.11844042 -0.02837584  0.09594444\n",
      "  0.10183038  0.10198523 -0.06081022  0.02417896 -0.15294054  0.04794516\n",
      "  0.06066442  0.15922716 -0.19703731  0.17048589 -0.12367983 -0.15320898\n",
      "  0.22272971  0.09056261 -0.31849727 -0.08702935 -0.13079947 -0.05045121\n",
      "  0.09113679  0.05342385  0.03645833  0.22512252 -0.10272612 -0.05701814\n",
      "  0.09566696 -0.13046604 -0.12130398  0.00603117 -0.04856138  0.21248373\n",
      "  0.17837637  0.02974899 -0.08555999 -0.03059218 -0.04345082  0.23660165\n",
      " -0.08013295  0.09815696  0.07034867 -0.12642416 -0.242515    0.27940539\n",
      " -0.16617132  0.01541816 -0.00099126  0.0524677  -0.03739194  0.07791251\n",
      "  0.20973601  0.3004286   0.12838844  0.06714884  0.02089154 -0.16434733\n",
      "  0.12680845  0.06278935 -0.01593244  0.184226    0.07969835 -0.18987359\n",
      " -0.11193918  0.18708067  0.06552409 -0.27893744 -0.0675354  -0.05583897\n",
      "  0.04787643  0.11910897 -0.01438636 -0.13045473  0.10323758 -0.26696325\n",
      " -0.40234262 -0.02973316 -0.0515894  -0.08254327 -0.11705977 -0.0447789\n",
      "  0.16213056 -0.31804127 -0.10855222  0.12037037  0.18612897  0.11705413\n",
      " -0.22371081 -0.27236599 -0.2145137  -0.07454851  0.07460587 -0.07304269\n",
      "  0.22288344  0.00952374  0.10791355  0.03955135 -0.03007846  0.04184525\n",
      " -0.28511386  0.05631058  0.27960488  0.02073415 -0.08864961  0.066971\n",
      "  0.23477738 -0.20298824  0.03927584  0.03217344  0.33202221  0.05400481\n",
      "  0.05493726 -0.036039    0.22249632 -0.13921215 -0.33608415  0.18813239\n",
      " -0.28481038  0.02863178 -0.04690326  0.27920871 -0.1286395   0.1268627\n",
      " -0.15716192  0.07503933 -0.08402846  0.04506429 -0.04430474 -0.1314799\n",
      "  0.06542573  0.24106775 -0.10216381  0.02992079 -0.27746017 -0.02798801\n",
      " -0.07106696  0.04219563 -0.15462466  0.13976994  0.05472141  0.09482377\n",
      "  0.1267994   0.16184228  0.17293295 -0.14490651  0.2610078   0.05841742\n",
      " -0.20719062  0.28466684  0.13873743 -0.08083654 -0.09813182  0.04846644\n",
      "  0.08657498  0.13033097 -0.25310149  0.11868851 -0.1590384   0.03733656\n",
      "  0.42320421 -0.01760412  0.18546778  0.49357605 -0.276461    0.01063255]\n"
     ]
    }
   ],
   "source": [
    "difference = toy_corpus_list_vecs[0] - neighbors_matrix[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs(wordVecMat, neighbors_mean_matrix, alpha, beta, nb_iter):\n",
    "    # Create a deep copy of wordVecMat \n",
    "    newWordVecMat = np.copy(wordVecMat, order='K')\n",
    "    updates = []\n",
    "    \n",
    "    for _ in range(nb_iter):\n",
    "        # Calculate the number of neighbors for each word\n",
    "        # numNeighbors = np.sum(neighbors_mean_matrix != 0, axis=1)\n",
    "        \n",
    "        # Update the word embeddings using retrofitting formula\n",
    "        newWordVecMat = (alpha * newWordVecMat + beta * neighbors_mean_matrix) / (alpha + beta)\n",
    "\n",
    "        # Calculate the updates\n",
    "        update = newWordVecMat - wordVecMat\n",
    "        updates.append(update)\n",
    "\n",
    "        # Update the wordVecMat for the next iteration\n",
    "        wordVecMat = newWordVecMat\n",
    "\n",
    "        # Stoping criterion\n",
    "        if np.linalg.norm(updates) < 1e-2:\n",
    "            break # TODO: return the embedding\n",
    "\n",
    "    # Convert the matrix back to a dictionary of word vectors\n",
    "    # retrofitted_wordVecs = dict(zip(wordList, newWordVecMat))\n",
    "\n",
    "    return newWordVecMat, updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = get_wordnet_lexicon(wordList, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': ['reckoner',\n",
       "  'figurer',\n",
       "  'computing_device',\n",
       "  'computing_machine',\n",
       "  'electronic_computer',\n",
       "  'data_processor',\n",
       "  'calculator',\n",
       "  'information_processing_system',\n",
       "  'estimator'],\n",
       " 'reckoner': ['computer'],\n",
       " 'honey': ['love'],\n",
       " 'physician': ['doctor'],\n",
       " 'auto': ['car'],\n",
       " 'medico': ['doctor'],\n",
       " 'arouse': ['sex'],\n",
       " 'level': ['plane'],\n",
       " 'bed': ['love'],\n",
       " 'hump': ['love'],\n",
       " 'making_love': ['love'],\n",
       " 'give_suck': ['nurse'],\n",
       " 'computing_device': ['computer'],\n",
       " 'computerized_tomography': ['cat'],\n",
       " 'love': ['honey',\n",
       "  'sleep_with',\n",
       "  'make_out',\n",
       "  'jazz',\n",
       "  'bang',\n",
       "  'screw',\n",
       "  'eff',\n",
       "  'be_intimate',\n",
       "  'have_it_off',\n",
       "  'love_life',\n",
       "  'have_intercourse',\n",
       "  'bed',\n",
       "  'hump',\n",
       "  'making_love',\n",
       "  'dear',\n",
       "  'have_it_away',\n",
       "  'lie_with',\n",
       "  'get_it_on',\n",
       "  'passion',\n",
       "  'know',\n",
       "  'sexual_love',\n",
       "  'erotic_love',\n",
       "  'dearest',\n",
       "  'sleep_together',\n",
       "  'have_a_go_at_it',\n",
       "  'do_it',\n",
       "  'beloved',\n",
       "  'fuck',\n",
       "  'enjoy',\n",
       "  'bonk',\n",
       "  'roll_in_the_hay',\n",
       "  'have_sex',\n",
       "  'lovemaking',\n",
       "  'get_laid',\n",
       "  'make_love'],\n",
       " 'dear': ['love'],\n",
       " 'regurgitate': ['cat'],\n",
       " 'aeroplane': ['plane'],\n",
       " 'doc': ['doctor'],\n",
       " 'harbor': ['nurse'],\n",
       " 'passion': ['love'],\n",
       " 'tiger': ['Panthera_tigris'],\n",
       " 'Panthera_tigris': ['tiger'],\n",
       " 'computing_machine': ['computer'],\n",
       " 'sheet': ['plane'],\n",
       " 'railcar': ['car'],\n",
       " 'shave': ['plane'],\n",
       " 'big_cat': ['cat'],\n",
       " 'Caterpillar': ['cat'],\n",
       " 'MD': ['doctor'],\n",
       " 'do_it': ['love'],\n",
       " 'bushel': ['doctor'],\n",
       " 'skim': ['plane'],\n",
       " 'automobile': ['car'],\n",
       " 'lovemaking': ['love'],\n",
       " 'get_laid': ['love'],\n",
       " 'information_processing_system': ['computer'],\n",
       " 'make_love': ['love'],\n",
       " 'puke': ['cat'],\n",
       " 'retch': ['cat'],\n",
       " 'railway_car': ['car'],\n",
       " 'sleep_with': ['love'],\n",
       " 'nanny': ['nurse'],\n",
       " 'jazz': ['love'],\n",
       " 'true_cat': ['cat'],\n",
       " 'planing_machine': ['plane'],\n",
       " 'Arabian_tea': ['cat'],\n",
       " 'airplane': ['plane'],\n",
       " 'be_intimate': ['love'],\n",
       " 'calculator': ['computer'],\n",
       " 'entertain': ['nurse'],\n",
       " 'cast': ['cat'],\n",
       " 'sick': ['cat'],\n",
       " 'elevator_car': ['car'],\n",
       " 'computed_tomography': ['cat'],\n",
       " 'turn_on': ['sex'],\n",
       " 'hold': ['nurse'],\n",
       " 'gondola': ['car'],\n",
       " 'honk': ['cat'],\n",
       " 'doctor_up': ['doctor'],\n",
       " 'have_it_away': ['love'],\n",
       " 'sexual_love': ['love'],\n",
       " 'disgorge': ['cat'],\n",
       " 'dearest': ['love'],\n",
       " 'sleep_together': ['love'],\n",
       " 'bozo': ['cat'],\n",
       " 'car': ['cable_car',\n",
       "  'elevator_car',\n",
       "  'railway_car',\n",
       "  'gondola',\n",
       "  'auto',\n",
       "  'railroad_car',\n",
       "  'automobile',\n",
       "  'railcar',\n",
       "  'motorcar',\n",
       "  'machine'],\n",
       " 'have_a_go_at_it': ['love'],\n",
       " 'sexual_practice': ['sex'],\n",
       " 'nurse': ['harbor',\n",
       "  'nursemaid',\n",
       "  'suckle',\n",
       "  'hold',\n",
       "  'nanny',\n",
       "  'give_suck',\n",
       "  'harbour',\n",
       "  'breastfeed',\n",
       "  'wet-nurse',\n",
       "  'entertain',\n",
       "  'suck',\n",
       "  'lactate'],\n",
       " 'chuck': ['cat'],\n",
       " 'sophisticate': ['doctor'],\n",
       " 'data_processor': ['computer'],\n",
       " 'sexual_urge': ['sex'],\n",
       " 'touch_on': ['doctor'],\n",
       " 'estimator': ['computer'],\n",
       " 'nursemaid': ['nurse'],\n",
       " 'suckle': ['nurse'],\n",
       " 'sexual_activity': ['sex'],\n",
       " 'harbour': ['nurse'],\n",
       " 'bang': ['love'],\n",
       " 'screw': ['love'],\n",
       " 'vomit_up': ['cat'],\n",
       " 'sex': ['sexual_practice',\n",
       "  'sexuality',\n",
       "  'wind_up',\n",
       "  'sex_activity',\n",
       "  'excite',\n",
       "  'turn_on',\n",
       "  'sexual_activity',\n",
       "  'arouse',\n",
       "  'sexual_urge',\n",
       "  'gender'],\n",
       " 'suck': ['nurse'],\n",
       " 'kat': ['cat'],\n",
       " 'love_life': ['love'],\n",
       " 'have_intercourse': ['love'],\n",
       " 'hombre': ['cat'],\n",
       " \"cat-o'-nine-tails\": ['cat'],\n",
       " 'breastfeed': ['nurse'],\n",
       " 'Dr.': ['doctor'],\n",
       " \"carpenter's_plane\": ['plane'],\n",
       " 'furbish_up': ['doctor'],\n",
       " 'get_it_on': ['love'],\n",
       " 'cable_car': ['car'],\n",
       " 'figurer': ['computer'],\n",
       " 'know': ['love'],\n",
       " 'be_sick': ['cat'],\n",
       " 'quat': ['cat'],\n",
       " 'keyboard': [],\n",
       " 'spue': ['cat'],\n",
       " 'planer': ['plane'],\n",
       " 'plane': [\"carpenter's_plane\",\n",
       "  'flat',\n",
       "  'planing_machine',\n",
       "  'airplane',\n",
       "  'skim',\n",
       "  'sheet',\n",
       "  'woodworking_plane',\n",
       "  'shave',\n",
       "  'level',\n",
       "  'planer',\n",
       "  'aeroplane'],\n",
       " 'beloved': ['love'],\n",
       " 'sex_activity': ['sex'],\n",
       " 'computed_axial_tomography': ['cat'],\n",
       " 'wet-nurse': ['nurse'],\n",
       " 'bonk': ['love'],\n",
       " 'roll_in_the_hay': ['love'],\n",
       " 'electronic_computer': ['computer'],\n",
       " 'regorge': ['cat'],\n",
       " 'computerized_axial_tomography': ['cat'],\n",
       " 'vomit': ['cat'],\n",
       " 'throw_up': ['cat'],\n",
       " 'khat': ['cat'],\n",
       " 'repair': ['doctor'],\n",
       " 'make_out': ['love'],\n",
       " 'eff': ['love'],\n",
       " 'CAT': ['cat'],\n",
       " 'motorcar': ['car'],\n",
       " 'have_it_off': ['love'],\n",
       " 'guy': ['cat'],\n",
       " 'qat': ['cat'],\n",
       " 'Doctor': ['doctor'],\n",
       " 'excite': ['sex'],\n",
       " 'African_tea': ['cat'],\n",
       " 'mend': ['doctor'],\n",
       " 'upchuck': ['cat'],\n",
       " 'lactate': ['nurse'],\n",
       " 'lie_with': ['love'],\n",
       " 'sexuality': ['sex'],\n",
       " 'wind_up': ['sex'],\n",
       " 'flat': ['plane'],\n",
       " 'purge': ['cat'],\n",
       " 'erotic_love': ['love'],\n",
       " 'fix': ['doctor'],\n",
       " 'railroad_car': ['car'],\n",
       " 'restore': ['doctor'],\n",
       " 'machine': ['car'],\n",
       " 'spew': ['cat'],\n",
       " 'doctor': ['doc',\n",
       "  'mend',\n",
       "  'Doctor',\n",
       "  'repair',\n",
       "  'physician',\n",
       "  'touch_on',\n",
       "  'restore',\n",
       "  'fix',\n",
       "  'sophisticate',\n",
       "  'bushel',\n",
       "  'medico',\n",
       "  'doctor_up',\n",
       "  'Dr.',\n",
       "  'Doctor_of_the_Church',\n",
       "  'MD',\n",
       "  'furbish_up'],\n",
       " 'fuck': ['love'],\n",
       " 'enjoy': ['love'],\n",
       " 'have_sex': ['love'],\n",
       " 'gender': ['sex'],\n",
       " 'woodworking_plane': ['plane'],\n",
       " 'Doctor_of_the_Church': ['doctor'],\n",
       " 'barf': ['cat'],\n",
       " 'CT': ['cat'],\n",
       " 'cat': ['puke',\n",
       "  'retch',\n",
       "  'throw_up',\n",
       "  'true_cat',\n",
       "  'Arabian_tea',\n",
       "  'vomit_up',\n",
       "  'CAT',\n",
       "  'cast',\n",
       "  'guy',\n",
       "  'qat',\n",
       "  'kat',\n",
       "  'sick',\n",
       "  'hombre',\n",
       "  \"cat-o'-nine-tails\",\n",
       "  'computed_tomography',\n",
       "  'African_tea',\n",
       "  'computerized_tomography',\n",
       "  'honk',\n",
       "  'upchuck',\n",
       "  'regurgitate',\n",
       "  'purge',\n",
       "  'be_sick',\n",
       "  'disgorge',\n",
       "  'quat',\n",
       "  'big_cat',\n",
       "  'Caterpillar',\n",
       "  'spue',\n",
       "  'bozo',\n",
       "  'spew',\n",
       "  'computed_axial_tomography',\n",
       "  'chuck',\n",
       "  'regorge',\n",
       "  'barf',\n",
       "  'CT',\n",
       "  'computerized_axial_tomography',\n",
       "  'vomit',\n",
       "  'khat']}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_graph_from_synonyms(synonyms_dict):\n",
    "    graph = {}\n",
    "    \n",
    "    # Create a set of all unique words in the dictionary\n",
    "    words = set(synonyms_dict.keys()).union(*synonyms_dict.values())\n",
    "    \n",
    "    # Initialize an empty adjacency dictionary for each word\n",
    "    for word in words:\n",
    "        graph[word] = set()\n",
    "    \n",
    "    # Iterate through the synonyms dictionary\n",
    "    for word, synonyms in synonyms_dict.items():\n",
    "        # Add synonyms to the adjacency set for the word\n",
    "        graph[word].update(synonyms)\n",
    "        \n",
    "        # Add the word as a synonym to each synonym's adjacency set\n",
    "        for synonym in synonyms:\n",
    "            graph[synonym].add(word)\n",
    "    \n",
    "    # Convert the adjacency sets to lists\n",
    "    graph = {word: list(adjacency_set) for word, adjacency_set in graph.items()}\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = generate_graph_from_synonyms(lexicon)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_article(Q, Q_hat, graph, alpha, beta, num_iterations=10):\n",
    "    num_words = Q.shape[0]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        Q_new = np.zeros_like(Q)\n",
    "        for i in range(num_words):\n",
    "            neighbors = graph[i]\n",
    "            numerator = np.sum(beta[i, j] * Q[j] for j in neighbors) + alpha[i] * Q_hat[i]\n",
    "            denominator = np.sum(beta[i, j] for j in neighbors) + alpha[i]\n",
    "            Q_new[i] = numerator / denominator\n",
    "        Q = Q_new\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_toy_vecs, updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newVecs = retrofitting_wordVecs_article(wordVecMat, neighbors_matrix, graph, alpha=1, beta=1, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6\n",
      "Number of edges: 5\n",
      "Neighbors of cat: ['kitten', 'animal', 'pet']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_keep = [\"cat\", \"kitten\", \"dog\", \"puppy\", \"animal\", \"pet\"]\n",
    "# Construct an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_nodes_from(words_to_keep)\n",
    "\n",
    "# Add edges between related words\n",
    "graph.add_edges_from([('cat', 'kitten'), ('dog', 'puppy'), ('cat', 'animal'), ('dog', 'animal'), ('cat', 'pet')])\n",
    "\n",
    "# Print the graph information\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Access neighbors of a word\n",
    "word = 'cat'\n",
    "neighbors = graph.neighbors(word)\n",
    "print(\"Neighbors of\", word + \":\", list(neighbors))\n",
    "\n",
    "# Create the layout for the graph\n",
    "layout = nx.spring_layout(graph)\n",
    "\n",
    "# Draw the nodes\n",
    "nx.draw_networkx_nodes(graph, pos=layout, node_color='lightblue', node_size=500)\n",
    "\n",
    "# Draw the edges\n",
    "nx.draw_networkx_edges(graph, pos=layout, edge_color='gray')\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(graph, pos=layout, font_color='black')\n",
    "\n",
    "# Set plot properties\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00338463, -0.08622685,  0.16280252, ..., -0.24678802,\n",
       "          0.1382305 , -0.00531627],\n",
       "        [ 0.08007812, -0.06433105,  0.02783203, ..., -0.08123779,\n",
       "          0.03717041, -0.03466797],\n",
       "        [ 0.00255203,  0.02276611, -0.13401031, ..., -0.07601929,\n",
       "          0.05496216,  0.07133484],\n",
       "        ...,\n",
       "        [ 0.04763455,  0.11241319, -0.07042948, ..., -0.00129022,\n",
       "         -0.09945594, -0.13053046],\n",
       "        [-0.03367829,  0.04928064, -0.00994873, ...,  0.08418322,\n",
       "          0.06436348,  0.01234341],\n",
       "        [ 0.04439545, -0.02075195,  0.11517334, ..., -0.06329346,\n",
       "          0.06408691, -0.06994629]]),\n",
       " array([[-0.00169231, -0.04311343,  0.08140126, ..., -0.12339401,\n",
       "          0.06911525, -0.00265814],\n",
       "        [ 0.04003906, -0.03216553,  0.01391602, ..., -0.0406189 ,\n",
       "          0.01858521, -0.01733398],\n",
       "        [ 0.00127602,  0.01138306, -0.06700516, ..., -0.03800964,\n",
       "          0.02748108,  0.03566742],\n",
       "        ...,\n",
       "        [ 0.02381727,  0.0562066 , -0.03521474, ..., -0.00064511,\n",
       "         -0.04972797, -0.06526523],\n",
       "        [-0.01683915,  0.02464032, -0.00497437, ...,  0.04209161,\n",
       "          0.03218174,  0.0061717 ],\n",
       "        [ 0.02219772, -0.01037598,  0.05758667, ..., -0.03164673,\n",
       "          0.03204346, -0.03497314]]),\n",
       " array([[-0.00084616, -0.02155671,  0.04070063, ..., -0.06169701,\n",
       "          0.03455763, -0.00132907],\n",
       "        [ 0.02001953, -0.01608276,  0.00695801, ..., -0.02030945,\n",
       "          0.0092926 , -0.00866699],\n",
       "        [ 0.00063801,  0.00569153, -0.03350258, ..., -0.01900482,\n",
       "          0.01374054,  0.01783371],\n",
       "        ...,\n",
       "        [ 0.01190864,  0.0281033 , -0.01760737, ..., -0.00032255,\n",
       "         -0.02486398, -0.03263262],\n",
       "        [-0.00841957,  0.01232016, -0.00248718, ...,  0.0210458 ,\n",
       "          0.01609087,  0.00308585],\n",
       "        [ 0.01109886, -0.00518799,  0.02879333, ..., -0.01582336,\n",
       "          0.01602173, -0.01748657]]),\n",
       " array([[-0.00042308, -0.01077836,  0.02035031, ..., -0.0308485 ,\n",
       "          0.01727881, -0.00066453],\n",
       "        [ 0.01000977, -0.00804138,  0.003479  , ..., -0.01015472,\n",
       "          0.0046463 , -0.0043335 ],\n",
       "        [ 0.000319  ,  0.00284576, -0.01675129, ..., -0.00950241,\n",
       "          0.00687027,  0.00891685],\n",
       "        ...,\n",
       "        [ 0.00595432,  0.01405165, -0.00880369, ..., -0.00016128,\n",
       "         -0.01243199, -0.01631631],\n",
       "        [-0.00420979,  0.00616008, -0.00124359, ...,  0.0105229 ,\n",
       "          0.00804543,  0.00154293],\n",
       "        [ 0.00554943, -0.00259399,  0.01439667, ..., -0.00791168,\n",
       "          0.00801086, -0.00874329]]),\n",
       " array([[-2.11539096e-04, -5.38917829e-03,  1.01751575e-02, ...,\n",
       "         -1.54242516e-02,  8.63940627e-03, -3.32267140e-04],\n",
       "        [ 5.00488281e-03, -4.02069092e-03,  1.73950195e-03, ...,\n",
       "         -5.07736206e-03,  2.32315063e-03, -2.16674805e-03],\n",
       "        [ 1.59502029e-04,  1.42288208e-03, -8.37564468e-03, ...,\n",
       "         -4.75120544e-03,  3.43513489e-03,  4.45842743e-03],\n",
       "        ...,\n",
       "        [ 2.97715928e-03,  7.02582463e-03, -4.40184260e-03, ...,\n",
       "         -8.06384487e-05, -6.21599623e-03, -8.15815385e-03],\n",
       "        [-2.10489333e-03,  3.08004022e-03, -6.21795654e-04, ...,\n",
       "          5.26145101e-03,  4.02271748e-03,  7.71462917e-04],\n",
       "        [ 2.77471542e-03, -1.29699707e-03,  7.19833374e-03, ...,\n",
       "         -3.95584106e-03,  4.00543213e-03, -4.37164307e-03]]),\n",
       " array([[-1.05769548e-04, -2.69458914e-03,  5.08757873e-03, ...,\n",
       "         -7.71212578e-03,  4.31970314e-03, -1.66133570e-04],\n",
       "        [ 2.50244141e-03, -2.01034546e-03,  8.69750977e-04, ...,\n",
       "         -2.53868103e-03,  1.16157532e-03, -1.08337402e-03],\n",
       "        [ 7.97510147e-05,  7.11441040e-04, -4.18782234e-03, ...,\n",
       "         -2.37560272e-03,  1.71756744e-03,  2.22921371e-03],\n",
       "        ...,\n",
       "        [ 1.48857964e-03,  3.51291231e-03, -2.20092130e-03, ...,\n",
       "         -4.03192244e-05, -3.10799811e-03, -4.07907693e-03],\n",
       "        [-1.05244666e-03,  1.54002011e-03, -3.10897827e-04, ...,\n",
       "          2.63072550e-03,  2.01135874e-03,  3.85731459e-04],\n",
       "        [ 1.38735771e-03, -6.48498535e-04,  3.59916687e-03, ...,\n",
       "         -1.97792053e-03,  2.00271606e-03, -2.18582153e-03]]),\n",
       " array([[-5.28847740e-05, -1.34729457e-03,  2.54378936e-03, ...,\n",
       "         -3.85606289e-03,  2.15985157e-03, -8.30667850e-05],\n",
       "        [ 1.25122070e-03, -1.00517273e-03,  4.34875488e-04, ...,\n",
       "         -1.26934052e-03,  5.80787659e-04, -5.41687012e-04],\n",
       "        [ 3.98755074e-05,  3.55720520e-04, -2.09391117e-03, ...,\n",
       "         -1.18780136e-03,  8.58783722e-04,  1.11460686e-03],\n",
       "        ...,\n",
       "        [ 7.44289820e-04,  1.75645616e-03, -1.10046065e-03, ...,\n",
       "         -2.01596122e-05, -1.55399906e-03, -2.03953846e-03],\n",
       "        [-5.26223332e-04,  7.70010054e-04, -1.55448914e-04, ...,\n",
       "          1.31536275e-03,  1.00567937e-03,  1.92865729e-04],\n",
       "        [ 6.93678856e-04, -3.24249268e-04,  1.79958344e-03, ...,\n",
       "         -9.88960266e-04,  1.00135803e-03, -1.09291077e-03]]),\n",
       " array([[-2.64423870e-05, -6.73647286e-04,  1.27189468e-03, ...,\n",
       "         -1.92803144e-03,  1.07992578e-03, -4.15333925e-05],\n",
       "        [ 6.25610352e-04, -5.02586365e-04,  2.17437744e-04, ...,\n",
       "         -6.34670258e-04,  2.90393829e-04, -2.70843506e-04],\n",
       "        [ 1.99377537e-05,  1.77860260e-04, -1.04695559e-03, ...,\n",
       "         -5.93900681e-04,  4.29391861e-04,  5.57303429e-04],\n",
       "        ...,\n",
       "        [ 3.72144910e-04,  8.78228078e-04, -5.50230325e-04, ...,\n",
       "         -1.00798061e-05, -7.76999528e-04, -1.01976923e-03],\n",
       "        [-2.63111666e-04,  3.85005027e-04, -7.77244568e-05, ...,\n",
       "          6.57681376e-04,  5.02839684e-04,  9.64328647e-05],\n",
       "        [ 3.46839428e-04, -1.62124634e-04,  8.99791718e-04, ...,\n",
       "         -4.94480133e-04,  5.00679016e-04, -5.46455383e-04]]),\n",
       " array([[-1.32211935e-05, -3.36823643e-04,  6.35947341e-04, ...,\n",
       "         -9.64015722e-04,  5.39962892e-04, -2.07666963e-05],\n",
       "        [ 3.12805176e-04, -2.51293182e-04,  1.08718872e-04, ...,\n",
       "         -3.17335129e-04,  1.45196915e-04, -1.35421753e-04],\n",
       "        [ 9.96887684e-06,  8.89301300e-05, -5.23477793e-04, ...,\n",
       "         -2.96950340e-04,  2.14695930e-04,  2.78651714e-04],\n",
       "        ...,\n",
       "        [ 1.86072455e-04,  4.39114039e-04, -2.75115162e-04, ...,\n",
       "         -5.03990304e-06, -3.88499764e-04, -5.09884616e-04],\n",
       "        [-1.31555833e-04,  1.92502514e-04, -3.88622284e-05, ...,\n",
       "          3.28840688e-04,  2.51419842e-04,  4.82164323e-05],\n",
       "        [ 1.73419714e-04, -8.10623169e-05,  4.49895859e-04, ...,\n",
       "         -2.47240067e-04,  2.50339508e-04, -2.73227692e-04]]),\n",
       " array([[-6.61059676e-06, -1.68411822e-04,  3.17973670e-04, ...,\n",
       "         -4.82007861e-04,  2.69981446e-04, -1.03833481e-05],\n",
       "        [ 1.56402588e-04, -1.25646591e-04,  5.43594360e-05, ...,\n",
       "         -1.58667564e-04,  7.25984573e-05, -6.77108765e-05],\n",
       "        [ 4.98443842e-06,  4.44650650e-05, -2.61738896e-04, ...,\n",
       "         -1.48475170e-04,  1.07347965e-04,  1.39325857e-04],\n",
       "        ...,\n",
       "        [ 9.30362276e-05,  2.19557020e-04, -1.37557581e-04, ...,\n",
       "         -2.51995152e-06, -1.94249882e-04, -2.54942308e-04],\n",
       "        [-6.57779165e-05,  9.62512568e-05, -1.94311142e-05, ...,\n",
       "          1.64420344e-04,  1.25709921e-04,  2.41082162e-05],\n",
       "        [ 8.67098570e-05, -4.05311584e-05,  2.24947929e-04, ...,\n",
       "         -1.23620033e-04,  1.25169754e-04, -1.36613846e-04]])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrofitted_toy_matrix = convert_dict_to_matrix(retrofitted_toy_vecs)\n",
    "retrofitted_similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, retrofitted_similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172961950302124"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrofitted_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"car\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"love\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"car\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"love\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"car\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"love\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"computer\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"car\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"love\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"love\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"plane\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"love\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"car\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"love\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"car\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"car\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "  - \"car\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "  - \"love\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "def print_vec_difference(wordList, similarity_matrix1, similarity_matrix2):\n",
    "    for i, word in enumerate(wordList):\n",
    "        print(f\"\\nSimilarities with \\\"{word}\\\":\")\n",
    "        for j, neighbor in enumerate(wordList):\n",
    "            similarity1 = similarity_matrix1[i, j]\n",
    "            similarity2 = similarity_matrix2[i, j]\n",
    "            difference = similarity2 - similarity1  # Calculate the difference\n",
    "            print(f\"  - \\\"{neighbor}\\\": {similarity1:.4f} -> {similarity2:.4f} (Difference: {difference:.4f})\")\n",
    "\n",
    "print_vec_difference(toy_corpus, similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Difference Matrix:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between wordVecMat and retrofitted_toy_vec\n",
    "# similarity_score = cosine_similarity_matrix(wordVecMat, retrofitted_toy_vecs)\n",
    "# print(\"Cosine Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average embedding update: 0.12658860989283166\n"
     ]
    }
   ],
   "source": [
    "def measure_embedding_updates(original_matrix, retrofitted_matrix):\n",
    "    absolute_diff = np.abs(original_matrix - retrofitted_matrix)\n",
    "    mean_absolute_diff = np.mean(absolute_diff)\n",
    "    return mean_absolute_diff\n",
    "\n",
    "# Example usage\n",
    "update_measure = measure_embedding_updates(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Average embedding update:\", update_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation score: 0.42055888661904023\n",
      "Pearson correlation score: 0.4232245375810048\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def spearman_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = spearmanr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "def pearson_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "similarity_score = spearman_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Spearman correlation score:\", similarity_score)\n",
    "similarity_score = pearson_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Pearson correlation score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 0.1, 'nb_iter': 1}\n",
      "Best Spearman correlation score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load human evaluation scores\n",
    "eval_file_path = r\"C:\\Users\\ninan\\OneDrive\\Bureau\\Université Paris Cité\\S2\\NLP project\\Improving-vector-space-representations-using-semantic-resources\\data\\English\\lexicon\\ws353_lexical_similarity.txt\"\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Find best values for hyperparameters\n",
    "best_similarity_score = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "iteration_count = 0\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1, 16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            cosine_sim = cosine_similarity(wordVecMat, retrofitted_toy_vec)\n",
    "\n",
    "            # Calculate Spearman correlation against human evaluation scores\n",
    "            eval_scores_list = []\n",
    "            cosine_sim_list = []\n",
    "            for (word1, word2), score in eval_scores.items():\n",
    "                if word1 in wordList and word2 in wordList:\n",
    "                    word1_index = wordList.index(word1)\n",
    "                    word2_index = wordList.index(word2)\n",
    "                    eval_scores_list.append(score)\n",
    "                    cosine_sim_list.append(cosine_sim[word1_index, word2_index])\n",
    "\n",
    "            # Check if there are valid pairs for comparison\n",
    "            if len(eval_scores_list) > 0 and len(cosine_sim_list) > 0:\n",
    "                correlation, _ = spearmanr(eval_scores_list, cosine_sim_list)\n",
    "                # print(\"alpha =\", alpha, \"beta =\", beta, \"nb_iter =\", nb_iter, \"correlation =\", correlation)\n",
    "\n",
    "                # Update best similarity score and parameters if improved\n",
    "                if correlation > best_similarity_score:\n",
    "                    best_similarity_score = correlation\n",
    "                    best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "            iteration_count += 1\n",
    "            if iteration_count >= 100:\n",
    "                break\n",
    "        if iteration_count >= 100:\n",
    "            break\n",
    "    if iteration_count >= 100:\n",
    "        break\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best Spearman correlation score:\", best_similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 1.1000000000000003, 'nb_iter': 15}\n",
      "Best embedding update: 0.12671235242449622\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters\n",
    "best_embed_update = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1,16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            embed_update = measure_embedding_updates(wordVecMat, retrofitted_toy_vec)\n",
    "            # print(\" alpha =\", alpha, \" beta=\", beta, \"nb_iter =\", nb_iter, \" similarity score =\", similarity_score)\n",
    "            if embed_update > best_embed_update:\n",
    "                best_embed_update = embed_update\n",
    "                best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best embedding update:\", best_embed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5134\n",
      "  - \"computer\": 0.2147\n",
      "  - \"keyboard\": 0.2270\n",
      "  - \"plane\": 0.2878\n",
      "  - \"car\": 0.2492\n",
      "  - \"doctor\": 0.2437\n",
      "  - \"nurse\": 0.3233\n",
      "  - \"love\": 0.3254\n",
      "  - \"sex\": 0.2202\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5134\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0783\n",
      "  - \"keyboard\": 0.1118\n",
      "  - \"plane\": 0.1769\n",
      "  - \"car\": 0.1518\n",
      "  - \"doctor\": 0.0866\n",
      "  - \"nurse\": 0.1714\n",
      "  - \"love\": 0.1518\n",
      "  - \"sex\": 0.2417\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.2147\n",
      "  - \"tiger\": 0.0783\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.4058\n",
      "  - \"plane\": 0.2883\n",
      "  - \"car\": 0.3039\n",
      "  - \"doctor\": 0.2093\n",
      "  - \"nurse\": 0.2180\n",
      "  - \"love\": 0.1358\n",
      "  - \"sex\": 0.1602\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2270\n",
      "  - \"tiger\": 0.1118\n",
      "  - \"computer\": 0.4058\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1872\n",
      "  - \"car\": 0.1700\n",
      "  - \"doctor\": 0.1131\n",
      "  - \"nurse\": 0.1637\n",
      "  - \"love\": 0.2198\n",
      "  - \"sex\": 0.1140\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.2878\n",
      "  - \"tiger\": 0.1769\n",
      "  - \"computer\": 0.2883\n",
      "  - \"keyboard\": 0.1872\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.4366\n",
      "  - \"doctor\": 0.2202\n",
      "  - \"nurse\": 0.1756\n",
      "  - \"love\": 0.1935\n",
      "  - \"sex\": 0.0994\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2492\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.3039\n",
      "  - \"keyboard\": 0.1700\n",
      "  - \"plane\": 0.4366\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1865\n",
      "  - \"nurse\": 0.1453\n",
      "  - \"love\": 0.1766\n",
      "  - \"sex\": 0.1273\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.2437\n",
      "  - \"tiger\": 0.0866\n",
      "  - \"computer\": 0.2093\n",
      "  - \"keyboard\": 0.1131\n",
      "  - \"plane\": 0.2202\n",
      "  - \"car\": 0.1865\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6105\n",
      "  - \"love\": 0.1844\n",
      "  - \"sex\": 0.1923\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.3233\n",
      "  - \"tiger\": 0.1714\n",
      "  - \"computer\": 0.2180\n",
      "  - \"keyboard\": 0.1637\n",
      "  - \"plane\": 0.1756\n",
      "  - \"car\": 0.1453\n",
      "  - \"doctor\": 0.6105\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.2675\n",
      "  - \"sex\": 0.3084\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.3254\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.1358\n",
      "  - \"keyboard\": 0.2198\n",
      "  - \"plane\": 0.1935\n",
      "  - \"car\": 0.1766\n",
      "  - \"doctor\": 0.1844\n",
      "  - \"nurse\": 0.2675\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.3760\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2202\n",
      "  - \"tiger\": 0.2417\n",
      "  - \"computer\": 0.1602\n",
      "  - \"keyboard\": 0.1140\n",
      "  - \"plane\": 0.0994\n",
      "  - \"car\": 0.1273\n",
      "  - \"doctor\": 0.1923\n",
      "  - \"nurse\": 0.3084\n",
      "  - \"love\": 0.3760\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_retrofitted_toy_matrix, new_updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=0.1, beta=0.1, nb_iter=1)\n",
    "new_retrofitted_toy_dict = convert_matrix_to_dict(new_retrofitted_toy_matrix, wordList)\n",
    "new_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(new_retrofitted_toy_dict)\n",
    "print_vec_similarities(toy_corpus, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between original and after tuning hyperparam\n",
    "print_vec_difference(toy_corpus, similarity_matrix, new_retrofitted_similarity_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between retrofitted embeddings and after tuning hyperaparams\n",
    "print_vec_difference(toy_corpus, retrofitted_similarity_matrix, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>Before: 0.29245239862991185, After: 1.00000000...</td>\n",
       "      <td>Before: 0.35037322527996934, After: 0.20200897...</td>\n",
       "      <td>Before: 0.06136659928459301, After: 0.19719178...</td>\n",
       "      <td>Before: 0.18344955625364173, After: 0.20547455...</td>\n",
       "      <td>Before: 0.21134097025538556, After: 0.39445950...</td>\n",
       "      <td>Before: 0.136072027917602, After: 0.2634861035...</td>\n",
       "      <td>Before: 0.16547475026405636, After: 0.34338708...</td>\n",
       "      <td>Before: 0.24690899138830727, After: 0.54854860...</td>\n",
       "      <td>Before: 0.2989067535773432, After: 0.594053102...</td>\n",
       "      <td>Before: 0.1093022564011111, After: 0.259890845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Before: 0.17347637872059773, After: 0.20200897...</td>\n",
       "      <td>Before: 0.48802072485209846, After: 1.00000000...</td>\n",
       "      <td>Before: 0.02942476361382193, After: 0.09025702...</td>\n",
       "      <td>Before: 0.06542581824273716, After: 0.18313975...</td>\n",
       "      <td>Before: 0.15090617196611955, After: 0.07307479...</td>\n",
       "      <td>Before: 0.16119598769364896, After: 0.10033040...</td>\n",
       "      <td>Before: 0.0774108002811773, After: 0.089083542...</td>\n",
       "      <td>Before: 0.1697249630498177, After: 0.202597136...</td>\n",
       "      <td>Before: 0.17516455047450735, After: 0.19102605...</td>\n",
       "      <td>Before: 0.14518818082220147, After: 0.18807845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>Before: 0.18984798734723213, After: 0.19719178...</td>\n",
       "      <td>Before: 0.05360514929979338, After: 0.09025702...</td>\n",
       "      <td>Before: 0.3047689400402037, After: 1.0</td>\n",
       "      <td>Before: 0.39639163439495995, After: 0.23934215...</td>\n",
       "      <td>Before: 0.28314903703275535, After: 0.40858220...</td>\n",
       "      <td>Before: 0.26826894486108244, After: 0.22732308...</td>\n",
       "      <td>Before: 0.18039329196329013, After: 0.20986951...</td>\n",
       "      <td>Before: 0.09297679298707379, After: 0.12068024...</td>\n",
       "      <td>Before: 0.1168711356729625, After: 0.234808759...</td>\n",
       "      <td>Before: 0.1158779845883439, After: 0.076953257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>Before: 0.20546589125510897, After: 0.20547455...</td>\n",
       "      <td>Before: 0.18314156317766062, After: 0.18313975...</td>\n",
       "      <td>Before: 0.2393287663091698, After: 0.239342157...</td>\n",
       "      <td>Before: 0.9999999999999996, After: 1.0</td>\n",
       "      <td>Before: 0.28971014677665063, After: 0.28970944...</td>\n",
       "      <td>Before: 0.15750632650840493, After: 0.15750846...</td>\n",
       "      <td>Before: 0.13804955762057758, After: 0.13804958...</td>\n",
       "      <td>Before: 0.16678031434047627, After: 0.16678347...</td>\n",
       "      <td>Before: 0.27407501845767246, After: 0.27407454...</td>\n",
       "      <td>Before: 0.10639718565916091, After: 0.10639914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>Before: 0.16761576142114898, After: 0.39445950...</td>\n",
       "      <td>Before: 0.06730278214710199, After: 0.07307479...</td>\n",
       "      <td>Before: 0.06606645196552532, After: 0.40858220...</td>\n",
       "      <td>Before: 0.10055138151211143, After: 0.28970944...</td>\n",
       "      <td>Before: 0.38405259310022044, After: 1.00000000...</td>\n",
       "      <td>Before: 0.3219357387657039, After: 0.354037032...</td>\n",
       "      <td>Before: 0.15146728859985834, After: 0.21833826...</td>\n",
       "      <td>Before: 0.10589313234551631, After: 0.28236372...</td>\n",
       "      <td>Before: 0.1936940498815496, After: 0.328525840...</td>\n",
       "      <td>Before: 0.05697047025775614, After: 0.11862340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>Before: 0.15859645192729996, After: 0.26348610...</td>\n",
       "      <td>Before: -0.049076379792710186, After: 0.100330...</td>\n",
       "      <td>Before: 0.13968323112249992, After: 0.22732308...</td>\n",
       "      <td>Before: 0.14983822223318854, After: 0.15750846...</td>\n",
       "      <td>Before: 0.2597415410728325, After: 0.354037032...</td>\n",
       "      <td>Before: 0.6158574248530795, After: 1.000000000...</td>\n",
       "      <td>Before: 0.13778205919388814, After: 0.19190468...</td>\n",
       "      <td>Before: 0.0865221800713605, After: 0.160778501...</td>\n",
       "      <td>Before: 0.22133439390681858, After: 0.24947266...</td>\n",
       "      <td>Before: 0.059270287407368415, After: 0.0662935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>Before: 0.25878907406446877, After: 0.34338708...</td>\n",
       "      <td>Before: 0.017639064485218965, After: 0.0890835...</td>\n",
       "      <td>Before: 0.0978054983995635, After: 0.209869514...</td>\n",
       "      <td>Before: 0.08500327165730943, After: 0.13804958...</td>\n",
       "      <td>Before: 0.13439994429915442, After: 0.21833826...</td>\n",
       "      <td>Before: 0.09431570687955, After: 0.19190468704...</td>\n",
       "      <td>Before: 0.6128107065755533, After: 1.0</td>\n",
       "      <td>Before: 0.27845097194129365, After: 0.34448646...</td>\n",
       "      <td>Before: 0.19325643013428553, After: 0.33078374...</td>\n",
       "      <td>Before: 0.0745189116843016, After: 0.175547118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>Before: 0.18217682480604822, After: 0.54854860...</td>\n",
       "      <td>Before: 0.07222178145580241, After: 0.20259713...</td>\n",
       "      <td>Before: 0.11697573887301807, After: 0.12068024...</td>\n",
       "      <td>Before: 0.12199094008346709, After: 0.16678347...</td>\n",
       "      <td>Before: 0.12790409339777273, After: 0.28236372...</td>\n",
       "      <td>Before: 0.07363428182232754, After: 0.16077850...</td>\n",
       "      <td>Before: 0.4308149649767604, After: 0.344486463...</td>\n",
       "      <td>Before: 0.378466332225932, After: 1.0000000000...</td>\n",
       "      <td>Before: 0.1708752362535986, After: 0.544714533...</td>\n",
       "      <td>Before: 0.1264203000118017, After: 0.409129275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>Before: 0.241072229246228, After: 0.5940531024...</td>\n",
       "      <td>Before: 0.10199943514005788, After: 0.19102605...</td>\n",
       "      <td>Before: 0.0730022470894344, After: 0.234808759...</td>\n",
       "      <td>Before: 0.15911448638969528, After: 0.27407454...</td>\n",
       "      <td>Before: 0.09505575751009387, After: 0.32852584...</td>\n",
       "      <td>Before: 0.11200247669649024, After: 0.24947266...</td>\n",
       "      <td>Before: 0.14771102908578468, After: 0.33078374...</td>\n",
       "      <td>Before: 0.3033847603340788, After: 0.544714533...</td>\n",
       "      <td>Before: 0.6110191309495465, After: 0.999999999...</td>\n",
       "      <td>Before: 0.30399420253175347, After: 0.36164712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>Before: 0.225917972105598, After: 0.2598908452...</td>\n",
       "      <td>Before: 0.1655264826766013, After: 0.188078452...</td>\n",
       "      <td>Before: 0.036750539503579295, After: 0.0769532...</td>\n",
       "      <td>Before: 0.09429740737651135, After: 0.10639914...</td>\n",
       "      <td>Before: 0.10212970436490482, After: 0.11862340...</td>\n",
       "      <td>Before: 0.13403080874265905, After: 0.06629354...</td>\n",
       "      <td>Before: 0.1436405909297276, After: 0.175547118...</td>\n",
       "      <td>Before: 0.26868181343357167, After: 0.40912927...</td>\n",
       "      <td>Before: 0.3049306009871644, After: 0.361647126...</td>\n",
       "      <td>Before: 0.4896246955281065, After: 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        cat  \\\n",
       "cat       Before: 0.29245239862991185, After: 1.00000000...   \n",
       "tiger     Before: 0.17347637872059773, After: 0.20200897...   \n",
       "computer  Before: 0.18984798734723213, After: 0.19719178...   \n",
       "keyboard  Before: 0.20546589125510897, After: 0.20547455...   \n",
       "plane     Before: 0.16761576142114898, After: 0.39445950...   \n",
       "car       Before: 0.15859645192729996, After: 0.26348610...   \n",
       "doctor    Before: 0.25878907406446877, After: 0.34338708...   \n",
       "nurse     Before: 0.18217682480604822, After: 0.54854860...   \n",
       "love      Before: 0.241072229246228, After: 0.5940531024...   \n",
       "sex       Before: 0.225917972105598, After: 0.2598908452...   \n",
       "\n",
       "                                                      tiger  \\\n",
       "cat       Before: 0.35037322527996934, After: 0.20200897...   \n",
       "tiger     Before: 0.48802072485209846, After: 1.00000000...   \n",
       "computer  Before: 0.05360514929979338, After: 0.09025702...   \n",
       "keyboard  Before: 0.18314156317766062, After: 0.18313975...   \n",
       "plane     Before: 0.06730278214710199, After: 0.07307479...   \n",
       "car       Before: -0.049076379792710186, After: 0.100330...   \n",
       "doctor    Before: 0.017639064485218965, After: 0.0890835...   \n",
       "nurse     Before: 0.07222178145580241, After: 0.20259713...   \n",
       "love      Before: 0.10199943514005788, After: 0.19102605...   \n",
       "sex       Before: 0.1655264826766013, After: 0.188078452...   \n",
       "\n",
       "                                                   computer  \\\n",
       "cat       Before: 0.06136659928459301, After: 0.19719178...   \n",
       "tiger     Before: 0.02942476361382193, After: 0.09025702...   \n",
       "computer             Before: 0.3047689400402037, After: 1.0   \n",
       "keyboard  Before: 0.2393287663091698, After: 0.239342157...   \n",
       "plane     Before: 0.06606645196552532, After: 0.40858220...   \n",
       "car       Before: 0.13968323112249992, After: 0.22732308...   \n",
       "doctor    Before: 0.0978054983995635, After: 0.209869514...   \n",
       "nurse     Before: 0.11697573887301807, After: 0.12068024...   \n",
       "love      Before: 0.0730022470894344, After: 0.234808759...   \n",
       "sex       Before: 0.036750539503579295, After: 0.0769532...   \n",
       "\n",
       "                                                   keyboard  \\\n",
       "cat       Before: 0.18344955625364173, After: 0.20547455...   \n",
       "tiger     Before: 0.06542581824273716, After: 0.18313975...   \n",
       "computer  Before: 0.39639163439495995, After: 0.23934215...   \n",
       "keyboard             Before: 0.9999999999999996, After: 1.0   \n",
       "plane     Before: 0.10055138151211143, After: 0.28970944...   \n",
       "car       Before: 0.14983822223318854, After: 0.15750846...   \n",
       "doctor    Before: 0.08500327165730943, After: 0.13804958...   \n",
       "nurse     Before: 0.12199094008346709, After: 0.16678347...   \n",
       "love      Before: 0.15911448638969528, After: 0.27407454...   \n",
       "sex       Before: 0.09429740737651135, After: 0.10639914...   \n",
       "\n",
       "                                                      plane  \\\n",
       "cat       Before: 0.21134097025538556, After: 0.39445950...   \n",
       "tiger     Before: 0.15090617196611955, After: 0.07307479...   \n",
       "computer  Before: 0.28314903703275535, After: 0.40858220...   \n",
       "keyboard  Before: 0.28971014677665063, After: 0.28970944...   \n",
       "plane     Before: 0.38405259310022044, After: 1.00000000...   \n",
       "car       Before: 0.2597415410728325, After: 0.354037032...   \n",
       "doctor    Before: 0.13439994429915442, After: 0.21833826...   \n",
       "nurse     Before: 0.12790409339777273, After: 0.28236372...   \n",
       "love      Before: 0.09505575751009387, After: 0.32852584...   \n",
       "sex       Before: 0.10212970436490482, After: 0.11862340...   \n",
       "\n",
       "                                                        car  \\\n",
       "cat       Before: 0.136072027917602, After: 0.2634861035...   \n",
       "tiger     Before: 0.16119598769364896, After: 0.10033040...   \n",
       "computer  Before: 0.26826894486108244, After: 0.22732308...   \n",
       "keyboard  Before: 0.15750632650840493, After: 0.15750846...   \n",
       "plane     Before: 0.3219357387657039, After: 0.354037032...   \n",
       "car       Before: 0.6158574248530795, After: 1.000000000...   \n",
       "doctor    Before: 0.09431570687955, After: 0.19190468704...   \n",
       "nurse     Before: 0.07363428182232754, After: 0.16077850...   \n",
       "love      Before: 0.11200247669649024, After: 0.24947266...   \n",
       "sex       Before: 0.13403080874265905, After: 0.06629354...   \n",
       "\n",
       "                                                     doctor  \\\n",
       "cat       Before: 0.16547475026405636, After: 0.34338708...   \n",
       "tiger     Before: 0.0774108002811773, After: 0.089083542...   \n",
       "computer  Before: 0.18039329196329013, After: 0.20986951...   \n",
       "keyboard  Before: 0.13804955762057758, After: 0.13804958...   \n",
       "plane     Before: 0.15146728859985834, After: 0.21833826...   \n",
       "car       Before: 0.13778205919388814, After: 0.19190468...   \n",
       "doctor               Before: 0.6128107065755533, After: 1.0   \n",
       "nurse     Before: 0.4308149649767604, After: 0.344486463...   \n",
       "love      Before: 0.14771102908578468, After: 0.33078374...   \n",
       "sex       Before: 0.1436405909297276, After: 0.175547118...   \n",
       "\n",
       "                                                      nurse  \\\n",
       "cat       Before: 0.24690899138830727, After: 0.54854860...   \n",
       "tiger     Before: 0.1697249630498177, After: 0.202597136...   \n",
       "computer  Before: 0.09297679298707379, After: 0.12068024...   \n",
       "keyboard  Before: 0.16678031434047627, After: 0.16678347...   \n",
       "plane     Before: 0.10589313234551631, After: 0.28236372...   \n",
       "car       Before: 0.0865221800713605, After: 0.160778501...   \n",
       "doctor    Before: 0.27845097194129365, After: 0.34448646...   \n",
       "nurse     Before: 0.378466332225932, After: 1.0000000000...   \n",
       "love      Before: 0.3033847603340788, After: 0.544714533...   \n",
       "sex       Before: 0.26868181343357167, After: 0.40912927...   \n",
       "\n",
       "                                                       love  \\\n",
       "cat       Before: 0.2989067535773432, After: 0.594053102...   \n",
       "tiger     Before: 0.17516455047450735, After: 0.19102605...   \n",
       "computer  Before: 0.1168711356729625, After: 0.234808759...   \n",
       "keyboard  Before: 0.27407501845767246, After: 0.27407454...   \n",
       "plane     Before: 0.1936940498815496, After: 0.328525840...   \n",
       "car       Before: 0.22133439390681858, After: 0.24947266...   \n",
       "doctor    Before: 0.19325643013428553, After: 0.33078374...   \n",
       "nurse     Before: 0.1708752362535986, After: 0.544714533...   \n",
       "love      Before: 0.6110191309495465, After: 0.999999999...   \n",
       "sex       Before: 0.3049306009871644, After: 0.361647126...   \n",
       "\n",
       "                                                        sex  \n",
       "cat       Before: 0.1093022564011111, After: 0.259890845...  \n",
       "tiger     Before: 0.14518818082220147, After: 0.18807845...  \n",
       "computer  Before: 0.1158779845883439, After: 0.076953257...  \n",
       "keyboard  Before: 0.10639718565916091, After: 0.10639914...  \n",
       "plane     Before: 0.05697047025775614, After: 0.11862340...  \n",
       "car       Before: 0.059270287407368415, After: 0.0662935...  \n",
       "doctor    Before: 0.0745189116843016, After: 0.175547118...  \n",
       "nurse     Before: 0.1264203000118017, After: 0.409129275...  \n",
       "love      Before: 0.30399420253175347, After: 0.36164712...  \n",
       "sex                  Before: 0.4896246955281065, After: 1.0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score before retrofitting\n",
    "        similarity_before = cosine_sim[word1_index, word2_index]\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Before: {similarity_before}, After: {similarity_after}\"\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Retrofitting: 0.20, Human: 0.73</td>\n",
       "      <td>Retrofitting: 1.00, Human: 1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.24, Human: 0.76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.35, Human: 0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.34, Human: 0.70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.36, Human: 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cat                            tiger  \\\n",
       "cat                                  None                             None   \n",
       "tiger     Retrofitting: 0.20, Human: 0.73  Retrofitting: 1.00, Human: 1.00   \n",
       "computer                             None                             None   \n",
       "keyboard                             None                             None   \n",
       "plane                                None                             None   \n",
       "car                                  None                             None   \n",
       "doctor                               None                             None   \n",
       "nurse                                None                             None   \n",
       "love                                 None                             None   \n",
       "sex                                  None                             None   \n",
       "\n",
       "         computer                         keyboard plane  \\\n",
       "cat          None                             None  None   \n",
       "tiger        None                             None  None   \n",
       "computer     None  Retrofitting: 0.24, Human: 0.76  None   \n",
       "keyboard     None                             None  None   \n",
       "plane        None                             None  None   \n",
       "car          None                             None  None   \n",
       "doctor       None                             None  None   \n",
       "nurse        None                             None  None   \n",
       "love         None                             None  None   \n",
       "sex          None                             None  None   \n",
       "\n",
       "                                      car doctor  \\\n",
       "cat                                  None   None   \n",
       "tiger                                None   None   \n",
       "computer                             None   None   \n",
       "keyboard                             None   None   \n",
       "plane     Retrofitting: 0.35, Human: 0.58   None   \n",
       "car                                  None   None   \n",
       "doctor                               None   None   \n",
       "nurse                                None   None   \n",
       "love                                 None   None   \n",
       "sex                                  None   None   \n",
       "\n",
       "                                    nurse  love  \\\n",
       "cat                                  None  None   \n",
       "tiger                                None  None   \n",
       "computer                             None  None   \n",
       "keyboard                             None  None   \n",
       "plane                                None  None   \n",
       "car                                  None  None   \n",
       "doctor    Retrofitting: 0.34, Human: 0.70  None   \n",
       "nurse                                None  None   \n",
       "love                                 None  None   \n",
       "sex                                  None  None   \n",
       "\n",
       "                                      sex  \n",
       "cat                                  None  \n",
       "tiger                                None  \n",
       "computer                             None  \n",
       "keyboard                             None  \n",
       "plane                                None  \n",
       "car                                  None  \n",
       "doctor                               None  \n",
       "nurse                                None  \n",
       "love      Retrofitting: 0.36, Human: 0.68  \n",
       "sex                                  None  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation scores from the file\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as eval_file:\n",
    "    for line in eval_file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Retrieve the evaluation score for the word pair\n",
    "        score = eval_scores.get((word1, word2))\n",
    "\n",
    "        # Scale the human score between 0 and 1\n",
    "        if score is not None:\n",
    "            scaled_score = score / 10.0\n",
    "        else:\n",
    "            scaled_score = None\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Retrofitting: {similarity_after:.2f}, Human: {scaled_score:.2f}\" if scaled_score is not None else None\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n"
     ]
    }
   ],
   "source": [
    "wordVecs_gensim = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "lexical_similarity = read_lexicon(\"../data/English/lexicon/ws353_lexical_similarity.txt\")\n",
    "output_file = \"../data/English/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_neighbors_embedding_matrix0(wordVecs, wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "\n",
    "    # Create a set of valid neighbors\n",
    "    valid_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors) & set(wordList)\n",
    "    \n",
    "    # Get the embedding size\n",
    "    embedding_size = 250 #wordVecs[next(iter(wordVecs))].shape[0]\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        if neighbors and any(neighbor in valid_neighbors for neighbor in neighbors):\n",
    "            embeddings = np.array([\n",
    "                wordVecs[wordList.index(neighbor)]\n",
    "                for neighbor in neighbors\n",
    "                if neighbor in valid_neighbors\n",
    "            ])\n",
    "            average_embedding = np.mean(embeddings, axis=0)\n",
    "            average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_neighbors_embedding_matrix(wordVecMat, wordList, relation_type, lang):\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type, lang)\n",
    "    valid_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors) & set(wordList)\n",
    "\n",
    "    embedding_size = wordVecMat.shape[1]\n",
    "    average_embeddings = []\n",
    "\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        if neighbors and any(neighbor in valid_neighbors for neighbor in neighbors):\n",
    "            embeddings = np.array([\n",
    "                wordVecMat[wordList.index(neighbor)] if neighbor in wordList else np.zeros(embedding_size)\n",
    "                for neighbor in neighbors\n",
    "                if neighbor in valid_neighbors\n",
    "            ])\n",
    "            if embeddings.size > 0:\n",
    "                average_embedding = np.mean(embeddings, axis=0)\n",
    "                average_embeddings.append(average_embedding)\n",
    "        else:\n",
    "            average_embeddings.append(np.zeros(embedding_size))\n",
    "\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "    return neighbors_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList_gensim = get_embeddings_words(wordVecs_gensim)\n",
    "wordVecMat_gensim = convert_dict_to_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07520224 0.07037208 0.0224631  ... 0.03620975 0.02141031 0.15191107]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create a small subset of your wordVecs dictionary\n",
    "subset_wordVecs = {word: wordVecs_gensim[word] for word in wordList_gensim[:100]}\n",
    "subset_wordVecMat = wordVecMat_gensim[:100] \n",
    "\n",
    "# Create a small subset of your wordList\n",
    "subset_wordList = wordList_gensim[:100]\n",
    "\n",
    "# Test the function on the subset\n",
    "neighbors_matrix = retrieve_neighbors_embedding_matrix(subset_wordVecMat, subset_wordList, \"synonyms\")\n",
    "\n",
    "# Print the result\n",
    "print(neighbors_matrix)\n",
    "print(type(neighbors_matrix))  \n",
    "print(neighbors_matrix.shape)  \n",
    "print(neighbors_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_matrix_gensim = retrieve_neighbors_embedding_matrix(wordVecMat_gensim, wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix_gensim))  \n",
    "print(neighbors_matrix_gensim.shape)  \n",
    "print(neighbors_matrix_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat_gensim))  \n",
    "print(wordVecMat_gensim.shape) \n",
    "print(wordVecMat_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(wordVecMat))  \n",
    "print(wordVecMat.shape) \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_gensim = get_wordnet_lexicon(wordList_gensim, \"synonyms\", \"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)\n",
    "# retrofitted_similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_test(wordVecMat, neighbors_embedding_matrix, alpha=1, beta=1, nb_iter=10):\n",
    "    newWordVecMat = np.copy(wordVecMat)\n",
    "    for _ in range(nb_iter):\n",
    "        updates = alpha * neighbors_embedding_matrix + beta * newWordVecMat\n",
    "        newWordVecMat = updates / (alpha + beta)\n",
    "\n",
    "    return newWordVecMat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_wordVecs_gensim = retrofitting_wordVecs_test(wordVecMat_gensim, neighbors_matrix_gensim, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_cosine_similarity(X, Y, sample_size=10000):\n",
    "    np.random.seed(42)  # Set a random seed for reproducibility\n",
    "    sample_X = X[np.random.choice(X.shape[0], sample_size, replace=False)]\n",
    "    sample_Y = Y[np.random.choice(Y.shape[0], sample_size, replace=False)]\n",
    "    similarities = cosine_similarity(sample_X, sample_Y)\n",
    "    avg_cos_similarity = np.mean(similarities)\n",
    "    return avg_cos_similarity\n",
    "\n",
    "# Compute the average cosine similarity using a random sample\n",
    "avg_cos_similarity = calculate_average_cosine_similarity(wordVecMat_gensim, retrofitted_wordVecs_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15219916974877842"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cos_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/French/word_embeddings/vecs100-linear-frwiki \n"
     ]
    }
   ],
   "source": [
    "wordVecs_FR = read_word_vecs(\"../data/French/word_embeddings/vecs100-linear-frwiki\")\n",
    "lexical_similarity = read_lexicon(\"../data/French/lexicon/rg65_french.txt\")\n",
    "output_file = \"../data/French/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList_FR = get_embeddings_words(wordVecs_FR)\n",
    "wordVecMat_FR = convert_dict_to_matrix(wordVecs_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'f'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neighbors_matrix_FR \u001b[39m=\u001b[39m retrieve_neighbors_embedding_matrix(wordVecMat_FR, wordList_FR, \u001b[39m\"\u001b[39;49m\u001b[39msynonyms\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfra\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[135], line 2\u001b[0m, in \u001b[0;36mretrieve_neighbors_embedding_matrix\u001b[1;34m(wordVecMat, wordList, relation_type, lang)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mretrieve_neighbors_embedding_matrix\u001b[39m(wordVecMat, wordList, relation_type, lang):\n\u001b[1;32m----> 2\u001b[0m     neighbors_dict \u001b[39m=\u001b[39m get_wordnet_lexicon(wordList, relation_type, lang)\n\u001b[0;32m      3\u001b[0m     valid_neighbors \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(neighbor \u001b[39mfor\u001b[39;00m neighbors \u001b[39min\u001b[39;00m neighbors_dict\u001b[39m.\u001b[39mvalues() \u001b[39mfor\u001b[39;00m neighbor \u001b[39min\u001b[39;00m neighbors) \u001b[39m&\u001b[39m \u001b[39mset\u001b[39m(wordList)\n\u001b[0;32m      5\u001b[0m     embedding_size \u001b[39m=\u001b[39m wordVecMat\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[133], line 6\u001b[0m, in \u001b[0;36mget_wordnet_lexicon\u001b[1;34m(target_words, relation_types, lang)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m target_words:\n\u001b[0;32m      5\u001b[0m     related_words \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m     word_synsets \u001b[39m=\u001b[39m wordnet\u001b[39m.\u001b[39;49msynsets(word, lang)\n\u001b[0;32m      8\u001b[0m     \u001b[39m# Skip word if no synsets found\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m word_synsets:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1757\u001b[0m, in \u001b[0;36mWordNetCorpusReader.synsets\u001b[1;34m(self, lemma, pos, lang, check_exceptions)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m pos \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1756\u001b[0m         pos \u001b[39m=\u001b[39m POS_LIST\n\u001b[1;32m-> 1757\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m   1758\u001b[0m         get_synset(p, offset)\n\u001b[0;32m   1759\u001b[0m         \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pos\n\u001b[0;32m   1760\u001b[0m         \u001b[39mfor\u001b[39;00m form \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_morphy(lemma, p, check_exceptions)\n\u001b[0;32m   1761\u001b[0m         \u001b[39mfor\u001b[39;00m offset \u001b[39min\u001b[39;00m index[form]\u001b[39m.\u001b[39mget(p, [])\n\u001b[0;32m   1762\u001b[0m     ]\n\u001b[0;32m   1764\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1760\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m pos \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1756\u001b[0m         pos \u001b[39m=\u001b[39m POS_LIST\n\u001b[0;32m   1757\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m   1758\u001b[0m         get_synset(p, offset)\n\u001b[0;32m   1759\u001b[0m         \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m pos\n\u001b[1;32m-> 1760\u001b[0m         \u001b[39mfor\u001b[39;00m form \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_morphy(lemma, p, check_exceptions)\n\u001b[0;32m   1761\u001b[0m         \u001b[39mfor\u001b[39;00m offset \u001b[39min\u001b[39;00m index[form]\u001b[39m.\u001b[39mget(p, [])\n\u001b[0;32m   1762\u001b[0m     ]\n\u001b[0;32m   1764\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1765\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_lang_data(lang)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:2072\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   2064\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_morphy\u001b[39m(\u001b[39mself\u001b[39m, form, pos, check_exceptions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   2065\u001b[0m     \u001b[39m# from jordanbg:\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m     \u001b[39m# Given an original string x\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2069\u001b[0m     \u001b[39m# 3. If there are no matches, keep applying rules until you either\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m     \u001b[39m#    find a match or you can't go any further\u001b[39;00m\n\u001b[1;32m-> 2072\u001b[0m     exceptions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exception_map[pos]\n\u001b[0;32m   2073\u001b[0m     substitutions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMORPHOLOGICAL_SUBSTITUTIONS[pos]\n\u001b[0;32m   2075\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply_rules\u001b[39m(forms):\n",
      "\u001b[1;31mKeyError\u001b[0m: 'f'"
     ]
    }
   ],
   "source": [
    "neighbors_matrix_FR = retrieve_neighbors_embedding_matrix(wordVecMat_FR, wordList_FR, \"synonyms\", \"fra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_wordVecs_FR, updates_FR= retrofitting_wordVecs(wordVecMat_FR, neighbors_matrix_FR, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cos_similarity = calculate_average_cosine_similarity(wordVecMat_FR, retrofitted_wordVecs_FR)\n",
    "avg_cos_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
