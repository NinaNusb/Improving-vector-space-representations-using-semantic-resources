{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, matutils\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained Word2Vec model\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "\n",
    "def norm_word(word):\n",
    "  \"\"\"\n",
    "  - input: word\n",
    "  - return: a normalized version of it\n",
    "  Normalization process: includes checking if the word is a number or a punctuation mark and replacing it with special tokens\n",
    "  \"\"\"\n",
    "  if isNumber.search(word.lower()):\n",
    "    return '---num---'\n",
    "  # check if the word consists only of non-alphanumeric characters by removing all non-alphanumeric characters from the word \n",
    "  # and checking if the result is an empty string\n",
    "  elif re.sub(r'\\W+', '', word) == '':\n",
    "    return '---punc---'\n",
    "  else:\n",
    "  # if input word not a number nor a punctuation mark, return a lowercase version of input word\n",
    "    return word.lower()\n",
    "  \n",
    "\n",
    "  \n",
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors\n",
    "\n",
    "  ''' Write word vectors to file '''\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "  \"\"\"\n",
    "  - input: a dictionary wordVectors where keys are words and values are their corresponding word vectors\n",
    "           file name outFileName\n",
    "  \"\"\"\n",
    "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "  outFile = open(outFileName, 'w', encoding= 'utf-8')  \n",
    "  for word, values in wordVectors.items():\n",
    "    outFile.write(word+' ')\n",
    "    for val in wordVectors[word]:\n",
    "      # write the word vectors to the ouptut file in the format:\n",
    "      # word1 val1 val2 val3 ...\n",
    "      # word2 val1 val2 val3 ...\n",
    "      # ...\n",
    "      outFile.write('%.4f' %(val)+' ')\n",
    "    outFile.write('\\n')      \n",
    "  outFile.close()\n",
    "\n",
    "''' Read the PPDB word relations as a dictionary '''\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.lower().strip().split()\n",
    "            lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the same format for the toy corpus as for the provided word embeddings\n",
    "def convert_matrix_to_dict(wordVecMat, wordList):\n",
    "    wordVecs = {}\n",
    "\n",
    "    for i, word in enumerate(wordList):\n",
    "        wordVecs[word] = wordVecMat[i]\n",
    "\n",
    "    return wordVecs\n",
    "\n",
    "def convert_dict_to_matrix(wordVecs):\n",
    "    wordVecMat = np.array(list(wordVecs.values()))\n",
    "\n",
    "    # Reshape the matrix if it is one-dimensional\n",
    "    # if wordVecMat.ndim == 1:\n",
    "    #     wordVecMat = wordVecMat.reshape(1, -1)\n",
    "\n",
    "    return wordVecMat\n",
    "\n",
    "def vectorize_list(corpus):\n",
    "    corpus_vecs = [model[word] for word in corpus]\n",
    "\n",
    "    return corpus_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same input format as the real corpus\n",
    "toy_corpus = [\"cat\", \"tiger\", \"computer\", \"keyboard\", \"plane\", \"car\", \"doctor\", \"nurse\", \"love\", \"sex\"]\n",
    "toy_corpus_list_vecs = vectorize_list(toy_corpus)\n",
    "toy_wordVecs = convert_matrix_to_dict(toy_corpus_list_vecs, toy_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    similarity = dot_product / norm_product\n",
    "    return similarity\n",
    "\n",
    "def generate_cosine_similarity_matrix(dict_vecs): \n",
    "    num_vectors = len(dict_vecs)\n",
    "    similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "    for i, word1 in enumerate(dict_vecs):\n",
    "        for j, word2 in enumerate(dict_vecs):\n",
    "            similarity_matrix[i, j] = calculate_cosine_similarity(dict_vecs[word1], dict_vecs[word2])\n",
    "    return similarity_matrix\n",
    "\n",
    "def print_vec_similarities(wordList, similarity_matrix):\n",
    "    for word, vec in zip(wordList, similarity_matrix):\n",
    "        print(f'Similarities with \"{word}\":')\n",
    "        for i in range(len(vec)):\n",
    "            similarity = vec[i]\n",
    "            print(f'  - \"{wordList[i]}\": {similarity:.4f}')\n",
    "        print()\n",
    "\n",
    "def print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix):\n",
    "    difference = np.abs(similarity_matrix - retrofitted_similarity_matrix)\n",
    "    print(\"Similarity Difference Matrix:\")\n",
    "    print(difference)\n",
    "\n",
    "def cosine_similarity_matrix(matrix1, matrix2):\n",
    "    dot_product = np.sum(matrix1 * matrix2)\n",
    "    norm_matrix1 = np.linalg.norm(matrix1)\n",
    "    norm_matrix2 = np.linalg.norm(matrix2)\n",
    "    cosine_similarity = dot_product / (norm_matrix1 * norm_matrix2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon(target_words, relation_types):\n",
    "    lexicon = {}\n",
    "\n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"antonyms\" in relation_types:\n",
    "                if syn.lemmas()[0].antonyms():\n",
    "                    related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "            if \"hyponyms\" in relation_types:\n",
    "                for hypo in syn.hyponyms():\n",
    "                    for lemma in hypo.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"hypernyms\" in relation_types:\n",
    "                for hyper in syn.hypernyms():\n",
    "                    for lemma in hyper.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"meronyms\" in relation_types:\n",
    "                for part in syn.part_meronyms():\n",
    "                    for lemma in part.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"holonyms\" in relation_types:\n",
    "                for whole in syn.part_holonyms():\n",
    "                    for lemma in whole.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"homonyms\" in relation_types:\n",
    "                for lemma in syn.lemmas():\n",
    "                    if lemma.name() != word:\n",
    "                        homonyms = wordnet.lemmas(lemma.name())\n",
    "                        for homonym in homonyms:\n",
    "                            related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecMat = convert_dict_to_matrix(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(toy_corpus_list_vecs)) \n",
    "\n",
    "print(type(wordVecMat)) \n",
    "print(wordVecMat.shape)  \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 10)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(similarity_matrix)) \n",
    "print(similarity_matrix.shape)  \n",
    "print(similarity_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for the big corpus to retrive the word list from the keys\n",
    "def get_embeddings_words(wordVecs):\n",
    "    wordList = list(wordVecs.keys()) # TODO: or set?\n",
    "    return wordList\n",
    "\n",
    "wordList = get_embeddings_words(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbors_embedding_matrix(wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        embeddings = [\n",
    "            model.get_vector(neighbor)\n",
    "            for neighbor in neighbors\n",
    "            if model.has_index_for(neighbor)\n",
    "        ]\n",
    "        if len(embeddings) > 0:\n",
    "            average_embedding = np.sum(embeddings, axis=0) / len(embeddings)\n",
    "        else:\n",
    "            # Handle the case where a word has no embeddings for its synonyms\n",
    "            average_embedding = np.zeros(model.vector_size)  # Use a zero vector\n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix\n",
    "\n",
    "   \n",
    "    \n",
    "neighbors_matrix = create_neighbors_embedding_matrix(wordList, \"synonyms\")\n",
    "\n",
    "# récupérer la liste des syn dans wordnet\n",
    "# vectorise chaque syn\n",
    "# BOW des synonymes (sum) pour n'avoir qu'un embedding \n",
    "# BOW_syn_cat\n",
    "# BOW_syn_dog= neighbors_matrix, shape (10, embedding_size) donc same size as wordVecs_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix))  # <class 'numpy.ndarray'>\n",
    "print(neighbors_matrix.shape)  # (m, n)\n",
    "print(neighbors_matrix.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  # <class 'numpy.ndarray'>\n",
    "print(wordVecMat.shape)  # (m, n)\n",
    "print(wordVecMat.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00676925  0.17245371 -0.32560504 -0.02995695  0.24918167  0.06591797\n",
      "  0.07754347  0.02062197  0.12026186 -0.24899179  0.11663705 -0.43598995\n",
      " -0.0165247  -0.43618888  0.05141873 -0.2046328   0.09973597  0.0461245\n",
      " -0.4420053   0.08787028  0.26338252 -0.1518453   0.11536521 -0.14642108\n",
      " -0.04931188  0.32405486 -0.15808557  0.31547716  0.40427201 -0.007934\n",
      " -0.00195312 -0.20903128 -0.03433369 -0.0849519   0.01340795  0.15198545\n",
      " -0.07754234  0.04350902  0.00148463  0.24564164  0.00093107  0.03174506\n",
      " -0.14347048  0.13828702  0.08990253 -0.03038646  0.37447442 -0.05503337\n",
      "  0.00611821  0.00164738 -0.15880896  0.13665545  0.34953252  0.14862174\n",
      " -0.0103189  -0.14141733  0.15832859 -0.30018898  0.35803392  0.18776052\n",
      "  0.28351056  0.18667716 -0.01274052  0.19207764  0.04131345  0.04772498\n",
      "  0.20808016  0.02882668 -0.10890771 -0.12867793  0.40634721 -0.03548855\n",
      " -0.15468343 -0.01318077 -0.11528298  0.38514766  0.11844098 -0.08239746\n",
      " -0.02005401 -0.06692618  0.08503554 -0.00346544  0.1995228  -0.07893711\n",
      " -0.34383251  0.04050474 -0.2636391  -0.14694101 -0.1783899  -0.0918257\n",
      " -0.0131429   0.04139088 -0.06987395 -0.25662345 -0.17748967 -0.27476671\n",
      " -0.01672363 -0.17666287 -0.33676034 -0.18375199 -0.24108435 -0.02301817\n",
      " -0.0048376   0.25613178  0.07612101 -0.20470513  0.0953064  -0.03844798\n",
      "  0.04892759 -0.11653646 -0.07707384  0.29826298  0.11636692  0.32834201\n",
      " -0.31238471 -0.00066913 -0.02505154 -0.23873901 -0.22574163 -0.04350577\n",
      " -0.03468753 -0.05264395 -0.30785455  0.02505323 -0.34844179  0.11226626\n",
      "  0.10000073  0.1189044   0.04702872 -0.14758527  0.13923419  0.04321967\n",
      " -0.15519799 -0.06542969 -0.02879789 -0.11844042 -0.02837584  0.09594444\n",
      "  0.10183038  0.10198523 -0.06081022  0.02417896 -0.15294054  0.04794516\n",
      "  0.06066442  0.15922716 -0.19703731  0.17048589 -0.12367983 -0.15320898\n",
      "  0.22272971  0.09056261 -0.31849727 -0.08702935 -0.13079947 -0.05045121\n",
      "  0.09113679  0.05342385  0.03645833  0.22512252 -0.10272612 -0.05701814\n",
      "  0.09566696 -0.13046604 -0.12130398  0.00603117 -0.04856138  0.21248373\n",
      "  0.17837637  0.02974899 -0.08555999 -0.03059218 -0.04345082  0.23660165\n",
      " -0.08013295  0.09815696  0.07034867 -0.12642416 -0.242515    0.27940539\n",
      " -0.16617132  0.01541816 -0.00099126  0.0524677  -0.03739194  0.07791251\n",
      "  0.20973601  0.3004286   0.12838844  0.06714884  0.02089154 -0.16434733\n",
      "  0.12680845  0.06278935 -0.01593244  0.184226    0.07969835 -0.18987359\n",
      " -0.11193918  0.18708067  0.06552409 -0.27893744 -0.0675354  -0.05583897\n",
      "  0.04787643  0.11910897 -0.01438636 -0.13045473  0.10323758 -0.26696325\n",
      " -0.40234262 -0.02973316 -0.0515894  -0.08254327 -0.11705977 -0.0447789\n",
      "  0.16213056 -0.31804127 -0.10855222  0.12037037  0.18612897  0.11705413\n",
      " -0.22371081 -0.27236599 -0.2145137  -0.07454851  0.07460587 -0.07304269\n",
      "  0.22288344  0.00952374  0.10791355  0.03955135 -0.03007846  0.04184525\n",
      " -0.28511386  0.05631058  0.27960488  0.02073415 -0.08864961  0.066971\n",
      "  0.23477738 -0.20298824  0.03927584  0.03217344  0.33202221  0.05400481\n",
      "  0.05493726 -0.036039    0.22249632 -0.13921215 -0.33608415  0.18813239\n",
      " -0.28481038  0.02863178 -0.04690326  0.27920871 -0.1286395   0.1268627\n",
      " -0.15716192  0.07503933 -0.08402846  0.04506429 -0.04430474 -0.1314799\n",
      "  0.06542573  0.24106775 -0.10216381  0.02992079 -0.27746017 -0.02798801\n",
      " -0.07106696  0.04219563 -0.15462466  0.13976994  0.05472141  0.09482377\n",
      "  0.1267994   0.16184228  0.17293295 -0.14490651  0.2610078   0.05841742\n",
      " -0.20719062  0.28466684  0.13873743 -0.08083654 -0.09813182  0.04846644\n",
      "  0.08657498  0.13033097 -0.25310149  0.11868851 -0.1590384   0.03733656\n",
      "  0.42320421 -0.01760412  0.18546778  0.49357605 -0.276461    0.01063255]\n"
     ]
    }
   ],
   "source": [
    "difference = toy_corpus_vecs[0] - neighbors_matrix[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs(wordVecMat, neighbors_mean_matrix, alpha, beta, nb_iter):\n",
    "    # Create a deep copy of wordVecMat \n",
    "    newWordVecMat = np.copy(wordVecMat, order='K')\n",
    "    updates = []\n",
    "    \n",
    "    for _ in range(nb_iter):\n",
    "        # Calculate the number of neighbors for each word\n",
    "        # numNeighbors = np.sum(neighbors_mean_matrix != 0, axis=1)\n",
    "        \n",
    "        # Update the word embeddings using retrofitting formula\n",
    "        newWordVecMat = (alpha * newWordVecMat + beta * neighbors_mean_matrix) / (alpha + beta)\n",
    "\n",
    "        # Calculate the updates\n",
    "        update = newWordVecMat - wordVecMat\n",
    "        updates.append(update)\n",
    "\n",
    "        # Update the wordVecMat for the next iteration\n",
    "        wordVecMat = newWordVecMat\n",
    "\n",
    "        # Stoping criterion\n",
    "        if np.linalg.norm(updates) < 1e-2:\n",
    "            break # TODO: return the embedding\n",
    "\n",
    "    # Convert the matrix back to a dictionary of word vectors\n",
    "    # retrofitted_wordVecs = dict(zip(wordList, wordVecMat))\n",
    "\n",
    "    return newWordVecMat, updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'puke': ['cat'],\n",
       " 'upchuck': ['cat'],\n",
       " 'physician': ['doctor'],\n",
       " 'big_cat': ['cat'],\n",
       " 'disgorge': ['cat'],\n",
       " 'honk': ['cat'],\n",
       " 'fix': ['doctor'],\n",
       " 'barf': ['cat'],\n",
       " 'sex': ['turn_on',\n",
       "  'wind_up',\n",
       "  'sexual_urge',\n",
       "  'gender',\n",
       "  'sexual_practice',\n",
       "  'sexuality',\n",
       "  'arouse',\n",
       "  'excite',\n",
       "  'sexual_activity',\n",
       "  'sex_activity'],\n",
       " 'sexuality': ['sex'],\n",
       " 'computed_tomography': ['cat'],\n",
       " 'harbour': ['nurse'],\n",
       " 'jazz': ['love'],\n",
       " 'touch_on': ['doctor'],\n",
       " 'sleep_with': ['love'],\n",
       " 'quat': ['cat'],\n",
       " 'sophisticate': ['doctor'],\n",
       " 'information_processing_system': ['computer'],\n",
       " 'beloved': ['love'],\n",
       " 'gondola': ['car'],\n",
       " 'computing_machine': ['computer'],\n",
       " 'planer': ['plane'],\n",
       " 'aeroplane': ['plane'],\n",
       " 'nursemaid': ['nurse'],\n",
       " 'have_a_go_at_it': ['love'],\n",
       " 'spue': ['cat'],\n",
       " 'purge': ['cat'],\n",
       " 'guy': ['cat'],\n",
       " 'computed_axial_tomography': ['cat'],\n",
       " 'fuck': ['love'],\n",
       " 'railroad_car': ['car'],\n",
       " 'turn_on': ['sex'],\n",
       " 'Doctor': ['doctor'],\n",
       " 'khat': ['cat'],\n",
       " 'restore': ['doctor'],\n",
       " 'woodworking_plane': ['plane'],\n",
       " 'spew': ['cat'],\n",
       " 'repair': ['doctor'],\n",
       " 'do_it': ['love'],\n",
       " 'have_it_away': ['love'],\n",
       " 'breastfeed': ['nurse'],\n",
       " 'erotic_love': ['love'],\n",
       " 'vomit': ['cat'],\n",
       " 'data_processor': ['computer'],\n",
       " 'Arabian_tea': ['cat'],\n",
       " 'lie_with': ['love'],\n",
       " 'sexual_love': ['love'],\n",
       " 'excite': ['sex'],\n",
       " 'motorcar': ['car'],\n",
       " 'figurer': ['computer'],\n",
       " 'entertain': ['nurse'],\n",
       " 'retch': ['cat'],\n",
       " 'car': ['railcar',\n",
       "  'railroad_car',\n",
       "  'gondola',\n",
       "  'elevator_car',\n",
       "  'cable_car',\n",
       "  'motorcar',\n",
       "  'railway_car',\n",
       "  'auto',\n",
       "  'machine',\n",
       "  'automobile'],\n",
       " 'Panthera_tigris': ['tiger'],\n",
       " 'have_intercourse': ['love'],\n",
       " 'wet-nurse': ['nurse'],\n",
       " 'shave': ['plane'],\n",
       " 'nurse': ['harbor',\n",
       "  'give_suck',\n",
       "  'hold',\n",
       "  'suck',\n",
       "  'lactate',\n",
       "  'harbour',\n",
       "  'suckle',\n",
       "  'entertain',\n",
       "  'nursemaid',\n",
       "  'breastfeed',\n",
       "  'nanny',\n",
       "  'wet-nurse'],\n",
       " 'computerized_tomography': ['cat'],\n",
       " 'sexual_practice': ['sex'],\n",
       " 'sexual_activity': ['sex'],\n",
       " 'Caterpillar': ['cat'],\n",
       " 'plane': ['shave',\n",
       "  'airplane',\n",
       "  'woodworking_plane',\n",
       "  'planer',\n",
       "  'sheet',\n",
       "  'skim',\n",
       "  'aeroplane',\n",
       "  'flat',\n",
       "  \"carpenter's_plane\",\n",
       "  'planing_machine',\n",
       "  'level'],\n",
       " 'bed': ['love'],\n",
       " 'calculator': ['computer'],\n",
       " 'automobile': ['car'],\n",
       " 'bushel': ['doctor'],\n",
       " 'lovemaking': ['love'],\n",
       " 'hold': ['nurse'],\n",
       " 'sexual_urge': ['sex'],\n",
       " 'arouse': ['sex'],\n",
       " 'kat': ['cat'],\n",
       " 'hump': ['love'],\n",
       " 'wind_up': ['sex'],\n",
       " 'make_out': ['love'],\n",
       " 'harbor': ['nurse'],\n",
       " 'enjoy': ['love'],\n",
       " 'eff': ['love'],\n",
       " 'true_cat': ['cat'],\n",
       " 'love_life': ['love'],\n",
       " 'vomit_up': ['cat'],\n",
       " 'planing_machine': ['plane'],\n",
       " 'making_love': ['love'],\n",
       " 'doctor': ['bushel',\n",
       "  'Dr.',\n",
       "  'Doctor',\n",
       "  'sophisticate',\n",
       "  'physician',\n",
       "  'MD',\n",
       "  'restore',\n",
       "  'mend',\n",
       "  'repair',\n",
       "  'Doctor_of_the_Church',\n",
       "  'doc',\n",
       "  'doctor_up',\n",
       "  'medico',\n",
       "  'touch_on',\n",
       "  'furbish_up',\n",
       "  'fix'],\n",
       " 'sheet': ['plane'],\n",
       " 'flat': ['plane'],\n",
       " 'make_love': ['love'],\n",
       " 'dearest': ['love'],\n",
       " 'regorge': ['cat'],\n",
       " 'nanny': ['nurse'],\n",
       " 'bonk': ['love'],\n",
       " 'sex_activity': ['sex'],\n",
       " 'cat': ['be_sick',\n",
       "  'puke',\n",
       "  'upchuck',\n",
       "  'vomit',\n",
       "  'Arabian_tea',\n",
       "  'CAT',\n",
       "  'big_cat',\n",
       "  'disgorge',\n",
       "  'retch',\n",
       "  'honk',\n",
       "  'regorge',\n",
       "  'bozo',\n",
       "  'barf',\n",
       "  \"cat-o'-nine-tails\",\n",
       "  'computerized_tomography',\n",
       "  'computed_tomography',\n",
       "  'Caterpillar',\n",
       "  'hombre',\n",
       "  'quat',\n",
       "  'regurgitate',\n",
       "  'CT',\n",
       "  'qat',\n",
       "  'kat',\n",
       "  'African_tea',\n",
       "  'spue',\n",
       "  'purge',\n",
       "  'computed_axial_tomography',\n",
       "  'guy',\n",
       "  'sick',\n",
       "  'throw_up',\n",
       "  'khat',\n",
       "  'computerized_axial_tomography',\n",
       "  'spew',\n",
       "  'true_cat',\n",
       "  'vomit_up',\n",
       "  'cast',\n",
       "  'chuck'],\n",
       " \"cat-o'-nine-tails\": ['cat'],\n",
       " 'dear': ['love'],\n",
       " 'get_it_on': ['love'],\n",
       " 'roll_in_the_hay': ['love'],\n",
       " 'hombre': ['cat'],\n",
       " 'machine': ['car'],\n",
       " 'regurgitate': ['cat'],\n",
       " 'love': ['erotic_love',\n",
       "  'lie_with',\n",
       "  'sexual_love',\n",
       "  'make_love',\n",
       "  'dearest',\n",
       "  'bonk',\n",
       "  'have_intercourse',\n",
       "  'be_intimate',\n",
       "  'dear',\n",
       "  'get_it_on',\n",
       "  'jazz',\n",
       "  'bed',\n",
       "  'roll_in_the_hay',\n",
       "  'sleep_with',\n",
       "  'get_laid',\n",
       "  'beloved',\n",
       "  'lovemaking',\n",
       "  'honey',\n",
       "  'screw',\n",
       "  'have_sex',\n",
       "  'have_a_go_at_it',\n",
       "  'hump',\n",
       "  'know',\n",
       "  'fuck',\n",
       "  'passion',\n",
       "  'make_out',\n",
       "  'enjoy',\n",
       "  'sleep_together',\n",
       "  'eff',\n",
       "  'bang',\n",
       "  'love_life',\n",
       "  'have_it_off',\n",
       "  'do_it',\n",
       "  'have_it_away',\n",
       "  'making_love'],\n",
       " 'give_suck': ['nurse'],\n",
       " 'CT': ['cat'],\n",
       " 'Doctor_of_the_Church': ['doctor'],\n",
       " 'keyboard': [],\n",
       " 'skim': ['plane'],\n",
       " 'honey': ['love'],\n",
       " 'lactate': ['nurse'],\n",
       " 'screw': ['love'],\n",
       " 'African_tea': ['cat'],\n",
       " 'reckoner': ['computer'],\n",
       " 'passion': ['love'],\n",
       " 'throw_up': ['cat'],\n",
       " 'airplane': ['plane'],\n",
       " 'computerized_axial_tomography': ['cat'],\n",
       " 'gender': ['sex'],\n",
       " 'cable_car': ['car'],\n",
       " 'have_it_off': ['love'],\n",
       " \"carpenter's_plane\": ['plane'],\n",
       " 'medico': ['doctor'],\n",
       " 'chuck': ['cat'],\n",
       " 'computer': ['information_processing_system',\n",
       "  'computing_machine',\n",
       "  'estimator',\n",
       "  'data_processor',\n",
       "  'computing_device',\n",
       "  'figurer',\n",
       "  'calculator',\n",
       "  'electronic_computer',\n",
       "  'reckoner'],\n",
       " 'level': ['plane'],\n",
       " 'railcar': ['car'],\n",
       " 'Dr.': ['doctor'],\n",
       " 'be_sick': ['cat'],\n",
       " 'suck': ['nurse'],\n",
       " 'estimator': ['computer'],\n",
       " 'CAT': ['cat'],\n",
       " 'bozo': ['cat'],\n",
       " 'mend': ['doctor'],\n",
       " 'be_intimate': ['love'],\n",
       " 'suckle': ['nurse'],\n",
       " 'auto': ['car'],\n",
       " 'furbish_up': ['doctor'],\n",
       " 'get_laid': ['love'],\n",
       " 'tiger': ['Panthera_tigris'],\n",
       " 'MD': ['doctor'],\n",
       " 'elevator_car': ['car'],\n",
       " 'computing_device': ['computer'],\n",
       " 'qat': ['cat'],\n",
       " 'have_sex': ['love'],\n",
       " 'doc': ['doctor'],\n",
       " 'doctor_up': ['doctor'],\n",
       " 'know': ['love'],\n",
       " 'sick': ['cat'],\n",
       " 'sleep_together': ['love'],\n",
       " 'bang': ['love'],\n",
       " 'cast': ['cat'],\n",
       " 'railway_car': ['car'],\n",
       " 'electronic_computer': ['computer']}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_graph_from_synonyms(synonyms_dict):\n",
    "    graph = {}\n",
    "    \n",
    "    # Create a set of all unique words in the dictionary\n",
    "    words = set(synonyms_dict.keys()).union(*synonyms_dict.values())\n",
    "    \n",
    "    # Initialize an empty adjacency dictionary for each word\n",
    "    for word in words:\n",
    "        graph[word] = set()\n",
    "    \n",
    "    # Iterate through the synonyms dictionary\n",
    "    for word, synonyms in synonyms_dict.items():\n",
    "        # Add synonyms to the adjacency set for the word\n",
    "        graph[word].update(synonyms)\n",
    "        \n",
    "        # Add the word as a synonym to each synonym's adjacency set\n",
    "        for synonym in synonyms:\n",
    "            graph[synonym].add(word)\n",
    "    \n",
    "    # Convert the adjacency sets to lists\n",
    "    graph = {word: list(adjacency_set) for word, adjacency_set in graph.items()}\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = generate_graph_from_synonyms(lexicon)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_article(Q, Q_hat, graph, alpha, beta, num_iterations=10):\n",
    "    num_words = Q.shape[0]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        Q_new = np.zeros_like(Q)\n",
    "        for i in range(num_words):\n",
    "            neighbors = graph[i]\n",
    "            numerator = np.sum(beta[i, j] * Q[j] for j in neighbors) + alpha[i] * Q_hat[i]\n",
    "            denominator = np.sum(beta[i, j] for j in neighbors) + alpha[i]\n",
    "            Q_new[i] = numerator / denominator\n",
    "        Q = Q_new\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_toy_vecs, updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newVecs = retrofitting_wordVecs_article(wordVecMat, neighbors_matrix, graph, alpha=1, beta=1, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6\n",
      "Number of edges: 5\n",
      "Neighbors of cat: ['kitten', 'animal', 'pet']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_keep = [\"cat\", \"kitten\", \"dog\", \"puppy\", \"animal\", \"pet\"]\n",
    "# Construct an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_nodes_from(words_to_keep)\n",
    "\n",
    "# Add edges between related words\n",
    "graph.add_edges_from([('cat', 'kitten'), ('dog', 'puppy'), ('cat', 'animal'), ('dog', 'animal'), ('cat', 'pet')])\n",
    "\n",
    "# Print the graph information\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Access neighbors of a word\n",
    "word = 'cat'\n",
    "neighbors = graph.neighbors(word)\n",
    "print(\"Neighbors of\", word + \":\", list(neighbors))\n",
    "\n",
    "# Create the layout for the graph\n",
    "layout = nx.spring_layout(graph)\n",
    "\n",
    "# Draw the nodes\n",
    "nx.draw_networkx_nodes(graph, pos=layout, node_color='lightblue', node_size=500)\n",
    "\n",
    "# Draw the edges\n",
    "nx.draw_networkx_edges(graph, pos=layout, edge_color='gray')\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(graph, pos=layout, font_color='black')\n",
    "\n",
    "# Set plot properties\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00338463, -0.08622685,  0.16280252, ..., -0.24678802,\n",
       "          0.1382305 , -0.00531627],\n",
       "        [ 0.08007812, -0.06433105,  0.02783203, ..., -0.08123779,\n",
       "          0.03717041, -0.03466797],\n",
       "        [ 0.00255203,  0.02276611, -0.13401031, ..., -0.07601929,\n",
       "          0.05496216,  0.07133484],\n",
       "        ...,\n",
       "        [ 0.04763455,  0.11241319, -0.07042948, ..., -0.00129022,\n",
       "         -0.09945594, -0.13053046],\n",
       "        [-0.03367829,  0.04928064, -0.00994873, ...,  0.08418322,\n",
       "          0.06436348,  0.01234341],\n",
       "        [ 0.04439545, -0.02075195,  0.11517334, ..., -0.06329346,\n",
       "          0.06408691, -0.06994629]]),\n",
       " array([[-0.00169231, -0.04311343,  0.08140126, ..., -0.12339401,\n",
       "          0.06911525, -0.00265814],\n",
       "        [ 0.04003906, -0.03216553,  0.01391602, ..., -0.0406189 ,\n",
       "          0.01858521, -0.01733398],\n",
       "        [ 0.00127602,  0.01138306, -0.06700516, ..., -0.03800964,\n",
       "          0.02748108,  0.03566742],\n",
       "        ...,\n",
       "        [ 0.02381727,  0.0562066 , -0.03521474, ..., -0.00064511,\n",
       "         -0.04972797, -0.06526523],\n",
       "        [-0.01683915,  0.02464032, -0.00497437, ...,  0.04209161,\n",
       "          0.03218174,  0.0061717 ],\n",
       "        [ 0.02219772, -0.01037598,  0.05758667, ..., -0.03164673,\n",
       "          0.03204346, -0.03497314]]),\n",
       " array([[-0.00084616, -0.02155671,  0.04070063, ..., -0.06169701,\n",
       "          0.03455763, -0.00132907],\n",
       "        [ 0.02001953, -0.01608276,  0.00695801, ..., -0.02030945,\n",
       "          0.0092926 , -0.00866699],\n",
       "        [ 0.00063801,  0.00569153, -0.03350258, ..., -0.01900482,\n",
       "          0.01374054,  0.01783371],\n",
       "        ...,\n",
       "        [ 0.01190864,  0.0281033 , -0.01760737, ..., -0.00032255,\n",
       "         -0.02486398, -0.03263262],\n",
       "        [-0.00841957,  0.01232016, -0.00248718, ...,  0.0210458 ,\n",
       "          0.01609087,  0.00308585],\n",
       "        [ 0.01109886, -0.00518799,  0.02879333, ..., -0.01582336,\n",
       "          0.01602173, -0.01748657]]),\n",
       " array([[-0.00042308, -0.01077836,  0.02035031, ..., -0.0308485 ,\n",
       "          0.01727881, -0.00066453],\n",
       "        [ 0.01000977, -0.00804138,  0.003479  , ..., -0.01015472,\n",
       "          0.0046463 , -0.0043335 ],\n",
       "        [ 0.000319  ,  0.00284576, -0.01675129, ..., -0.00950241,\n",
       "          0.00687027,  0.00891685],\n",
       "        ...,\n",
       "        [ 0.00595432,  0.01405165, -0.00880369, ..., -0.00016128,\n",
       "         -0.01243199, -0.01631631],\n",
       "        [-0.00420979,  0.00616008, -0.00124359, ...,  0.0105229 ,\n",
       "          0.00804543,  0.00154293],\n",
       "        [ 0.00554943, -0.00259399,  0.01439667, ..., -0.00791168,\n",
       "          0.00801086, -0.00874329]]),\n",
       " array([[-2.11539096e-04, -5.38917829e-03,  1.01751575e-02, ...,\n",
       "         -1.54242516e-02,  8.63940627e-03, -3.32267140e-04],\n",
       "        [ 5.00488281e-03, -4.02069092e-03,  1.73950195e-03, ...,\n",
       "         -5.07736206e-03,  2.32315063e-03, -2.16674805e-03],\n",
       "        [ 1.59502029e-04,  1.42288208e-03, -8.37564468e-03, ...,\n",
       "         -4.75120544e-03,  3.43513489e-03,  4.45842743e-03],\n",
       "        ...,\n",
       "        [ 2.97715928e-03,  7.02582463e-03, -4.40184260e-03, ...,\n",
       "         -8.06384487e-05, -6.21599623e-03, -8.15815385e-03],\n",
       "        [-2.10489333e-03,  3.08004022e-03, -6.21795654e-04, ...,\n",
       "          5.26145101e-03,  4.02271748e-03,  7.71462917e-04],\n",
       "        [ 2.77471542e-03, -1.29699707e-03,  7.19833374e-03, ...,\n",
       "         -3.95584106e-03,  4.00543213e-03, -4.37164307e-03]]),\n",
       " array([[-1.05769548e-04, -2.69458914e-03,  5.08757873e-03, ...,\n",
       "         -7.71212578e-03,  4.31970314e-03, -1.66133570e-04],\n",
       "        [ 2.50244141e-03, -2.01034546e-03,  8.69750977e-04, ...,\n",
       "         -2.53868103e-03,  1.16157532e-03, -1.08337402e-03],\n",
       "        [ 7.97510147e-05,  7.11441040e-04, -4.18782234e-03, ...,\n",
       "         -2.37560272e-03,  1.71756744e-03,  2.22921371e-03],\n",
       "        ...,\n",
       "        [ 1.48857964e-03,  3.51291231e-03, -2.20092130e-03, ...,\n",
       "         -4.03192244e-05, -3.10799811e-03, -4.07907693e-03],\n",
       "        [-1.05244666e-03,  1.54002011e-03, -3.10897827e-04, ...,\n",
       "          2.63072550e-03,  2.01135874e-03,  3.85731459e-04],\n",
       "        [ 1.38735771e-03, -6.48498535e-04,  3.59916687e-03, ...,\n",
       "         -1.97792053e-03,  2.00271606e-03, -2.18582153e-03]]),\n",
       " array([[-5.28847740e-05, -1.34729457e-03,  2.54378936e-03, ...,\n",
       "         -3.85606289e-03,  2.15985157e-03, -8.30667850e-05],\n",
       "        [ 1.25122070e-03, -1.00517273e-03,  4.34875488e-04, ...,\n",
       "         -1.26934052e-03,  5.80787659e-04, -5.41687012e-04],\n",
       "        [ 3.98755074e-05,  3.55720520e-04, -2.09391117e-03, ...,\n",
       "         -1.18780136e-03,  8.58783722e-04,  1.11460686e-03],\n",
       "        ...,\n",
       "        [ 7.44289820e-04,  1.75645616e-03, -1.10046065e-03, ...,\n",
       "         -2.01596122e-05, -1.55399906e-03, -2.03953846e-03],\n",
       "        [-5.26223332e-04,  7.70010054e-04, -1.55448914e-04, ...,\n",
       "          1.31536275e-03,  1.00567937e-03,  1.92865729e-04],\n",
       "        [ 6.93678856e-04, -3.24249268e-04,  1.79958344e-03, ...,\n",
       "         -9.88960266e-04,  1.00135803e-03, -1.09291077e-03]]),\n",
       " array([[-2.64423870e-05, -6.73647286e-04,  1.27189468e-03, ...,\n",
       "         -1.92803144e-03,  1.07992578e-03, -4.15333925e-05],\n",
       "        [ 6.25610352e-04, -5.02586365e-04,  2.17437744e-04, ...,\n",
       "         -6.34670258e-04,  2.90393829e-04, -2.70843506e-04],\n",
       "        [ 1.99377537e-05,  1.77860260e-04, -1.04695559e-03, ...,\n",
       "         -5.93900681e-04,  4.29391861e-04,  5.57303429e-04],\n",
       "        ...,\n",
       "        [ 3.72144910e-04,  8.78228078e-04, -5.50230325e-04, ...,\n",
       "         -1.00798061e-05, -7.76999528e-04, -1.01976923e-03],\n",
       "        [-2.63111666e-04,  3.85005027e-04, -7.77244568e-05, ...,\n",
       "          6.57681376e-04,  5.02839684e-04,  9.64328647e-05],\n",
       "        [ 3.46839428e-04, -1.62124634e-04,  8.99791718e-04, ...,\n",
       "         -4.94480133e-04,  5.00679016e-04, -5.46455383e-04]]),\n",
       " array([[-1.32211935e-05, -3.36823643e-04,  6.35947341e-04, ...,\n",
       "         -9.64015722e-04,  5.39962892e-04, -2.07666963e-05],\n",
       "        [ 3.12805176e-04, -2.51293182e-04,  1.08718872e-04, ...,\n",
       "         -3.17335129e-04,  1.45196915e-04, -1.35421753e-04],\n",
       "        [ 9.96887684e-06,  8.89301300e-05, -5.23477793e-04, ...,\n",
       "         -2.96950340e-04,  2.14695930e-04,  2.78651714e-04],\n",
       "        ...,\n",
       "        [ 1.86072455e-04,  4.39114039e-04, -2.75115162e-04, ...,\n",
       "         -5.03990304e-06, -3.88499764e-04, -5.09884616e-04],\n",
       "        [-1.31555833e-04,  1.92502514e-04, -3.88622284e-05, ...,\n",
       "          3.28840688e-04,  2.51419842e-04,  4.82164323e-05],\n",
       "        [ 1.73419714e-04, -8.10623169e-05,  4.49895859e-04, ...,\n",
       "         -2.47240067e-04,  2.50339508e-04, -2.73227692e-04]]),\n",
       " array([[-6.61059676e-06, -1.68411822e-04,  3.17973670e-04, ...,\n",
       "         -4.82007861e-04,  2.69981446e-04, -1.03833481e-05],\n",
       "        [ 1.56402588e-04, -1.25646591e-04,  5.43594360e-05, ...,\n",
       "         -1.58667564e-04,  7.25984573e-05, -6.77108765e-05],\n",
       "        [ 4.98443842e-06,  4.44650650e-05, -2.61738896e-04, ...,\n",
       "         -1.48475170e-04,  1.07347965e-04,  1.39325857e-04],\n",
       "        ...,\n",
       "        [ 9.30362276e-05,  2.19557020e-04, -1.37557581e-04, ...,\n",
       "         -2.51995152e-06, -1.94249882e-04, -2.54942308e-04],\n",
       "        [-6.57779165e-05,  9.62512568e-05, -1.94311142e-05, ...,\n",
       "          1.64420344e-04,  1.25709921e-04,  2.41082162e-05],\n",
       "        [ 8.67098570e-05, -4.05311584e-05,  2.24947929e-04, ...,\n",
       "         -1.23620033e-04,  1.25169754e-04, -1.36613846e-04]])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.2028\n",
      "  - \"computer\": 0.1974\n",
      "  - \"keyboard\": 0.2057\n",
      "  - \"plane\": 0.3947\n",
      "  - \"car\": 0.2636\n",
      "  - \"doctor\": 0.3436\n",
      "  - \"nurse\": 0.5487\n",
      "  - \"love\": 0.5941\n",
      "  - \"sex\": 0.2601\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.2028\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0903\n",
      "  - \"keyboard\": 0.1831\n",
      "  - \"plane\": 0.0734\n",
      "  - \"car\": 0.1005\n",
      "  - \"doctor\": 0.0891\n",
      "  - \"nurse\": 0.2028\n",
      "  - \"love\": 0.1912\n",
      "  - \"sex\": 0.1883\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1974\n",
      "  - \"tiger\": 0.0903\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.2398\n",
      "  - \"plane\": 0.4086\n",
      "  - \"car\": 0.2276\n",
      "  - \"doctor\": 0.2100\n",
      "  - \"nurse\": 0.1209\n",
      "  - \"love\": 0.2347\n",
      "  - \"sex\": 0.0771\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2057\n",
      "  - \"tiger\": 0.1831\n",
      "  - \"computer\": 0.2398\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.2897\n",
      "  - \"car\": 0.1576\n",
      "  - \"doctor\": 0.1381\n",
      "  - \"nurse\": 0.1669\n",
      "  - \"love\": 0.2741\n",
      "  - \"sex\": 0.1065\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.3947\n",
      "  - \"tiger\": 0.0734\n",
      "  - \"computer\": 0.4086\n",
      "  - \"keyboard\": 0.2897\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3545\n",
      "  - \"doctor\": 0.2185\n",
      "  - \"nurse\": 0.2824\n",
      "  - \"love\": 0.3285\n",
      "  - \"sex\": 0.1187\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2636\n",
      "  - \"tiger\": 0.1005\n",
      "  - \"computer\": 0.2276\n",
      "  - \"keyboard\": 0.1576\n",
      "  - \"plane\": 0.3545\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1919\n",
      "  - \"nurse\": 0.1608\n",
      "  - \"love\": 0.2495\n",
      "  - \"sex\": 0.0665\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.3436\n",
      "  - \"tiger\": 0.0891\n",
      "  - \"computer\": 0.2100\n",
      "  - \"keyboard\": 0.1381\n",
      "  - \"plane\": 0.2185\n",
      "  - \"car\": 0.1919\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.3451\n",
      "  - \"love\": 0.3307\n",
      "  - \"sex\": 0.1756\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.5487\n",
      "  - \"tiger\": 0.2028\n",
      "  - \"computer\": 0.1209\n",
      "  - \"keyboard\": 0.1669\n",
      "  - \"plane\": 0.2824\n",
      "  - \"car\": 0.1608\n",
      "  - \"doctor\": 0.3451\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.5446\n",
      "  - \"sex\": 0.4092\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.5941\n",
      "  - \"tiger\": 0.1912\n",
      "  - \"computer\": 0.2347\n",
      "  - \"keyboard\": 0.2741\n",
      "  - \"plane\": 0.3285\n",
      "  - \"car\": 0.2495\n",
      "  - \"doctor\": 0.3307\n",
      "  - \"nurse\": 0.5446\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.3620\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2601\n",
      "  - \"tiger\": 0.1883\n",
      "  - \"computer\": 0.0771\n",
      "  - \"keyboard\": 0.1065\n",
      "  - \"plane\": 0.1187\n",
      "  - \"car\": 0.0665\n",
      "  - \"doctor\": 0.1756\n",
      "  - \"nurse\": 0.4092\n",
      "  - \"love\": 0.3620\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrofitted_toy_matrix = convert_dict_to_matrix(retrofitted_toy_vecs)\n",
    "retrofitted_similarity_matrix = generate_cosine_similarity_matrix(retrofitted_toy_vecs)\n",
    "print_vec_similarities(toy_corpus, retrofitted_similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.202819326843667"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrofitted_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.2028 (Difference: -0.3145)\n",
      "  - \"computer\": 0.1732 -> 0.1974 (Difference: 0.0241)\n",
      "  - \"keyboard\": 0.1834 -> 0.2057 (Difference: 0.0223)\n",
      "  - \"plane\": 0.1833 -> 0.3947 (Difference: 0.2114)\n",
      "  - \"car\": 0.2153 -> 0.2636 (Difference: 0.0483)\n",
      "  - \"doctor\": 0.1292 -> 0.3436 (Difference: 0.2144)\n",
      "  - \"nurse\": 0.1594 -> 0.5487 (Difference: 0.3893)\n",
      "  - \"love\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"sex\": 0.1368 -> 0.2601 (Difference: 0.1233)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.2028 (Difference: -0.3145)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"keyboard\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"plane\": 0.1660 -> 0.0734 (Difference: -0.0926)\n",
      "  - \"car\": 0.1672 -> 0.1005 (Difference: -0.0668)\n",
      "  - \"doctor\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"nurse\": 0.1111 -> 0.2028 (Difference: 0.0917)\n",
      "  - \"love\": 0.0871 -> 0.1912 (Difference: 0.1041)\n",
      "  - \"sex\": 0.2222 -> 0.1883 (Difference: -0.0339)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1974 (Difference: 0.0241)\n",
      "  - \"tiger\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.2398 (Difference: -0.1566)\n",
      "  - \"plane\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"car\": 0.2461 -> 0.2276 (Difference: -0.0185)\n",
      "  - \"doctor\": 0.1628 -> 0.2100 (Difference: 0.0472)\n",
      "  - \"nurse\": 0.2178 -> 0.1209 (Difference: -0.0969)\n",
      "  - \"love\": 0.0573 -> 0.2347 (Difference: 0.1774)\n",
      "  - \"sex\": 0.1853 -> 0.0771 (Difference: -0.1083)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2057 (Difference: 0.0223)\n",
      "  - \"tiger\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"computer\": 0.3964 -> 0.2398 (Difference: -0.1566)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.2897 (Difference: 0.1891)\n",
      "  - \"car\": 0.1498 -> 0.1576 (Difference: 0.0077)\n",
      "  - \"doctor\": 0.0850 -> 0.1381 (Difference: 0.0530)\n",
      "  - \"nurse\": 0.1220 -> 0.1669 (Difference: 0.0449)\n",
      "  - \"love\": 0.1591 -> 0.2741 (Difference: 0.1149)\n",
      "  - \"sex\": 0.0943 -> 0.1065 (Difference: 0.0122)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.3947 (Difference: 0.2114)\n",
      "  - \"tiger\": 0.1660 -> 0.0734 (Difference: -0.0926)\n",
      "  - \"computer\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"keyboard\": 0.1006 -> 0.2897 (Difference: 0.1891)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3545 (Difference: -0.0235)\n",
      "  - \"doctor\": 0.1879 -> 0.2185 (Difference: 0.0306)\n",
      "  - \"nurse\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"love\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"sex\": 0.0587 -> 0.1187 (Difference: 0.0600)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2636 (Difference: 0.0483)\n",
      "  - \"tiger\": 0.1672 -> 0.1005 (Difference: -0.0668)\n",
      "  - \"computer\": 0.2461 -> 0.2276 (Difference: -0.0185)\n",
      "  - \"keyboard\": 0.1498 -> 0.1576 (Difference: 0.0077)\n",
      "  - \"plane\": 0.3780 -> 0.3545 (Difference: -0.0235)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"nurse\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"love\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"sex\": 0.1169 -> 0.0665 (Difference: -0.0504)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.3436 (Difference: 0.2144)\n",
      "  - \"tiger\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"computer\": 0.1628 -> 0.2100 (Difference: 0.0472)\n",
      "  - \"keyboard\": 0.0850 -> 0.1381 (Difference: 0.0530)\n",
      "  - \"plane\": 0.1879 -> 0.2185 (Difference: 0.0306)\n",
      "  - \"car\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.3451 (Difference: -0.2868)\n",
      "  - \"love\": 0.0831 -> 0.3307 (Difference: 0.2476)\n",
      "  - \"sex\": 0.1994 -> 0.1756 (Difference: -0.0238)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.5487 (Difference: 0.3893)\n",
      "  - \"tiger\": 0.1111 -> 0.2028 (Difference: 0.0917)\n",
      "  - \"computer\": 0.2178 -> 0.1209 (Difference: -0.0969)\n",
      "  - \"keyboard\": 0.1220 -> 0.1669 (Difference: 0.0449)\n",
      "  - \"plane\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"car\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"doctor\": 0.6320 -> 0.3451 (Difference: -0.2868)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"love\": 0.0631 -> 0.5446 (Difference: 0.4815)\n",
      "  - \"sex\": 0.1997 -> 0.4092 (Difference: 0.2095)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"tiger\": 0.0871 -> 0.1912 (Difference: 0.1041)\n",
      "  - \"computer\": 0.0573 -> 0.2347 (Difference: 0.1774)\n",
      "  - \"keyboard\": 0.1591 -> 0.2741 (Difference: 0.1149)\n",
      "  - \"plane\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"car\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"doctor\": 0.0831 -> 0.3307 (Difference: 0.2476)\n",
      "  - \"nurse\": 0.0631 -> 0.5446 (Difference: 0.4815)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3620 (Difference: 0.0980)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2601 (Difference: 0.1233)\n",
      "  - \"tiger\": 0.2222 -> 0.1883 (Difference: -0.0339)\n",
      "  - \"computer\": 0.1853 -> 0.0771 (Difference: -0.1083)\n",
      "  - \"keyboard\": 0.0943 -> 0.1065 (Difference: 0.0122)\n",
      "  - \"plane\": 0.0587 -> 0.1187 (Difference: 0.0600)\n",
      "  - \"car\": 0.1169 -> 0.0665 (Difference: -0.0504)\n",
      "  - \"doctor\": 0.1994 -> 0.1756 (Difference: -0.0238)\n",
      "  - \"nurse\": 0.1997 -> 0.4092 (Difference: 0.2095)\n",
      "  - \"love\": 0.2639 -> 0.3620 (Difference: 0.0980)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "def print_vec_difference(wordList, similarity_matrix1, similarity_matrix2):\n",
    "    for i, word in enumerate(wordList):\n",
    "        print(f\"\\nSimilarities with \\\"{word}\\\":\")\n",
    "        for j, neighbor in enumerate(wordList):\n",
    "            similarity1 = similarity_matrix1[i, j]\n",
    "            similarity2 = similarity_matrix2[i, j]\n",
    "            difference = similarity2 - similarity1  # Calculate the difference\n",
    "            print(f\"  - \\\"{neighbor}\\\": {similarity1:.4f} -> {similarity2:.4f} (Difference: {difference:.4f})\")\n",
    "\n",
    "print_vec_difference(toy_corpus, similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Difference Matrix:\n",
      "[[2.22044605e-16 3.14476868e-01 2.41217867e-02 2.22933088e-02\n",
      "  2.11355107e-01 4.83279095e-02 2.14378839e-01 3.89320093e-01\n",
      "  4.53515643e-01 1.23285595e-01]\n",
      " [3.14476868e-01 2.22044605e-16 2.25892341e-02 1.17657636e-01\n",
      "  9.26185593e-02 6.67839173e-02 5.63388951e-03 9.16843459e-02\n",
      "  1.04134213e-01 3.39072019e-02]\n",
      " [2.41217867e-02 2.25892341e-02 1.19209290e-07 1.56634334e-01\n",
      "  2.17671595e-01 1.85491256e-02 4.72104928e-02 9.69479563e-02\n",
      "  1.77417493e-01 1.08268138e-01]\n",
      " [2.22933088e-02 1.17657636e-01 1.56634334e-01 0.00000000e+00\n",
      "  1.89135575e-01 7.73628855e-03 5.30468973e-02 4.48904136e-02\n",
      "  1.14945142e-01 1.21624538e-02]\n",
      " [2.11355107e-01 9.26185593e-02 2.17671595e-01 1.89135575e-01\n",
      "  1.19209289e-07 2.35002630e-02 3.06061912e-02 1.84610812e-01\n",
      "  2.20484199e-01 5.99760552e-02]\n",
      " [4.83279095e-02 6.67839173e-02 1.85491256e-02 7.73628855e-03\n",
      "  2.35002630e-02 5.96046448e-08 2.35511302e-03 3.02293567e-02\n",
      "  1.65307530e-01 5.03995492e-02]\n",
      " [2.14378839e-01 5.63388951e-03 4.72104928e-02 5.30468973e-02\n",
      "  3.06061912e-02 2.35511302e-03 0.00000000e+00 2.86839741e-01\n",
      "  2.47609503e-01 2.38474003e-02]\n",
      " [3.89320093e-01 9.16843459e-02 9.69479563e-02 4.48904136e-02\n",
      "  1.84610812e-01 3.02293567e-02 2.86839741e-01 1.11022302e-16\n",
      "  4.81536790e-01 2.09466050e-01]\n",
      " [4.53515643e-01 1.04134213e-01 1.77417493e-01 1.14945142e-01\n",
      "  2.20484199e-01 1.65307530e-01 2.47609503e-01 4.81536790e-01\n",
      "  0.00000000e+00 9.80384921e-02]\n",
      " [1.23285595e-01 3.39072019e-02 1.08268138e-01 1.21624538e-02\n",
      "  5.99760552e-02 5.03995492e-02 2.38474003e-02 2.09466050e-01\n",
      "  9.80384921e-02 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.4249422167016215\n"
     ]
    }
   ],
   "source": [
    "# Calculate cosine similarity between wordVecMat and retrofitted_toy_vec\n",
    "similarity_score = cosine_similarity_matrix(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Cosine Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average embedding update: 0.12658860989283166\n"
     ]
    }
   ],
   "source": [
    "def measure_embedding_updates(original_matrix, retrofitted_matrix):\n",
    "    absolute_diff = np.abs(original_matrix - retrofitted_matrix)\n",
    "    mean_absolute_diff = np.mean(absolute_diff)\n",
    "    return mean_absolute_diff\n",
    "\n",
    "# Example usage\n",
    "update_measure = measure_embedding_updates(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Average embedding update:\", update_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation score: 0.42055888661904023\n",
      "Pearson correlation score: 0.4232245375810048\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def spearman_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = spearmanr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "def pearson_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "similarity_score = spearman_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Spearman correlation score:\", similarity_score)\n",
    "similarity_score = pearson_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Pearson correlation score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 0.1, 'nb_iter': 1}\n",
      "Best Spearman correlation score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load human evaluation scores\n",
    "eval_file_path = r\"C:\\Users\\ninan\\OneDrive\\Bureau\\Université Paris Cité\\S2\\NLP project\\Improving-vector-space-representations-using-semantic-resources\\data\\English\\lexicon\\ws353_lexical_similarity.txt\"\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Find best values for hyperparameters\n",
    "best_similarity_score = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "iteration_count = 0\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1, 16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            cosine_sim = cosine_similarity(wordVecMat, retrofitted_toy_vec)\n",
    "\n",
    "            # Calculate Spearman correlation against human evaluation scores\n",
    "            eval_scores_list = []\n",
    "            cosine_sim_list = []\n",
    "            for (word1, word2), score in eval_scores.items():\n",
    "                if word1 in wordList and word2 in wordList:\n",
    "                    word1_index = wordList.index(word1)\n",
    "                    word2_index = wordList.index(word2)\n",
    "                    eval_scores_list.append(score)\n",
    "                    cosine_sim_list.append(cosine_sim[word1_index, word2_index])\n",
    "\n",
    "            # Check if there are valid pairs for comparison\n",
    "            if len(eval_scores_list) > 0 and len(cosine_sim_list) > 0:\n",
    "                correlation, _ = spearmanr(eval_scores_list, cosine_sim_list)\n",
    "                # print(\"alpha =\", alpha, \"beta =\", beta, \"nb_iter =\", nb_iter, \"correlation =\", correlation)\n",
    "\n",
    "                # Update best similarity score and parameters if improved\n",
    "                if correlation > best_similarity_score:\n",
    "                    best_similarity_score = correlation\n",
    "                    best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "            iteration_count += 1\n",
    "            if iteration_count >= 100:\n",
    "                break\n",
    "        if iteration_count >= 100:\n",
    "            break\n",
    "    if iteration_count >= 100:\n",
    "        break\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best Spearman correlation score:\", best_similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 1.1000000000000003, 'nb_iter': 15}\n",
      "Best embedding update: 0.12671235242449622\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters\n",
    "best_embed_update = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1,16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            embed_update = measure_embedding_updates(wordVecMat, retrofitted_toy_vec)\n",
    "            # print(\" alpha =\", alpha, \" beta=\", beta, \"nb_iter =\", nb_iter, \" similarity score =\", similarity_score)\n",
    "            if embed_update > best_embed_update:\n",
    "                best_embed_update = embed_update\n",
    "                best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best embedding update:\", best_embed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.2020\n",
      "  - \"computer\": 0.1972\n",
      "  - \"keyboard\": 0.2055\n",
      "  - \"plane\": 0.3945\n",
      "  - \"car\": 0.2635\n",
      "  - \"doctor\": 0.3434\n",
      "  - \"nurse\": 0.5485\n",
      "  - \"love\": 0.5941\n",
      "  - \"sex\": 0.2599\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.2020\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0903\n",
      "  - \"keyboard\": 0.1831\n",
      "  - \"plane\": 0.0731\n",
      "  - \"car\": 0.1003\n",
      "  - \"doctor\": 0.0891\n",
      "  - \"nurse\": 0.2026\n",
      "  - \"love\": 0.1910\n",
      "  - \"sex\": 0.1881\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1972\n",
      "  - \"tiger\": 0.0903\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.2393\n",
      "  - \"plane\": 0.4086\n",
      "  - \"car\": 0.2273\n",
      "  - \"doctor\": 0.2099\n",
      "  - \"nurse\": 0.1207\n",
      "  - \"love\": 0.2348\n",
      "  - \"sex\": 0.0769\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2055\n",
      "  - \"tiger\": 0.1831\n",
      "  - \"computer\": 0.2393\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.2897\n",
      "  - \"car\": 0.1575\n",
      "  - \"doctor\": 0.1380\n",
      "  - \"nurse\": 0.1668\n",
      "  - \"love\": 0.2741\n",
      "  - \"sex\": 0.1064\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.3945\n",
      "  - \"tiger\": 0.0731\n",
      "  - \"computer\": 0.4086\n",
      "  - \"keyboard\": 0.2897\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3540\n",
      "  - \"doctor\": 0.2183\n",
      "  - \"nurse\": 0.2824\n",
      "  - \"love\": 0.3285\n",
      "  - \"sex\": 0.1186\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2635\n",
      "  - \"tiger\": 0.1003\n",
      "  - \"computer\": 0.2273\n",
      "  - \"keyboard\": 0.1575\n",
      "  - \"plane\": 0.3540\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1919\n",
      "  - \"nurse\": 0.1608\n",
      "  - \"love\": 0.2495\n",
      "  - \"sex\": 0.0663\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.3434\n",
      "  - \"tiger\": 0.0891\n",
      "  - \"computer\": 0.2099\n",
      "  - \"keyboard\": 0.1380\n",
      "  - \"plane\": 0.2183\n",
      "  - \"car\": 0.1919\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.3445\n",
      "  - \"love\": 0.3308\n",
      "  - \"sex\": 0.1755\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.5485\n",
      "  - \"tiger\": 0.2026\n",
      "  - \"computer\": 0.1207\n",
      "  - \"keyboard\": 0.1668\n",
      "  - \"plane\": 0.2824\n",
      "  - \"car\": 0.1608\n",
      "  - \"doctor\": 0.3445\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.5447\n",
      "  - \"sex\": 0.4091\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.5941\n",
      "  - \"tiger\": 0.1910\n",
      "  - \"computer\": 0.2348\n",
      "  - \"keyboard\": 0.2741\n",
      "  - \"plane\": 0.3285\n",
      "  - \"car\": 0.2495\n",
      "  - \"doctor\": 0.3308\n",
      "  - \"nurse\": 0.5447\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.3616\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2599\n",
      "  - \"tiger\": 0.1881\n",
      "  - \"computer\": 0.0769\n",
      "  - \"keyboard\": 0.1064\n",
      "  - \"plane\": 0.1186\n",
      "  - \"car\": 0.0663\n",
      "  - \"doctor\": 0.1755\n",
      "  - \"nurse\": 0.4091\n",
      "  - \"love\": 0.3616\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_retrofitted_toy_vecs, new_updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=0.1, beta=1.1000000000000003, nb_iter=15)\n",
    "new_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(new_retrofitted_toy_vecs)\n",
    "print_vec_similarities(toy_corpus, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.2020 (Difference: -0.3153)\n",
      "  - \"computer\": 0.1732 -> 0.1972 (Difference: 0.0239)\n",
      "  - \"keyboard\": 0.1834 -> 0.2055 (Difference: 0.0220)\n",
      "  - \"plane\": 0.1833 -> 0.3945 (Difference: 0.2111)\n",
      "  - \"car\": 0.2153 -> 0.2635 (Difference: 0.0482)\n",
      "  - \"doctor\": 0.1292 -> 0.3434 (Difference: 0.2141)\n",
      "  - \"nurse\": 0.1594 -> 0.5485 (Difference: 0.3892)\n",
      "  - \"love\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"sex\": 0.1368 -> 0.2599 (Difference: 0.1231)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.2020 (Difference: -0.3153)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"keyboard\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"plane\": 0.1660 -> 0.0731 (Difference: -0.0930)\n",
      "  - \"car\": 0.1672 -> 0.1003 (Difference: -0.0669)\n",
      "  - \"doctor\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"nurse\": 0.1111 -> 0.2026 (Difference: 0.0915)\n",
      "  - \"love\": 0.0871 -> 0.1910 (Difference: 0.1040)\n",
      "  - \"sex\": 0.2222 -> 0.1881 (Difference: -0.0341)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1972 (Difference: 0.0239)\n",
      "  - \"tiger\": 0.0677 -> 0.0903 (Difference: 0.0226)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.2393 (Difference: -0.1571)\n",
      "  - \"plane\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"car\": 0.2461 -> 0.2273 (Difference: -0.0188)\n",
      "  - \"doctor\": 0.1628 -> 0.2099 (Difference: 0.0471)\n",
      "  - \"nurse\": 0.2178 -> 0.1207 (Difference: -0.0971)\n",
      "  - \"love\": 0.0573 -> 0.2348 (Difference: 0.1775)\n",
      "  - \"sex\": 0.1853 -> 0.0769 (Difference: -0.1084)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2055 (Difference: 0.0220)\n",
      "  - \"tiger\": 0.0654 -> 0.1831 (Difference: 0.1177)\n",
      "  - \"computer\": 0.3964 -> 0.2393 (Difference: -0.1571)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.2897 (Difference: 0.1892)\n",
      "  - \"car\": 0.1498 -> 0.1575 (Difference: 0.0077)\n",
      "  - \"doctor\": 0.0850 -> 0.1380 (Difference: 0.0530)\n",
      "  - \"nurse\": 0.1220 -> 0.1668 (Difference: 0.0448)\n",
      "  - \"love\": 0.1591 -> 0.2741 (Difference: 0.1150)\n",
      "  - \"sex\": 0.0943 -> 0.1064 (Difference: 0.0121)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.3945 (Difference: 0.2111)\n",
      "  - \"tiger\": 0.1660 -> 0.0731 (Difference: -0.0930)\n",
      "  - \"computer\": 0.1909 -> 0.4086 (Difference: 0.2177)\n",
      "  - \"keyboard\": 0.1006 -> 0.2897 (Difference: 0.1892)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3540 (Difference: -0.0239)\n",
      "  - \"doctor\": 0.1879 -> 0.2183 (Difference: 0.0305)\n",
      "  - \"nurse\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"love\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"sex\": 0.0587 -> 0.1186 (Difference: 0.0599)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2635 (Difference: 0.0482)\n",
      "  - \"tiger\": 0.1672 -> 0.1003 (Difference: -0.0669)\n",
      "  - \"computer\": 0.2461 -> 0.2273 (Difference: -0.0188)\n",
      "  - \"keyboard\": 0.1498 -> 0.1575 (Difference: 0.0077)\n",
      "  - \"plane\": 0.3780 -> 0.3540 (Difference: -0.0239)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"nurse\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"love\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"sex\": 0.1169 -> 0.0663 (Difference: -0.0506)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.3434 (Difference: 0.2141)\n",
      "  - \"tiger\": 0.0835 -> 0.0891 (Difference: 0.0056)\n",
      "  - \"computer\": 0.1628 -> 0.2099 (Difference: 0.0471)\n",
      "  - \"keyboard\": 0.0850 -> 0.1380 (Difference: 0.0530)\n",
      "  - \"plane\": 0.1879 -> 0.2183 (Difference: 0.0305)\n",
      "  - \"car\": 0.1895 -> 0.1919 (Difference: 0.0024)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.3445 (Difference: -0.2875)\n",
      "  - \"love\": 0.0831 -> 0.3308 (Difference: 0.2477)\n",
      "  - \"sex\": 0.1994 -> 0.1755 (Difference: -0.0239)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.5485 (Difference: 0.3892)\n",
      "  - \"tiger\": 0.1111 -> 0.2026 (Difference: 0.0915)\n",
      "  - \"computer\": 0.2178 -> 0.1207 (Difference: -0.0971)\n",
      "  - \"keyboard\": 0.1220 -> 0.1668 (Difference: 0.0448)\n",
      "  - \"plane\": 0.0978 -> 0.2824 (Difference: 0.1846)\n",
      "  - \"car\": 0.1306 -> 0.1608 (Difference: 0.0302)\n",
      "  - \"doctor\": 0.6320 -> 0.3445 (Difference: -0.2875)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.5447 (Difference: 0.4817)\n",
      "  - \"sex\": 0.1997 -> 0.4091 (Difference: 0.2094)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.5941 (Difference: 0.4535)\n",
      "  - \"tiger\": 0.0871 -> 0.1910 (Difference: 0.1040)\n",
      "  - \"computer\": 0.0573 -> 0.2348 (Difference: 0.1775)\n",
      "  - \"keyboard\": 0.1591 -> 0.2741 (Difference: 0.1150)\n",
      "  - \"plane\": 0.1080 -> 0.3285 (Difference: 0.2205)\n",
      "  - \"car\": 0.0842 -> 0.2495 (Difference: 0.1653)\n",
      "  - \"doctor\": 0.0831 -> 0.3308 (Difference: 0.2477)\n",
      "  - \"nurse\": 0.0631 -> 0.5447 (Difference: 0.4817)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3616 (Difference: 0.0977)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2599 (Difference: 0.1231)\n",
      "  - \"tiger\": 0.2222 -> 0.1881 (Difference: -0.0341)\n",
      "  - \"computer\": 0.1853 -> 0.0769 (Difference: -0.1084)\n",
      "  - \"keyboard\": 0.0943 -> 0.1064 (Difference: 0.0121)\n",
      "  - \"plane\": 0.0587 -> 0.1186 (Difference: 0.0599)\n",
      "  - \"car\": 0.1169 -> 0.0663 (Difference: -0.0506)\n",
      "  - \"doctor\": 0.1994 -> 0.1755 (Difference: -0.0239)\n",
      "  - \"nurse\": 0.1997 -> 0.4091 (Difference: 0.2094)\n",
      "  - \"love\": 0.2639 -> 0.3616 (Difference: 0.0977)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between original and after tuning hyperparam\n",
    "print_vec_difference(toy_corpus, similarity_matrix, new_retrofitted_similarity_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"tiger\": 0.2028 -> 0.2020 (Difference: -0.0008)\n",
      "  - \"computer\": 0.1974 -> 0.1972 (Difference: -0.0002)\n",
      "  - \"keyboard\": 0.2057 -> 0.2055 (Difference: -0.0003)\n",
      "  - \"plane\": 0.3947 -> 0.3945 (Difference: -0.0002)\n",
      "  - \"car\": 0.2636 -> 0.2635 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.3436 -> 0.3434 (Difference: -0.0002)\n",
      "  - \"nurse\": 0.5487 -> 0.5485 (Difference: -0.0001)\n",
      "  - \"love\": 0.5941 -> 0.5941 (Difference: -0.0001)\n",
      "  - \"sex\": 0.2601 -> 0.2599 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.2028 -> 0.2020 (Difference: -0.0008)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0903 -> 0.0903 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1831 -> 0.1831 (Difference: 0.0001)\n",
      "  - \"plane\": 0.0734 -> 0.0731 (Difference: -0.0004)\n",
      "  - \"car\": 0.1005 -> 0.1003 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.0891 -> 0.0891 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.2028 -> 0.2026 (Difference: -0.0002)\n",
      "  - \"love\": 0.1912 -> 0.1910 (Difference: -0.0002)\n",
      "  - \"sex\": 0.1883 -> 0.1881 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1974 -> 0.1972 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0903 -> 0.0903 (Difference: 0.0000)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.2398 -> 0.2393 (Difference: -0.0004)\n",
      "  - \"plane\": 0.4086 -> 0.4086 (Difference: -0.0000)\n",
      "  - \"car\": 0.2276 -> 0.2273 (Difference: -0.0003)\n",
      "  - \"doctor\": 0.2100 -> 0.2099 (Difference: -0.0001)\n",
      "  - \"nurse\": 0.1209 -> 0.1207 (Difference: -0.0002)\n",
      "  - \"love\": 0.2347 -> 0.2348 (Difference: 0.0001)\n",
      "  - \"sex\": 0.0771 -> 0.0769 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2057 -> 0.2055 (Difference: -0.0003)\n",
      "  - \"tiger\": 0.1831 -> 0.1831 (Difference: 0.0001)\n",
      "  - \"computer\": 0.2398 -> 0.2393 (Difference: -0.0004)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.2897 -> 0.2897 (Difference: 0.0000)\n",
      "  - \"car\": 0.1576 -> 0.1575 (Difference: -0.0001)\n",
      "  - \"doctor\": 0.1381 -> 0.1380 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.1669 -> 0.1668 (Difference: -0.0001)\n",
      "  - \"love\": 0.2741 -> 0.2741 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1065 -> 0.1064 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.3947 -> 0.3945 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0734 -> 0.0731 (Difference: -0.0004)\n",
      "  - \"computer\": 0.4086 -> 0.4086 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.2897 -> 0.2897 (Difference: 0.0000)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3545 -> 0.3540 (Difference: -0.0004)\n",
      "  - \"doctor\": 0.2185 -> 0.2183 (Difference: -0.0001)\n",
      "  - \"nurse\": 0.2824 -> 0.2824 (Difference: -0.0000)\n",
      "  - \"love\": 0.3285 -> 0.3285 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1187 -> 0.1186 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2636 -> 0.2635 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.1005 -> 0.1003 (Difference: -0.0001)\n",
      "  - \"computer\": 0.2276 -> 0.2273 (Difference: -0.0003)\n",
      "  - \"keyboard\": 0.1576 -> 0.1575 (Difference: -0.0001)\n",
      "  - \"plane\": 0.3545 -> 0.3540 (Difference: -0.0004)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1919 -> 0.1919 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1608 -> 0.1608 (Difference: -0.0000)\n",
      "  - \"love\": 0.2495 -> 0.2495 (Difference: -0.0000)\n",
      "  - \"sex\": 0.0665 -> 0.0663 (Difference: -0.0002)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.3436 -> 0.3434 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.0891 -> 0.0891 (Difference: -0.0000)\n",
      "  - \"computer\": 0.2100 -> 0.2099 (Difference: -0.0001)\n",
      "  - \"keyboard\": 0.1381 -> 0.1380 (Difference: -0.0000)\n",
      "  - \"plane\": 0.2185 -> 0.2183 (Difference: -0.0001)\n",
      "  - \"car\": 0.1919 -> 0.1919 (Difference: 0.0000)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.3451 -> 0.3445 (Difference: -0.0006)\n",
      "  - \"love\": 0.3307 -> 0.3308 (Difference: 0.0001)\n",
      "  - \"sex\": 0.1756 -> 0.1755 (Difference: -0.0000)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.5487 -> 0.5485 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.2028 -> 0.2026 (Difference: -0.0002)\n",
      "  - \"computer\": 0.1209 -> 0.1207 (Difference: -0.0002)\n",
      "  - \"keyboard\": 0.1669 -> 0.1668 (Difference: -0.0001)\n",
      "  - \"plane\": 0.2824 -> 0.2824 (Difference: -0.0000)\n",
      "  - \"car\": 0.1608 -> 0.1608 (Difference: -0.0000)\n",
      "  - \"doctor\": 0.3451 -> 0.3445 (Difference: -0.0006)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.5446 -> 0.5447 (Difference: 0.0001)\n",
      "  - \"sex\": 0.4092 -> 0.4091 (Difference: -0.0001)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.5941 -> 0.5941 (Difference: -0.0001)\n",
      "  - \"tiger\": 0.1912 -> 0.1910 (Difference: -0.0002)\n",
      "  - \"computer\": 0.2347 -> 0.2348 (Difference: 0.0001)\n",
      "  - \"keyboard\": 0.2741 -> 0.2741 (Difference: 0.0000)\n",
      "  - \"plane\": 0.3285 -> 0.3285 (Difference: 0.0000)\n",
      "  - \"car\": 0.2495 -> 0.2495 (Difference: -0.0000)\n",
      "  - \"doctor\": 0.3307 -> 0.3308 (Difference: 0.0001)\n",
      "  - \"nurse\": 0.5446 -> 0.5447 (Difference: 0.0001)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"sex\": 0.3620 -> 0.3616 (Difference: -0.0003)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2601 -> 0.2599 (Difference: -0.0002)\n",
      "  - \"tiger\": 0.1883 -> 0.1881 (Difference: -0.0002)\n",
      "  - \"computer\": 0.0771 -> 0.0769 (Difference: -0.0001)\n",
      "  - \"keyboard\": 0.1065 -> 0.1064 (Difference: -0.0001)\n",
      "  - \"plane\": 0.1187 -> 0.1186 (Difference: -0.0001)\n",
      "  - \"car\": 0.0665 -> 0.0663 (Difference: -0.0002)\n",
      "  - \"doctor\": 0.1756 -> 0.1755 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.4092 -> 0.4091 (Difference: -0.0001)\n",
      "  - \"love\": 0.3620 -> 0.3616 (Difference: -0.0003)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between retrofitted embeddings and after tuning hyperaparams\n",
    "print_vec_difference(toy_corpus, retrofitted_similarity_matrix, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>Before: 0.29245239862991185, After: 1.00000000...</td>\n",
       "      <td>Before: 0.35037322527996934, After: 0.20200897...</td>\n",
       "      <td>Before: 0.06136659928459301, After: 0.19719178...</td>\n",
       "      <td>Before: 0.18344955625364173, After: 0.20547455...</td>\n",
       "      <td>Before: 0.21134097025538556, After: 0.39445950...</td>\n",
       "      <td>Before: 0.136072027917602, After: 0.2634861035...</td>\n",
       "      <td>Before: 0.16547475026405636, After: 0.34338708...</td>\n",
       "      <td>Before: 0.24690899138830727, After: 0.54854860...</td>\n",
       "      <td>Before: 0.2989067535773432, After: 0.594053102...</td>\n",
       "      <td>Before: 0.1093022564011111, After: 0.259890845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Before: 0.17347637872059773, After: 0.20200897...</td>\n",
       "      <td>Before: 0.48802072485209846, After: 1.00000000...</td>\n",
       "      <td>Before: 0.02942476361382193, After: 0.09025702...</td>\n",
       "      <td>Before: 0.06542581824273716, After: 0.18313975...</td>\n",
       "      <td>Before: 0.15090617196611955, After: 0.07307479...</td>\n",
       "      <td>Before: 0.16119598769364896, After: 0.10033040...</td>\n",
       "      <td>Before: 0.0774108002811773, After: 0.089083542...</td>\n",
       "      <td>Before: 0.1697249630498177, After: 0.202597136...</td>\n",
       "      <td>Before: 0.17516455047450735, After: 0.19102605...</td>\n",
       "      <td>Before: 0.14518818082220147, After: 0.18807845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>Before: 0.18984798734723213, After: 0.19719178...</td>\n",
       "      <td>Before: 0.05360514929979338, After: 0.09025702...</td>\n",
       "      <td>Before: 0.3047689400402037, After: 1.0</td>\n",
       "      <td>Before: 0.39639163439495995, After: 0.23934215...</td>\n",
       "      <td>Before: 0.28314903703275535, After: 0.40858220...</td>\n",
       "      <td>Before: 0.26826894486108244, After: 0.22732308...</td>\n",
       "      <td>Before: 0.18039329196329013, After: 0.20986951...</td>\n",
       "      <td>Before: 0.09297679298707379, After: 0.12068024...</td>\n",
       "      <td>Before: 0.1168711356729625, After: 0.234808759...</td>\n",
       "      <td>Before: 0.1158779845883439, After: 0.076953257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>Before: 0.20546589125510897, After: 0.20547455...</td>\n",
       "      <td>Before: 0.18314156317766062, After: 0.18313975...</td>\n",
       "      <td>Before: 0.2393287663091698, After: 0.239342157...</td>\n",
       "      <td>Before: 0.9999999999999996, After: 1.0</td>\n",
       "      <td>Before: 0.28971014677665063, After: 0.28970944...</td>\n",
       "      <td>Before: 0.15750632650840493, After: 0.15750846...</td>\n",
       "      <td>Before: 0.13804955762057758, After: 0.13804958...</td>\n",
       "      <td>Before: 0.16678031434047627, After: 0.16678347...</td>\n",
       "      <td>Before: 0.27407501845767246, After: 0.27407454...</td>\n",
       "      <td>Before: 0.10639718565916091, After: 0.10639914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>Before: 0.16761576142114898, After: 0.39445950...</td>\n",
       "      <td>Before: 0.06730278214710199, After: 0.07307479...</td>\n",
       "      <td>Before: 0.06606645196552532, After: 0.40858220...</td>\n",
       "      <td>Before: 0.10055138151211143, After: 0.28970944...</td>\n",
       "      <td>Before: 0.38405259310022044, After: 1.00000000...</td>\n",
       "      <td>Before: 0.3219357387657039, After: 0.354037032...</td>\n",
       "      <td>Before: 0.15146728859985834, After: 0.21833826...</td>\n",
       "      <td>Before: 0.10589313234551631, After: 0.28236372...</td>\n",
       "      <td>Before: 0.1936940498815496, After: 0.328525840...</td>\n",
       "      <td>Before: 0.05697047025775614, After: 0.11862340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>Before: 0.15859645192729996, After: 0.26348610...</td>\n",
       "      <td>Before: -0.049076379792710186, After: 0.100330...</td>\n",
       "      <td>Before: 0.13968323112249992, After: 0.22732308...</td>\n",
       "      <td>Before: 0.14983822223318854, After: 0.15750846...</td>\n",
       "      <td>Before: 0.2597415410728325, After: 0.354037032...</td>\n",
       "      <td>Before: 0.6158574248530795, After: 1.000000000...</td>\n",
       "      <td>Before: 0.13778205919388814, After: 0.19190468...</td>\n",
       "      <td>Before: 0.0865221800713605, After: 0.160778501...</td>\n",
       "      <td>Before: 0.22133439390681858, After: 0.24947266...</td>\n",
       "      <td>Before: 0.059270287407368415, After: 0.0662935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>Before: 0.25878907406446877, After: 0.34338708...</td>\n",
       "      <td>Before: 0.017639064485218965, After: 0.0890835...</td>\n",
       "      <td>Before: 0.0978054983995635, After: 0.209869514...</td>\n",
       "      <td>Before: 0.08500327165730943, After: 0.13804958...</td>\n",
       "      <td>Before: 0.13439994429915442, After: 0.21833826...</td>\n",
       "      <td>Before: 0.09431570687955, After: 0.19190468704...</td>\n",
       "      <td>Before: 0.6128107065755533, After: 1.0</td>\n",
       "      <td>Before: 0.27845097194129365, After: 0.34448646...</td>\n",
       "      <td>Before: 0.19325643013428553, After: 0.33078374...</td>\n",
       "      <td>Before: 0.0745189116843016, After: 0.175547118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>Before: 0.18217682480604822, After: 0.54854860...</td>\n",
       "      <td>Before: 0.07222178145580241, After: 0.20259713...</td>\n",
       "      <td>Before: 0.11697573887301807, After: 0.12068024...</td>\n",
       "      <td>Before: 0.12199094008346709, After: 0.16678347...</td>\n",
       "      <td>Before: 0.12790409339777273, After: 0.28236372...</td>\n",
       "      <td>Before: 0.07363428182232754, After: 0.16077850...</td>\n",
       "      <td>Before: 0.4308149649767604, After: 0.344486463...</td>\n",
       "      <td>Before: 0.378466332225932, After: 1.0000000000...</td>\n",
       "      <td>Before: 0.1708752362535986, After: 0.544714533...</td>\n",
       "      <td>Before: 0.1264203000118017, After: 0.409129275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>Before: 0.241072229246228, After: 0.5940531024...</td>\n",
       "      <td>Before: 0.10199943514005788, After: 0.19102605...</td>\n",
       "      <td>Before: 0.0730022470894344, After: 0.234808759...</td>\n",
       "      <td>Before: 0.15911448638969528, After: 0.27407454...</td>\n",
       "      <td>Before: 0.09505575751009387, After: 0.32852584...</td>\n",
       "      <td>Before: 0.11200247669649024, After: 0.24947266...</td>\n",
       "      <td>Before: 0.14771102908578468, After: 0.33078374...</td>\n",
       "      <td>Before: 0.3033847603340788, After: 0.544714533...</td>\n",
       "      <td>Before: 0.6110191309495465, After: 0.999999999...</td>\n",
       "      <td>Before: 0.30399420253175347, After: 0.36164712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>Before: 0.225917972105598, After: 0.2598908452...</td>\n",
       "      <td>Before: 0.1655264826766013, After: 0.188078452...</td>\n",
       "      <td>Before: 0.036750539503579295, After: 0.0769532...</td>\n",
       "      <td>Before: 0.09429740737651135, After: 0.10639914...</td>\n",
       "      <td>Before: 0.10212970436490482, After: 0.11862340...</td>\n",
       "      <td>Before: 0.13403080874265905, After: 0.06629354...</td>\n",
       "      <td>Before: 0.1436405909297276, After: 0.175547118...</td>\n",
       "      <td>Before: 0.26868181343357167, After: 0.40912927...</td>\n",
       "      <td>Before: 0.3049306009871644, After: 0.361647126...</td>\n",
       "      <td>Before: 0.4896246955281065, After: 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        cat  \\\n",
       "cat       Before: 0.29245239862991185, After: 1.00000000...   \n",
       "tiger     Before: 0.17347637872059773, After: 0.20200897...   \n",
       "computer  Before: 0.18984798734723213, After: 0.19719178...   \n",
       "keyboard  Before: 0.20546589125510897, After: 0.20547455...   \n",
       "plane     Before: 0.16761576142114898, After: 0.39445950...   \n",
       "car       Before: 0.15859645192729996, After: 0.26348610...   \n",
       "doctor    Before: 0.25878907406446877, After: 0.34338708...   \n",
       "nurse     Before: 0.18217682480604822, After: 0.54854860...   \n",
       "love      Before: 0.241072229246228, After: 0.5940531024...   \n",
       "sex       Before: 0.225917972105598, After: 0.2598908452...   \n",
       "\n",
       "                                                      tiger  \\\n",
       "cat       Before: 0.35037322527996934, After: 0.20200897...   \n",
       "tiger     Before: 0.48802072485209846, After: 1.00000000...   \n",
       "computer  Before: 0.05360514929979338, After: 0.09025702...   \n",
       "keyboard  Before: 0.18314156317766062, After: 0.18313975...   \n",
       "plane     Before: 0.06730278214710199, After: 0.07307479...   \n",
       "car       Before: -0.049076379792710186, After: 0.100330...   \n",
       "doctor    Before: 0.017639064485218965, After: 0.0890835...   \n",
       "nurse     Before: 0.07222178145580241, After: 0.20259713...   \n",
       "love      Before: 0.10199943514005788, After: 0.19102605...   \n",
       "sex       Before: 0.1655264826766013, After: 0.188078452...   \n",
       "\n",
       "                                                   computer  \\\n",
       "cat       Before: 0.06136659928459301, After: 0.19719178...   \n",
       "tiger     Before: 0.02942476361382193, After: 0.09025702...   \n",
       "computer             Before: 0.3047689400402037, After: 1.0   \n",
       "keyboard  Before: 0.2393287663091698, After: 0.239342157...   \n",
       "plane     Before: 0.06606645196552532, After: 0.40858220...   \n",
       "car       Before: 0.13968323112249992, After: 0.22732308...   \n",
       "doctor    Before: 0.0978054983995635, After: 0.209869514...   \n",
       "nurse     Before: 0.11697573887301807, After: 0.12068024...   \n",
       "love      Before: 0.0730022470894344, After: 0.234808759...   \n",
       "sex       Before: 0.036750539503579295, After: 0.0769532...   \n",
       "\n",
       "                                                   keyboard  \\\n",
       "cat       Before: 0.18344955625364173, After: 0.20547455...   \n",
       "tiger     Before: 0.06542581824273716, After: 0.18313975...   \n",
       "computer  Before: 0.39639163439495995, After: 0.23934215...   \n",
       "keyboard             Before: 0.9999999999999996, After: 1.0   \n",
       "plane     Before: 0.10055138151211143, After: 0.28970944...   \n",
       "car       Before: 0.14983822223318854, After: 0.15750846...   \n",
       "doctor    Before: 0.08500327165730943, After: 0.13804958...   \n",
       "nurse     Before: 0.12199094008346709, After: 0.16678347...   \n",
       "love      Before: 0.15911448638969528, After: 0.27407454...   \n",
       "sex       Before: 0.09429740737651135, After: 0.10639914...   \n",
       "\n",
       "                                                      plane  \\\n",
       "cat       Before: 0.21134097025538556, After: 0.39445950...   \n",
       "tiger     Before: 0.15090617196611955, After: 0.07307479...   \n",
       "computer  Before: 0.28314903703275535, After: 0.40858220...   \n",
       "keyboard  Before: 0.28971014677665063, After: 0.28970944...   \n",
       "plane     Before: 0.38405259310022044, After: 1.00000000...   \n",
       "car       Before: 0.2597415410728325, After: 0.354037032...   \n",
       "doctor    Before: 0.13439994429915442, After: 0.21833826...   \n",
       "nurse     Before: 0.12790409339777273, After: 0.28236372...   \n",
       "love      Before: 0.09505575751009387, After: 0.32852584...   \n",
       "sex       Before: 0.10212970436490482, After: 0.11862340...   \n",
       "\n",
       "                                                        car  \\\n",
       "cat       Before: 0.136072027917602, After: 0.2634861035...   \n",
       "tiger     Before: 0.16119598769364896, After: 0.10033040...   \n",
       "computer  Before: 0.26826894486108244, After: 0.22732308...   \n",
       "keyboard  Before: 0.15750632650840493, After: 0.15750846...   \n",
       "plane     Before: 0.3219357387657039, After: 0.354037032...   \n",
       "car       Before: 0.6158574248530795, After: 1.000000000...   \n",
       "doctor    Before: 0.09431570687955, After: 0.19190468704...   \n",
       "nurse     Before: 0.07363428182232754, After: 0.16077850...   \n",
       "love      Before: 0.11200247669649024, After: 0.24947266...   \n",
       "sex       Before: 0.13403080874265905, After: 0.06629354...   \n",
       "\n",
       "                                                     doctor  \\\n",
       "cat       Before: 0.16547475026405636, After: 0.34338708...   \n",
       "tiger     Before: 0.0774108002811773, After: 0.089083542...   \n",
       "computer  Before: 0.18039329196329013, After: 0.20986951...   \n",
       "keyboard  Before: 0.13804955762057758, After: 0.13804958...   \n",
       "plane     Before: 0.15146728859985834, After: 0.21833826...   \n",
       "car       Before: 0.13778205919388814, After: 0.19190468...   \n",
       "doctor               Before: 0.6128107065755533, After: 1.0   \n",
       "nurse     Before: 0.4308149649767604, After: 0.344486463...   \n",
       "love      Before: 0.14771102908578468, After: 0.33078374...   \n",
       "sex       Before: 0.1436405909297276, After: 0.175547118...   \n",
       "\n",
       "                                                      nurse  \\\n",
       "cat       Before: 0.24690899138830727, After: 0.54854860...   \n",
       "tiger     Before: 0.1697249630498177, After: 0.202597136...   \n",
       "computer  Before: 0.09297679298707379, After: 0.12068024...   \n",
       "keyboard  Before: 0.16678031434047627, After: 0.16678347...   \n",
       "plane     Before: 0.10589313234551631, After: 0.28236372...   \n",
       "car       Before: 0.0865221800713605, After: 0.160778501...   \n",
       "doctor    Before: 0.27845097194129365, After: 0.34448646...   \n",
       "nurse     Before: 0.378466332225932, After: 1.0000000000...   \n",
       "love      Before: 0.3033847603340788, After: 0.544714533...   \n",
       "sex       Before: 0.26868181343357167, After: 0.40912927...   \n",
       "\n",
       "                                                       love  \\\n",
       "cat       Before: 0.2989067535773432, After: 0.594053102...   \n",
       "tiger     Before: 0.17516455047450735, After: 0.19102605...   \n",
       "computer  Before: 0.1168711356729625, After: 0.234808759...   \n",
       "keyboard  Before: 0.27407501845767246, After: 0.27407454...   \n",
       "plane     Before: 0.1936940498815496, After: 0.328525840...   \n",
       "car       Before: 0.22133439390681858, After: 0.24947266...   \n",
       "doctor    Before: 0.19325643013428553, After: 0.33078374...   \n",
       "nurse     Before: 0.1708752362535986, After: 0.544714533...   \n",
       "love      Before: 0.6110191309495465, After: 0.999999999...   \n",
       "sex       Before: 0.3049306009871644, After: 0.361647126...   \n",
       "\n",
       "                                                        sex  \n",
       "cat       Before: 0.1093022564011111, After: 0.259890845...  \n",
       "tiger     Before: 0.14518818082220147, After: 0.18807845...  \n",
       "computer  Before: 0.1158779845883439, After: 0.076953257...  \n",
       "keyboard  Before: 0.10639718565916091, After: 0.10639914...  \n",
       "plane     Before: 0.05697047025775614, After: 0.11862340...  \n",
       "car       Before: 0.059270287407368415, After: 0.0662935...  \n",
       "doctor    Before: 0.0745189116843016, After: 0.175547118...  \n",
       "nurse     Before: 0.1264203000118017, After: 0.409129275...  \n",
       "love      Before: 0.30399420253175347, After: 0.36164712...  \n",
       "sex                  Before: 0.4896246955281065, After: 1.0  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score before retrofitting\n",
    "        similarity_before = cosine_sim[word1_index, word2_index]\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Before: {similarity_before}, After: {similarity_after}\"\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Retrofitting: 0.20, Human: 0.73</td>\n",
       "      <td>Retrofitting: 1.00, Human: 1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.24, Human: 0.76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.35, Human: 0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.34, Human: 0.70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.36, Human: 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cat                            tiger  \\\n",
       "cat                                  None                             None   \n",
       "tiger     Retrofitting: 0.20, Human: 0.73  Retrofitting: 1.00, Human: 1.00   \n",
       "computer                             None                             None   \n",
       "keyboard                             None                             None   \n",
       "plane                                None                             None   \n",
       "car                                  None                             None   \n",
       "doctor                               None                             None   \n",
       "nurse                                None                             None   \n",
       "love                                 None                             None   \n",
       "sex                                  None                             None   \n",
       "\n",
       "         computer                         keyboard plane  \\\n",
       "cat          None                             None  None   \n",
       "tiger        None                             None  None   \n",
       "computer     None  Retrofitting: 0.24, Human: 0.76  None   \n",
       "keyboard     None                             None  None   \n",
       "plane        None                             None  None   \n",
       "car          None                             None  None   \n",
       "doctor       None                             None  None   \n",
       "nurse        None                             None  None   \n",
       "love         None                             None  None   \n",
       "sex          None                             None  None   \n",
       "\n",
       "                                      car doctor  \\\n",
       "cat                                  None   None   \n",
       "tiger                                None   None   \n",
       "computer                             None   None   \n",
       "keyboard                             None   None   \n",
       "plane     Retrofitting: 0.35, Human: 0.58   None   \n",
       "car                                  None   None   \n",
       "doctor                               None   None   \n",
       "nurse                                None   None   \n",
       "love                                 None   None   \n",
       "sex                                  None   None   \n",
       "\n",
       "                                    nurse  love  \\\n",
       "cat                                  None  None   \n",
       "tiger                                None  None   \n",
       "computer                             None  None   \n",
       "keyboard                             None  None   \n",
       "plane                                None  None   \n",
       "car                                  None  None   \n",
       "doctor    Retrofitting: 0.34, Human: 0.70  None   \n",
       "nurse                                None  None   \n",
       "love                                 None  None   \n",
       "sex                                  None  None   \n",
       "\n",
       "                                      sex  \n",
       "cat                                  None  \n",
       "tiger                                None  \n",
       "computer                             None  \n",
       "keyboard                             None  \n",
       "plane                                None  \n",
       "car                                  None  \n",
       "doctor                               None  \n",
       "nurse                                None  \n",
       "love      Retrofitting: 0.36, Human: 0.68  \n",
       "sex                                  None  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation scores from the file\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as eval_file:\n",
    "    for line in eval_file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Retrieve the evaluation score for the word pair\n",
    "        score = eval_scores.get((word1, word2))\n",
    "\n",
    "        # Scale the human score between 0 and 1\n",
    "        if score is not None:\n",
    "            scaled_score = score / 10.0\n",
    "        else:\n",
    "            scaled_score = None\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Retrofitting: {similarity_after:.2f}, Human: {scaled_score:.2f}\" if scaled_score is not None else None\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n"
     ]
    }
   ],
   "source": [
    "wordVecs_gensim = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "lexical_similarity = read_lexicon(\"../data/English/lexicon/ws353_lexical_similarity.txt\")\n",
    "output_file = \"../data/English/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ninan\\AppData\\Local\\Temp\\ipykernel_10760\\730395986.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  wordVecMat = np.array(list(wordVecs.values()))\n"
     ]
    }
   ],
   "source": [
    "wordList_gensim = get_embeddings_words(wordVecs_gensim)\n",
    "wordVecMat_gensim = convert_dict_to_matrix(wordVecs_gensim)\n",
    "neighbors_matrix_gensim = create_neighbors_embedding_matrix(wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordVecs_gensim[\"cat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125777, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix_gensim))  \n",
    "print(neighbors_matrix_gensim.shape)  \n",
    "print(neighbors_matrix_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125777,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat_gensim))  \n",
    "print(wordVecMat_gensim.shape) \n",
    "print(wordVecMat_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([1.]),\n",
       "       array([ 9.23727516e-02, -1.51682346e-02,  5.35253701e-02, -7.96715736e-03,\n",
       "              -1.86745677e-02, -4.08309749e-02, -3.26983925e-02,  1.08234716e-02,\n",
       "               9.79218392e-02, -9.00711200e-02,  1.32788468e-02, -6.93899727e-02,\n",
       "               1.28221380e-02, -2.23395430e-02, -5.09426289e-02,  1.39390398e-02,\n",
       "               8.01953568e-03,  1.36401065e-01,  5.53190450e-02,  8.40246267e-02,\n",
       "              -2.51137099e-02, -1.38256539e-01, -8.80196985e-02,  5.23078567e-02,\n",
       "               8.70052924e-02, -2.35834339e-02, -8.39187396e-02,  1.18150800e-01,\n",
       "              -9.67921254e-02,  6.80466006e-03, -7.03565223e-02, -1.74815478e-02,\n",
       "               1.10553682e-01, -4.69019616e-02,  3.49367179e-02,  2.64891119e-02,\n",
       "               9.55595392e-02, -3.72210157e-02, -3.58388309e-02,  5.14034828e-02,\n",
       "               5.96762432e-02, -1.01779748e-03,  7.74788437e-02, -4.84887610e-02,\n",
       "              -2.50650998e-02,  1.51855685e-02, -7.50701945e-02, -6.55750220e-02,\n",
       "              -5.09723979e-02, -6.33517695e-02, -4.14583843e-02, -4.09990377e-02,\n",
       "               8.23707529e-02,  3.63897454e-03, -3.64685013e-02,  4.89631805e-02,\n",
       "              -6.40296731e-03,  9.45639742e-02,  7.79607996e-03,  1.04861402e-01,\n",
       "               8.08868260e-02, -6.87814044e-03, -6.94106979e-02, -6.05365289e-03,\n",
       "               5.43592782e-02,  6.28554943e-02, -2.08039914e-02, -1.40389354e-01,\n",
       "               4.16645062e-02,  3.32236830e-02,  8.21077308e-02, -8.71134404e-02,\n",
       "               1.19950504e-01, -7.27904186e-02,  7.43252165e-02, -1.07132134e-01,\n",
       "              -9.71237292e-02, -1.16566261e-02, -2.46894079e-03,  1.96298126e-02,\n",
       "               1.72501788e-01,  6.01966350e-02, -2.52734827e-02, -1.05635395e-01,\n",
       "              -1.26736699e-02,  3.97898145e-02, -6.26350532e-02, -1.41539793e-01,\n",
       "               4.57541604e-02,  1.35462400e-01, -5.51253583e-03,  2.33822107e-02,\n",
       "              -6.74060024e-02, -9.16552816e-02, -7.98445351e-02,  2.99117904e-02,\n",
       "              -3.76965657e-02, -2.04328213e-02,  1.73880958e-02,  1.18409677e-01,\n",
       "               3.76973193e-03, -7.31148627e-03, -2.30664335e-02, -6.26595466e-02,\n",
       "              -1.58789218e-02,  7.04198285e-02, -9.84162303e-02, -8.24762632e-02,\n",
       "              -8.06094847e-02,  3.52246103e-02, -7.48237526e-02, -2.76983352e-02,\n",
       "               4.68940484e-02, -2.18014405e-02,  2.78566007e-02,  1.78157893e-02,\n",
       "               6.58501024e-02,  1.25316079e-02,  2.59706042e-03,  1.10449302e-01,\n",
       "              -1.12913344e-01,  4.90012396e-02,  5.40744004e-02, -1.03969086e-02,\n",
       "              -2.89380811e-02, -5.59995864e-03,  8.76029328e-02, -1.91584077e-02,\n",
       "               6.98685372e-02, -7.46767918e-02,  4.83067558e-02, -5.61066040e-02,\n",
       "              -1.32095115e-02, -5.34379473e-02, -6.44856283e-02,  2.14449664e-02,\n",
       "               1.09845256e-01,  1.11071059e-01,  8.56852833e-02,  5.33218860e-02,\n",
       "               3.14970825e-02, -5.41105754e-02,  4.22553638e-02, -6.70333250e-02,\n",
       "              -2.32736859e-02, -1.93053685e-02, -8.86595430e-02, -1.30164653e-01,\n",
       "              -3.04860678e-02, -6.07471726e-02, -9.05504381e-04, -7.06719227e-02,\n",
       "              -6.32907243e-02, -7.92872147e-03, -4.33330761e-02,  1.46949456e-02,\n",
       "               6.14906433e-02, -4.34973707e-02,  2.92930479e-02, -3.44182102e-02,\n",
       "              -4.26446214e-02, -5.73339147e-02,  6.72575343e-02,  4.96429682e-02,\n",
       "               1.12635626e-01,  2.75347943e-02, -5.79937309e-02,  3.34350804e-02,\n",
       "              -7.44133929e-02,  5.99298447e-03,  4.41055621e-02,  3.30149234e-02,\n",
       "               5.08725400e-02, -4.01545786e-02,  1.42808554e-01,  4.71401134e-02,\n",
       "               1.60126938e-02,  5.73222332e-03, -5.30023405e-02,  4.28409459e-02,\n",
       "               1.06186686e-01,  6.54721495e-02, -1.55529704e-02, -7.68781887e-02,\n",
       "              -6.18373200e-02, -1.48611243e-02,  6.81875322e-02,  8.30735268e-02,\n",
       "              -5.11645774e-02, -2.64039501e-02, -7.78281581e-02, -3.15038653e-02,\n",
       "               2.37055244e-02, -8.45793094e-02, -1.07552668e-01,  4.47928863e-02,\n",
       "               5.81987223e-02, -1.08147294e-01,  5.64932238e-03,  1.33617478e-02,\n",
       "               6.55637174e-02,  5.42624348e-05, -5.52474488e-02,  4.49771525e-02,\n",
       "              -1.14584175e-01, -7.58242162e-03, -2.99912999e-03, -1.94214298e-03,\n",
       "               5.20282544e-02, -1.33133261e-01,  2.96864505e-02, -1.92228444e-02,\n",
       "               1.10019724e-01, -9.27601251e-02,  2.10187802e-02, -1.57123663e-02,\n",
       "              -9.14548120e-03,  4.28579030e-02,  7.07472872e-02, -6.78295508e-02,\n",
       "               1.19903024e-01,  7.34837719e-02, -6.01951277e-02,  4.40437633e-02,\n",
       "              -2.89621978e-02,  2.55150259e-02, -6.26245021e-02,  3.72289290e-02,\n",
       "               7.10468610e-02,  5.81109227e-02, -5.41851862e-02,  3.02886128e-02,\n",
       "               8.70245103e-02,  1.01602641e-02,  4.82811319e-02,  3.06929434e-02,\n",
       "               1.79254446e-03,  1.16950997e-01, -5.36836355e-02, -3.07807430e-02,\n",
       "              -3.44253699e-02, -4.59874135e-02,  5.24310777e-03, -4.74958338e-02,\n",
       "              -4.71013007e-02, -5.47225351e-02, -1.72026991e-02,  7.28213180e-02,\n",
       "               1.44036619e-02,  6.86431105e-02])                                 ,\n",
       "       array([ 1.04079566e-01, -8.84250625e-02,  5.60106707e-02, -4.37808452e-02,\n",
       "              -4.46859934e-02, -1.17395569e-02, -4.71450196e-02,  6.54381380e-02,\n",
       "               1.50297829e-03,  6.37185964e-02, -1.05126849e-02,  2.40231632e-02,\n",
       "               4.46547814e-02,  4.85015415e-02, -1.30985758e-01,  3.16432151e-02,\n",
       "               3.83336293e-02,  5.80207241e-02,  8.82579582e-04,  5.24030426e-02,\n",
       "              -9.46213666e-02, -7.57457840e-02, -4.17823162e-02, -1.38355634e-02,\n",
       "              -1.52348218e-02, -2.73287550e-02, -9.12999286e-02, -4.27844618e-03,\n",
       "               4.40953662e-03, -8.46277615e-02, -1.25078525e-02,  2.57455859e-02,\n",
       "              -8.99986280e-02, -2.11699054e-02,  2.50838913e-02,  7.24411525e-02,\n",
       "               4.84477608e-02, -5.01802674e-02,  4.23739038e-02,  5.98324612e-02,\n",
       "               3.13915983e-02, -1.15598718e-01,  6.56220488e-02, -8.93892735e-02,\n",
       "               4.73462170e-04, -7.00191006e-02, -2.84274178e-02, -9.14526274e-02,\n",
       "               1.75632376e-02, -3.09599122e-02,  1.20041387e-02, -9.38184977e-03,\n",
       "               7.60958387e-02, -9.02507250e-02,  2.24299102e-02,  7.07307344e-02,\n",
       "               2.20515246e-02,  4.54941444e-02,  9.77929869e-02,  3.92647075e-02,\n",
       "               1.84736679e-02,  1.73365904e-02, -1.60050381e-02,  3.26131883e-02,\n",
       "               6.61651378e-02,  1.54763547e-02, -1.07773627e-01,  8.19531324e-03,\n",
       "               2.12366510e-02,  2.63861524e-02,  5.21610295e-02,  2.52591587e-02,\n",
       "               5.83410073e-02, -2.41965099e-03, -4.40142150e-02, -1.64467121e-01,\n",
       "              -1.12809805e-01,  5.11055834e-02, -4.17016452e-02,  5.53249669e-02,\n",
       "               2.18154657e-01,  6.71235865e-02,  2.05038891e-04, -8.22676534e-02,\n",
       "              -1.42032889e-01,  9.28461236e-02, -6.16643660e-02, -9.90765208e-03,\n",
       "              -5.91203472e-03,  5.12818112e-02, -4.35541980e-02, -4.12709194e-02,\n",
       "               3.98217218e-02, -9.57200293e-03, -1.36499720e-01, -2.75664465e-02,\n",
       "              -5.06105129e-02, -1.53006071e-02, -2.36054024e-02,  6.53459426e-02,\n",
       "              -8.77345568e-02,  5.11900959e-02,  1.48136997e-03,  4.14918044e-02,\n",
       "              -2.85296971e-02,  5.43108167e-02, -1.57663863e-02, -6.95590836e-02,\n",
       "              -7.80026524e-02,  2.49201483e-02, -9.42208925e-02, -3.07980899e-02,\n",
       "               4.70129688e-02, -3.71883886e-02,  7.18404414e-03, -5.86656122e-02,\n",
       "               7.94374444e-02, -4.64386678e-02, -2.73772537e-02,  1.74686413e-02,\n",
       "              -1.43060484e-01,  4.17256544e-02,  1.29082786e-01, -4.31988612e-02,\n",
       "              -3.98154794e-02,  4.40401449e-02, -2.70632129e-03,  7.19960213e-02,\n",
       "               4.67527086e-02, -1.49689435e-01, -6.13147915e-03, -4.19777514e-03,\n",
       "              -1.27550036e-01, -4.42250161e-04, -6.87432497e-03, -1.28007652e-02,\n",
       "               6.15361567e-02,  3.61276605e-02,  1.56718379e-01,  8.92529010e-02,\n",
       "               2.09360554e-04, -2.55218198e-03,  1.11592536e-01, -2.85056879e-02,\n",
       "               4.13611942e-02,  3.66990804e-02, -6.14261944e-02, -1.34529042e-01,\n",
       "              -2.38714248e-02, -1.48934104e-02,  6.79850380e-02,  5.26373728e-02,\n",
       "              -2.13898300e-02, -3.08043323e-02,  6.41440401e-02,  1.04121342e-01,\n",
       "               6.12725353e-02, -2.89167260e-02,  3.34208590e-03, -4.29097900e-02,\n",
       "               3.35063319e-02,  9.22338880e-02,  1.61774244e-02,  7.26817251e-02,\n",
       "               5.29413298e-02,  6.35505318e-02, -7.63104813e-02, -1.05971974e-02,\n",
       "              -6.28446602e-02,  3.35216978e-03,  7.78816458e-02,  1.03852919e-01,\n",
       "               2.14882678e-02, -5.19713565e-02,  6.66870986e-02, -8.57225827e-02,\n",
       "              -5.04688584e-02, -7.29064516e-02, -2.29235401e-02,  4.11018944e-02,\n",
       "              -1.67459632e-02, -1.83953978e-02,  3.40499011e-03, -1.44052546e-01,\n",
       "              -3.43067999e-02,  6.37709366e-02,  6.40249543e-02,  3.66347356e-02,\n",
       "              -1.28604042e-01, -8.09605905e-02, -3.51461629e-02,  2.02013727e-03,\n",
       "               7.91330073e-02, -3.08144162e-02, -1.60874858e-01,  7.17900220e-02,\n",
       "               1.03829389e-01, -4.03489647e-02, -1.10839127e-01, -3.58333073e-02,\n",
       "               7.36550596e-02, -1.69519625e-02, -1.40351282e-01,  6.88930674e-02,\n",
       "              -1.58273698e-02, -2.57984062e-02,  7.82220968e-03, -1.99271872e-02,\n",
       "               5.04400474e-02, -8.76582075e-02,  4.46326929e-02, -3.35461873e-02,\n",
       "               6.99619586e-02,  6.35836645e-02, -5.41120202e-03, -3.32503935e-02,\n",
       "               5.03473717e-03,  5.87491644e-02, -1.28795155e-02,  6.12139527e-03,\n",
       "               1.71181064e-02,  1.37769808e-01, -6.25488664e-03,  7.53323449e-02,\n",
       "              -7.12306068e-03, -5.12385946e-02,  4.54110724e-03,  9.92887624e-02,\n",
       "               1.01981158e-01,  1.64693768e-02, -6.93746927e-02, -1.85043998e-02,\n",
       "              -8.61523481e-02, -3.65603070e-02, -3.07130972e-02,  2.77998163e-02,\n",
       "              -3.63643916e-02,  6.36360046e-02,  3.14631458e-02, -6.35764617e-04,\n",
       "               8.06230206e-04, -8.61931638e-03,  7.49486773e-02,  2.85205736e-02,\n",
       "              -4.88895308e-02, -5.26916337e-02, -4.78792221e-03,  6.86111989e-02,\n",
       "               7.68425260e-02,  8.03541171e-03])                                 ,\n",
       "       ...,\n",
       "       array([ 0.09232989,  0.10664697,  0.0930283 , -0.0195678 ,  0.02399662,\n",
       "              -0.0342162 ,  0.05206771,  0.01238272,  0.03542594,  0.01331743,\n",
       "               0.00043705,  0.04215438,  0.07261716, -0.03089299, -0.0545804 ,\n",
       "              -0.10644986,  0.04691451,  0.05597927,  0.02467087, -0.08879432,\n",
       "              -0.02748206, -0.06257714, -0.09344416,  0.00556176,  0.12705902,\n",
       "              -0.01711254, -0.15592537, -0.05892649,  0.05985596,  0.09386229,\n",
       "              -0.08042752, -0.03057375,  0.01262608, -0.05492083,  0.00747721,\n",
       "              -0.00523227,  0.00165021, -0.08968026, -0.0524544 , -0.08870226,\n",
       "              -0.0515999 ,  0.02338434,  0.01553229,  0.04688421, -0.056628  ,\n",
       "              -0.02108357,  0.01756486,  0.01620928, -0.11504727, -0.02422198,\n",
       "              -0.04888351,  0.00121293,  0.00360462, -0.05413082, -0.00681503,\n",
       "               0.08054145, -0.02350784, -0.00354515,  0.05782704,  0.01832684,\n",
       "               0.0657438 , -0.05315167,  0.05593552, -0.04466912, -0.10835073,\n",
       "              -0.03956491, -0.04360247,  0.03113567,  0.00723635,  0.01276964,\n",
       "              -0.02116651,  0.00645546, -0.01011499, -0.04813497,  0.01954752,\n",
       "               0.02743079,  0.11055966,  0.01686508,  0.04971454,  0.07033007,\n",
       "               0.13560834,  0.16363979,  0.03415878,  0.03922151,  0.0350069 ,\n",
       "              -0.04137964,  0.03569163, -0.07421907,  0.02676337, -0.06220617,\n",
       "              -0.02194719,  0.03544873, -0.07126797, -0.00802842,  0.01286238,\n",
       "               0.01778224, -0.10162502, -0.01018335, -0.12420681, -0.017167  ,\n",
       "              -0.06974719,  0.04625849,  0.05119362, -0.04055977,  0.0799351 ,\n",
       "              -0.09721786, -0.05057222,  0.0113122 ,  0.00847709,  0.05319839,\n",
       "               0.06386026,  0.10764434, -0.03810656, -0.07647312,  0.06928872,\n",
       "               0.11084495,  0.05251889,  0.05686544, -0.08718216,  0.02804102,\n",
       "              -0.14569735,  0.06250878, -0.00928009,  0.05118291,  0.05781154,\n",
       "               0.07342176, -0.05987464, -0.02204266,  0.03611319,  0.13157624,\n",
       "               0.00534051, -0.0423442 , -0.07430634, -0.09885029,  0.08019122,\n",
       "              -0.06927573,  0.05037489, -0.07690219,  0.11706548,  0.09328602,\n",
       "              -0.01127278, -0.00628501,  0.05187744, -0.02976414, -0.04080291,\n",
       "              -0.08989582,  0.06553097, -0.02352744, -0.0731686 , -0.10838422,\n",
       "               0.04663583, -0.01812837, -0.07471992, -0.00272437, -0.07703755,\n",
       "              -0.00205353,  0.07109183,  0.0826663 ,  0.08244322, -0.06314567,\n",
       "              -0.01662855, -0.05146614, -0.03229346,  0.04344137,  0.02849971,\n",
       "               0.04285621,  0.01958603, -0.04441186, -0.05957341, -0.08109676,\n",
       "              -0.07133792,  0.04569452,  0.02050092, -0.05093157,  0.05783114,\n",
       "               0.04435056,  0.02429512,  0.04696031,  0.13874629,  0.01750014,\n",
       "               0.09337306, -0.00230874,  0.01753273, -0.00826586, -0.00700439,\n",
       "              -0.10914461, -0.03536533,  0.0344133 , -0.04044128,  0.05442522,\n",
       "              -0.00782676, -0.11100583, -0.10919862, -0.08832127,  0.07614317,\n",
       "               0.05669181, -0.00725481, -0.1403131 , -0.01195775,  0.00083103,\n",
       "              -0.06465711, -0.0311482 ,  0.03153968,  0.00241242,  0.10432341,\n",
       "               0.02965955,  0.01042238, -0.11576117, -0.07256157, -0.01843143,\n",
       "               0.00907455,  0.02330094,  0.1429404 , -0.1220054 ,  0.00298892,\n",
       "              -0.09142344, -0.00143123, -0.05544674,  0.04999436, -0.00626177,\n",
       "               0.06953299, -0.10313874, -0.01059465,  0.02448926,  0.06121974,\n",
       "               0.01484322,  0.00214627,  0.01636332,  0.04284527,  0.09505107,\n",
       "              -0.00309762, -0.14855617, -0.03704038, -0.03973285, -0.07410331,\n",
       "               0.02100951, -0.05927467,  0.08795189,  0.0800169 , -0.02911199,\n",
       "              -0.04375492, -0.05754744, -0.08386101, -0.0249017 , -0.10230475,\n",
       "               0.04385085, -0.00431078, -0.03234655,  0.14640898,  0.01457639]),\n",
       "       array([ 0.08054659, -0.05460365,  0.01836888,  0.09026856, -0.13573152,\n",
       "              -0.07198418,  0.02314987,  0.01255929, -0.11043614, -0.03100345,\n",
       "               0.01808475,  0.10977957,  0.07949035, -0.09746918, -0.13225225,\n",
       "              -0.04226302,  0.01438062,  0.11748558,  0.02345723,  0.05519614,\n",
       "              -0.04463319, -0.04624968,  0.0131656 ,  0.00079193,  0.1319499 ,\n",
       "               0.06747991, -0.05615346, -0.1116878 ,  0.04815131,  0.07249077,\n",
       "              -0.06197667, -0.03912475,  0.10499958,  0.02664376, -0.04767235,\n",
       "               0.02495338, -0.06576911,  0.00165093,  0.01010442,  0.04299067,\n",
       "               0.06143444, -0.0183002 ,  0.09515687, -0.00125226, -0.0248839 ,\n",
       "              -0.03047724,  0.07659236,  0.01310452, -0.00948669, -0.03618772,\n",
       "              -0.0387403 ,  0.0255671 , -0.05579665, -0.0566953 ,  0.04139421,\n",
       "               0.04655844, -0.0701242 , -0.01089774,  0.02863208,  0.04551983,\n",
       "               0.03277633, -0.16044682,  0.00961384, -0.09189526, -0.01167906,\n",
       "              -0.00706927,  0.07486555,  0.1113416 ,  0.00830431,  0.0179588 ,\n",
       "               0.01049748,  0.03757414, -0.00371294,  0.05420559,  0.05810415,\n",
       "              -0.05391545,  0.0501144 , -0.01751188, -0.05212175, -0.01662003,\n",
       "               0.00873602, -0.00223401, -0.03990887, -0.01260754, -0.07434874,\n",
       "              -0.02032176, -0.0096663 , -0.02995243,  0.1470061 ,  0.04163649,\n",
       "              -0.04565198, -0.02849913, -0.04433024, -0.07290946, -0.03733646,\n",
       "              -0.02376339, -0.06292018,  0.01408367, -0.07884059,  0.06889837,\n",
       "               0.01538599, -0.04208361,  0.04546376, -0.02473152,  0.04841361,\n",
       "               0.04362121, -0.07552111, -0.1240879 , -0.08718535, -0.02629094,\n",
       "              -0.07446748, -0.01593684,  0.05155569, -0.01762301,  0.00558573,\n",
       "              -0.04453788,  0.00808165, -0.01074577, -0.08261941, -0.00921057,\n",
       "              -0.05824491, -0.02598959,  0.06522467, -0.08314823, -0.08347301,\n",
       "               0.03118547, -0.00809086,  0.05805569, -0.14275073, -0.01012324,\n",
       "               0.04201854, -0.04639946, -0.09373361,  0.00213089, -0.02348146,\n",
       "               0.12975293,  0.13765737,  0.00899972,  0.04409877,  0.03790252,\n",
       "               0.06996281,  0.0259153 ,  0.01792997,  0.05112979, -0.09698721,\n",
       "              -0.1021951 , -0.07811314, -0.04516121, -0.02192844,  0.09272923,\n",
       "              -0.05938785,  0.08304251, -0.09302959, -0.04172299,  0.02595956,\n",
       "               0.04813228,  0.06006844, -0.04981485,  0.05318439, -0.1412694 ,\n",
       "               0.08102154, -0.0204363 , -0.05891629, -0.1009915 ,  0.12461452,\n",
       "               0.08813646, -0.00449446,  0.07803065, -0.01177737, -0.10192859,\n",
       "               0.0698653 ,  0.11036245, -0.06206698,  0.05878494, -0.03683087,\n",
       "               0.0235173 ,  0.00907301,  0.08525529,  0.06210182,  0.0316422 ,\n",
       "              -0.11603108,  0.00176767,  0.1026178 , -0.01523301, -0.00408598,\n",
       "              -0.08529334,  0.04855538, -0.0377123 ,  0.0517359 ,  0.02294303,\n",
       "              -0.02076568, -0.00208324, -0.04613074, -0.00877526,  0.04306996,\n",
       "              -0.0792741 ,  0.12272231, -0.16047505,  0.10945579, -0.06919451,\n",
       "               0.04497199,  0.03210574, -0.11463625,  0.06162486, -0.0349767 ,\n",
       "              -0.06058184,  0.09652627,  0.07076655, -0.05285841,  0.01596787,\n",
       "               0.03516292,  0.06160684,  0.04062931,  0.04051578, -0.00464964,\n",
       "              -0.01947477,  0.10433721,  0.04375637, -0.06869113, -0.03605116,\n",
       "               0.08674143, -0.04786237,  0.14192997,  0.03615208, -0.1385404 ,\n",
       "               0.0676443 ,  0.02752499,  0.05628562, -0.02089984,  0.00604106,\n",
       "              -0.10690041, -0.07715642,  0.01535215, -0.05777696,  0.00374478,\n",
       "              -0.01272949, -0.08633316,  0.0720913 ,  0.01511988,  0.02615979,\n",
       "               0.01696103,  0.03893313,  0.04077708, -0.01977973, -0.00705505,\n",
       "               0.01003974,  0.0138548 ,  0.03778859,  0.04299007,  0.00644914]),\n",
       "       array([-1.52642699e-02, -4.16457407e-02, -4.27674991e-02, -5.31152682e-02,\n",
       "              -4.41538113e-02,  1.29533291e-01, -2.63861685e-02,  6.30948870e-02,\n",
       "              -1.85509204e-03,  2.75724582e-02,  8.71050147e-04, -2.46868419e-02,\n",
       "              -1.86072926e-02,  1.06271579e-01, -4.12264103e-02, -3.00135249e-02,\n",
       "               7.20570856e-02,  4.40395834e-03,  4.40897744e-02,  7.70890506e-02,\n",
       "               3.82609333e-02, -2.68141526e-02,  1.38252941e-02, -1.06322265e-01,\n",
       "               1.94810625e-02, -4.54142750e-02, -1.73747431e-01, -6.11040565e-02,\n",
       "               1.26625176e-01, -9.02354052e-02, -7.84904449e-02,  7.98681036e-03,\n",
       "               2.67582748e-02,  3.95149686e-02, -1.09379470e-02, -6.42018105e-02,\n",
       "               7.60382521e-02, -6.72436868e-03,  4.23135541e-02, -3.80673392e-02,\n",
       "              -9.78553015e-03, -1.00267688e-01,  2.02495053e-03,  4.20480111e-02,\n",
       "              -5.17492302e-02, -5.62083245e-02,  1.33709535e-01, -3.35145383e-02,\n",
       "              -8.47190840e-03, -1.33666020e-01, -4.75841121e-02,  7.22511743e-02,\n",
       "              -5.79909733e-02,  1.88847034e-03,  5.33602897e-02,  7.20756291e-02,\n",
       "               7.71409724e-04,  1.21705955e-01, -5.08826305e-02,  2.57381349e-02,\n",
       "               2.95410365e-03,  6.56877632e-02, -9.42949489e-03,  1.36344196e-02,\n",
       "               1.20453650e-02,  8.81078473e-02,  6.51455512e-02, -8.74519018e-02,\n",
       "              -1.29116186e-01, -2.57317065e-02,  6.48023728e-02, -2.19480901e-03,\n",
       "               4.40625773e-02, -3.28571093e-02, -5.37019847e-04, -6.48686349e-02,\n",
       "              -1.39113359e-01, -1.33387126e-02,  7.90912544e-02,  1.54301725e-01,\n",
       "               5.92395691e-02,  1.55404445e-01,  1.79360178e-02,  1.11951083e-01,\n",
       "               2.09563836e-02, -1.66310497e-02,  7.82901751e-02, -1.33270425e-01,\n",
       "               2.64816057e-02,  3.73443898e-02, -2.17797151e-02, -2.12815130e-02,\n",
       "               1.58062347e-02,  5.81375906e-03, -4.02183855e-02, -5.57830602e-02,\n",
       "              -8.66933489e-02,  1.96578439e-02, -3.59467042e-02,  9.87401975e-02,\n",
       "              -4.11252864e-02, -5.42016702e-02,  7.29657173e-02, -6.13555064e-02,\n",
       "              -1.22733265e-03,  7.92450419e-02, -6.60934951e-02, -4.15554957e-02,\n",
       "              -6.96840118e-02, -6.88972727e-02,  5.14416553e-02,  1.37221922e-02,\n",
       "               6.45761420e-02, -4.10943806e-02, -3.37986248e-03,  5.91137206e-02,\n",
       "              -5.58975354e-02, -4.19117782e-02,  2.28564745e-02,  1.15656323e-01,\n",
       "              -1.70182381e-01,  3.34425895e-02, -1.05425996e-02,  2.26295021e-02,\n",
       "              -7.16273709e-04, -1.13135642e-01, -7.63992323e-05,  3.84221382e-04,\n",
       "               4.98548259e-03, -1.20520902e-01, -1.30475054e-01, -1.65170690e-02,\n",
       "              -6.85664566e-03, -1.38443321e-02,  8.25618565e-02, -4.01355579e-03,\n",
       "               6.57478442e-03, -3.81429967e-02,  5.64051329e-02, -4.11275117e-02,\n",
       "              -3.39116165e-02,  1.06055486e-01, -2.92285167e-02, -3.08521858e-02,\n",
       "              -1.64525376e-02,  8.85091287e-02,  1.54187991e-02,  2.21983038e-02,\n",
       "               1.16329328e-01, -2.80765942e-02, -5.33788332e-02, -5.59660227e-02,\n",
       "              -5.45671009e-02,  4.32820195e-02, -4.10446840e-02,  1.70951318e-02,\n",
       "               1.05852249e-01,  1.41935681e-01,  2.23263776e-04, -1.06180840e-01,\n",
       "              -4.30167237e-02,  2.06448527e-02,  7.35781474e-02, -3.72956822e-02,\n",
       "              -3.43608638e-02, -2.89073432e-02, -2.46465407e-02,  3.02036577e-03,\n",
       "              -7.73009410e-02, -2.75146025e-02,  6.28481348e-02,  4.81970367e-02,\n",
       "              -1.87007519e-02, -8.57923819e-02,  8.97372031e-02,  3.52966926e-02,\n",
       "              -3.23418472e-02,  5.76084826e-05,  1.19946795e-01, -3.54996821e-03,\n",
       "               2.57329427e-02, -6.29618683e-02, -2.07321308e-02, -7.52594250e-03,\n",
       "              -2.38941690e-02, -1.32359074e-01,  7.13207850e-02,  5.59761599e-02,\n",
       "               7.19020620e-02, -2.61572181e-02,  9.14929020e-02, -3.85514482e-02,\n",
       "               5.48148421e-02, -5.01661095e-02, -3.27883747e-02,  2.31316601e-02,\n",
       "              -1.18132993e-01, -9.56822502e-02, -2.35035192e-02, -1.02742133e-01,\n",
       "              -1.80564270e-03, -1.56769247e-02, -6.59033624e-02, -4.52706247e-02,\n",
       "              -1.29167861e-01,  3.84666426e-02, -4.97195819e-02,  8.66945852e-02,\n",
       "              -9.64014909e-03, -4.89936656e-02, -5.73389837e-03, -4.97143898e-02,\n",
       "               9.47498829e-03,  5.55721587e-02,  1.02765868e-01, -1.24985435e-01,\n",
       "              -6.15523148e-02, -6.10170257e-02,  5.44946576e-02, -9.95983908e-03,\n",
       "               7.29325862e-02, -2.71637594e-02, -3.95446382e-02,  7.06821467e-02,\n",
       "              -2.51927087e-02, -8.47660609e-03,  6.55871338e-02, -1.40599312e-02,\n",
       "              -5.53733724e-02, -4.26401670e-02, -2.60813133e-02, -4.54911688e-02,\n",
       "               2.77747060e-02,  7.44385659e-03,  7.89730705e-02, -3.83694746e-02,\n",
       "              -1.49461376e-01, -4.08374913e-02, -7.21547481e-02, -4.14837942e-02,\n",
       "               4.80833032e-02,  1.47223051e-02,  5.78431197e-02, -1.54578641e-03,\n",
       "               1.75404231e-02, -4.42695228e-03, -9.03550727e-02,  6.19526072e-03,\n",
       "               5.87356803e-02,  4.77732559e-02])                                 ],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordVecMat_gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_gensim = get_wordnet_lexicon(wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 118. GiB for an array with shape (125777, 125777) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[85], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m similarity_matrix_gensim \u001b[39m=\u001b[39m generate_cosine_similarity_matrix(wordVecs_gensim)\n\u001b[0;32m      2\u001b[0m retrofitted_similarity_matrix_gensim \u001b[39m=\u001b[39m generate_cosine_similarity_matrix(wordVecs_gensim)\n",
      "Cell \u001b[1;32mIn[49], line 9\u001b[0m, in \u001b[0;36mgenerate_cosine_similarity_matrix\u001b[1;34m(vectors)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate_cosine_similarity_matrix\u001b[39m(vectors):\n\u001b[0;32m      8\u001b[0m     num_vectors \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(vectors)\n\u001b[1;32m----> 9\u001b[0m     similarity_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((num_vectors, num_vectors))\n\u001b[0;32m     11\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_vectors):\n\u001b[0;32m     12\u001b[0m         \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_vectors):\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 118. GiB for an array with shape (125777, 125777) and data type float64"
     ]
    }
   ],
   "source": [
    "similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)\n",
    "retrofitted_similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrofitted_wordVecs_gensim, updates_gensim = retrofitting_wordVecs(wordVecMat_gensim, neighbors_matrix_gensim, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_vec_difference(wordVecs_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_matrix_gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m print_vec_difference(wordList_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity_matrix_gensim' is not defined"
     ]
    }
   ],
   "source": [
    "print_vec_difference(wordList_gensim, similarity_matrix_gensim, retrofitted_similarity_matrix_gensim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
