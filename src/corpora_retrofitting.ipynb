{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw to\n",
      "[nltk_data]     C:\\Users\\ninan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard library imports\n",
    "import argparse\n",
    "import gzip\n",
    "import math\n",
    "import re\n",
    "import sys\n",
    "import urllib.request\n",
    "import io\n",
    "import random\n",
    "from copy import deepcopy\n",
    "\n",
    "# Third-party library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim import corpora, matutils\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.cluster import KMeans\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('omw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained Word2Vec model\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "isNumber = re.compile(r'\\d+.*')\n",
    "\n",
    "def norm_word(word):\n",
    "  \"\"\"\n",
    "  - input: word\n",
    "  - return: a normalized version of it\n",
    "  Normalization process: includes checking if the word is a number or a punctuation mark and replacing it with special tokens\n",
    "  \"\"\"\n",
    "  if isNumber.search(word.lower()):\n",
    "    return '---num---'\n",
    "  # check if the word consists only of non-alphanumeric characters by removing all non-alphanumeric characters from the word \n",
    "  # and checking if the result is an empty string\n",
    "  elif re.sub(r'\\W+', '', word) == '':\n",
    "    return '---punc---'\n",
    "  else:\n",
    "  # if input word not a number nor a punctuation mark, return a lowercase version of input word\n",
    "    return word.lower()\n",
    "  \n",
    "\n",
    "  \n",
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    first_line = True\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # Skip the first line\n",
    "      if first_line:\n",
    "        first_line =False\n",
    "        continue\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors\n",
    "\n",
    "  ''' Write word vectors to file '''\n",
    "def print_word_vecs(wordVectors, outFileName):\n",
    "  \"\"\"\n",
    "  - input: a dictionary wordVectors where keys are words and values are their corresponding word vectors\n",
    "           file name outFileName\n",
    "  \"\"\"\n",
    "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
    "  outFile = open(outFileName, 'w', encoding= 'utf-8')  \n",
    "  for word, values in wordVectors.items():\n",
    "    outFile.write(word+' ')\n",
    "    for val in wordVectors[word]:\n",
    "      # write the word vectors to the ouptut file in the format:\n",
    "      # word1 val1 val2 val3 ...\n",
    "      # word2 val1 val2 val3 ...\n",
    "      # ...\n",
    "      outFile.write('%.4f' %(val)+' ')\n",
    "    outFile.write('\\n')      \n",
    "  outFile.close()\n",
    "\n",
    "''' Read the PPDB word relations as a dictionary '''\n",
    "def read_lexicon(filename):\n",
    "    lexicon = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            words = line.lower().strip().split()\n",
    "            lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the same format for the toy corpus as for the provided word embeddings\n",
    "def convert_matrix_to_dict(wordVecMat, wordList):\n",
    "    wordVecs = {}\n",
    "\n",
    "    for i, word in enumerate(wordList):\n",
    "        wordVecs[word] = wordVecMat[i]\n",
    "\n",
    "    return wordVecs\n",
    "\n",
    "def convert_dict_to_matrix(wordVecs):\n",
    "    wordVecMat = np.stack(list(wordVecs.values()))\n",
    "    return wordVecMat\n",
    "\n",
    "def vectorize_list(corpus):\n",
    "    corpus_vecs = [model[word] for word in corpus]\n",
    "\n",
    "    return corpus_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same input format as the real corpus\n",
    "toy_corpus = [\"cat\", \"tiger\", \"computer\", \"keyboard\", \"plane\", \"car\", \"doctor\", \"nurse\", \"love\", \"sex\"]\n",
    "toy_corpus_list_vecs = vectorize_list(toy_corpus)\n",
    "toy_wordVecs = convert_matrix_to_dict(toy_corpus_list_vecs, toy_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
    "    similarity = dot_product / norm_product\n",
    "    return similarity\n",
    "\n",
    "def generate_cosine_similarity_matrix(dict_vecs): \n",
    "    num_vectors = len(dict_vecs)\n",
    "    similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "    for i, word1 in enumerate(dict_vecs):\n",
    "        for j, word2 in enumerate(dict_vecs):\n",
    "            similarity_matrix[i, j] = calculate_cosine_similarity(dict_vecs[word1], dict_vecs[word2])\n",
    "    return similarity_matrix\n",
    "\n",
    "def print_vec_similarities(wordList, similarity_matrix):\n",
    "    for word, vec in zip(wordList, similarity_matrix):\n",
    "        print(f'Similarities with \"{word}\":')\n",
    "        for i in range(len(vec)):\n",
    "            similarity = vec[i]\n",
    "            print(f'  - \"{wordList[i]}\": {similarity:.4f}')\n",
    "        print()\n",
    "\n",
    "def print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix):\n",
    "    difference = np.abs(similarity_matrix - retrofitted_similarity_matrix)\n",
    "    print(\"Similarity Difference Matrix:\")\n",
    "    print(difference)\n",
    "\n",
    "def cosine_similarity_matrix(matrix1, matrix2):\n",
    "    dot_product = np.sum(matrix1 * matrix2)\n",
    "    norm_matrix1 = np.linalg.norm(matrix1)\n",
    "    norm_matrix2 = np.linalg.norm(matrix2)\n",
    "    cosine_similarity = dot_product / (norm_matrix1 * norm_matrix2)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon(target_words, relation_types):\n",
    "    lexicon = {}\n",
    "        \n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas():\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"antonyms\" in relation_types:\n",
    "                if syn.lemmas()[0].antonyms():\n",
    "                    related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "            if \"hyponyms\" in relation_types:\n",
    "                for hypo in syn.hyponyms():\n",
    "                    for lemma in hypo.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"hypernyms\" in relation_types:\n",
    "                for hyper in syn.hypernyms():\n",
    "                    for lemma in hyper.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"meronyms\" in relation_types:\n",
    "                for part in syn.part_meronyms():\n",
    "                    for lemma in part.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"holonyms\" in relation_types:\n",
    "                for whole in syn.part_holonyms():\n",
    "                    for lemma in whole.lemmas():\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"homonyms\" in relation_types:\n",
    "                for lemma in syn.lemmas():\n",
    "                    if lemma.name() != word:\n",
    "                        homonyms = wordnet.lemmas(lemma.name())\n",
    "                        for homonym in homonyms:\n",
    "                            related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordVecMat = convert_dict_to_matrix(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(toy_corpus_list_vecs)) \n",
    "\n",
    "print(type(wordVecMat)) \n",
    "print(wordVecMat.shape)  \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 10)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(similarity_matrix)) \n",
    "print(similarity_matrix.shape)  \n",
    "print(similarity_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for the big corpus to retrive the word list from the keys\n",
    "def get_embeddings_words(wordVecs):\n",
    "    wordList = list(wordVecs.keys()) # TODO: or set?\n",
    "    return wordList\n",
    "\n",
    "wordList = get_embeddings_words(toy_wordVecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neighbors_embedding_matrix(wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        embeddings = [\n",
    "            model.get_vector(neighbor)\n",
    "            for neighbor in neighbors\n",
    "            if model.has_index_for(neighbor)\n",
    "        ]\n",
    "        if len(embeddings) > 0:\n",
    "            average_embedding = np.sum(embeddings, axis=0) / len(embeddings)\n",
    "        else:\n",
    "            # Handle the case where a word has no embeddings for its synonyms\n",
    "            average_embedding = np.zeros(model.vector_size)  # Use a zero vector\n",
    "        average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix\n",
    "\n",
    "   \n",
    "    \n",
    "neighbors_matrix = create_neighbors_embedding_matrix(wordList, \"synonyms\")\n",
    "\n",
    "# récupérer la liste des syn dans wordnet\n",
    "# vectorise chaque syn\n",
    "# BOW des synonymes (sum) pour n'avoir qu'un embedding \n",
    "# BOW_syn_cat\n",
    "# BOW_syn_dog= neighbors_matrix, shape (10, embedding_size) donc same size as wordVecs_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix))  # <class 'numpy.ndarray'>\n",
    "print(neighbors_matrix.shape)  # (m, n)\n",
    "print(neighbors_matrix.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  # <class 'numpy.ndarray'>\n",
    "print(wordVecMat.shape)  # (m, n)\n",
    "print(wordVecMat.ndim)   # 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00676925  0.17245371 -0.32560504 -0.02995695  0.24918167  0.06591797\n",
      "  0.07754347  0.02062197  0.12026186 -0.24899179  0.11663705 -0.43598995\n",
      " -0.0165247  -0.43618888  0.05141873 -0.2046328   0.09973597  0.0461245\n",
      " -0.4420053   0.08787028  0.26338252 -0.1518453   0.11536521 -0.14642108\n",
      " -0.04931188  0.32405486 -0.15808557  0.31547716  0.40427201 -0.007934\n",
      " -0.00195312 -0.20903128 -0.03433369 -0.0849519   0.01340795  0.15198545\n",
      " -0.07754234  0.04350902  0.00148463  0.24564164  0.00093107  0.03174506\n",
      " -0.14347048  0.13828702  0.08990253 -0.03038646  0.37447442 -0.05503337\n",
      "  0.00611821  0.00164738 -0.15880896  0.13665545  0.34953252  0.14862174\n",
      " -0.0103189  -0.14141733  0.15832859 -0.30018898  0.35803392  0.18776052\n",
      "  0.28351056  0.18667716 -0.01274052  0.19207764  0.04131345  0.04772498\n",
      "  0.20808016  0.02882668 -0.10890771 -0.12867793  0.40634721 -0.03548855\n",
      " -0.15468343 -0.01318077 -0.11528298  0.38514766  0.11844098 -0.08239746\n",
      " -0.02005401 -0.06692618  0.08503554 -0.00346544  0.1995228  -0.07893711\n",
      " -0.34383251  0.04050474 -0.2636391  -0.14694101 -0.1783899  -0.0918257\n",
      " -0.0131429   0.04139088 -0.06987395 -0.25662345 -0.17748967 -0.27476671\n",
      " -0.01672363 -0.17666287 -0.33676034 -0.18375199 -0.24108435 -0.02301817\n",
      " -0.0048376   0.25613178  0.07612101 -0.20470513  0.0953064  -0.03844798\n",
      "  0.04892759 -0.11653646 -0.07707384  0.29826298  0.11636692  0.32834201\n",
      " -0.31238471 -0.00066913 -0.02505154 -0.23873901 -0.22574163 -0.04350577\n",
      " -0.03468753 -0.05264395 -0.30785455  0.02505323 -0.34844179  0.11226626\n",
      "  0.10000073  0.1189044   0.04702872 -0.14758527  0.13923419  0.04321967\n",
      " -0.15519799 -0.06542969 -0.02879789 -0.11844042 -0.02837584  0.09594444\n",
      "  0.10183038  0.10198523 -0.06081022  0.02417896 -0.15294054  0.04794516\n",
      "  0.06066442  0.15922716 -0.19703731  0.17048589 -0.12367983 -0.15320898\n",
      "  0.22272971  0.09056261 -0.31849727 -0.08702935 -0.13079947 -0.05045121\n",
      "  0.09113679  0.05342385  0.03645833  0.22512252 -0.10272612 -0.05701814\n",
      "  0.09566696 -0.13046604 -0.12130398  0.00603117 -0.04856138  0.21248373\n",
      "  0.17837637  0.02974899 -0.08555999 -0.03059218 -0.04345082  0.23660165\n",
      " -0.08013295  0.09815696  0.07034867 -0.12642416 -0.242515    0.27940539\n",
      " -0.16617132  0.01541816 -0.00099126  0.0524677  -0.03739194  0.07791251\n",
      "  0.20973601  0.3004286   0.12838844  0.06714884  0.02089154 -0.16434733\n",
      "  0.12680845  0.06278935 -0.01593244  0.184226    0.07969835 -0.18987359\n",
      " -0.11193918  0.18708067  0.06552409 -0.27893744 -0.0675354  -0.05583897\n",
      "  0.04787643  0.11910897 -0.01438636 -0.13045473  0.10323758 -0.26696325\n",
      " -0.40234262 -0.02973316 -0.0515894  -0.08254327 -0.11705977 -0.0447789\n",
      "  0.16213056 -0.31804127 -0.10855222  0.12037037  0.18612897  0.11705413\n",
      " -0.22371081 -0.27236599 -0.2145137  -0.07454851  0.07460587 -0.07304269\n",
      "  0.22288344  0.00952374  0.10791355  0.03955135 -0.03007846  0.04184525\n",
      " -0.28511386  0.05631058  0.27960488  0.02073415 -0.08864961  0.066971\n",
      "  0.23477738 -0.20298824  0.03927584  0.03217344  0.33202221  0.05400481\n",
      "  0.05493726 -0.036039    0.22249632 -0.13921215 -0.33608415  0.18813239\n",
      " -0.28481038  0.02863178 -0.04690326  0.27920871 -0.1286395   0.1268627\n",
      " -0.15716192  0.07503933 -0.08402846  0.04506429 -0.04430474 -0.1314799\n",
      "  0.06542573  0.24106775 -0.10216381  0.02992079 -0.27746017 -0.02798801\n",
      " -0.07106696  0.04219563 -0.15462466  0.13976994  0.05472141  0.09482377\n",
      "  0.1267994   0.16184228  0.17293295 -0.14490651  0.2610078   0.05841742\n",
      " -0.20719062  0.28466684  0.13873743 -0.08083654 -0.09813182  0.04846644\n",
      "  0.08657498  0.13033097 -0.25310149  0.11868851 -0.1590384   0.03733656\n",
      "  0.42320421 -0.01760412  0.18546778  0.49357605 -0.276461    0.01063255]\n"
     ]
    }
   ],
   "source": [
    "difference = toy_corpus_list_vecs[0] - neighbors_matrix[0]\n",
    "print(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs(wordVecMat, neighbors_mean_matrix, alpha, beta, nb_iter):\n",
    "    # Create a deep copy of wordVecMat \n",
    "    newWordVecMat = np.copy(wordVecMat, order='K')\n",
    "    updates = []\n",
    "    \n",
    "    for _ in range(nb_iter):\n",
    "        # Calculate the number of neighbors for each word\n",
    "        # numNeighbors = np.sum(neighbors_mean_matrix != 0, axis=1)\n",
    "        \n",
    "        # Update the word embeddings using retrofitting formula\n",
    "        newWordVecMat = (alpha * newWordVecMat + beta * neighbors_mean_matrix) / (alpha + beta)\n",
    "\n",
    "        # Calculate the updates\n",
    "        update = newWordVecMat - wordVecMat\n",
    "        updates.append(update)\n",
    "\n",
    "        # Update the wordVecMat for the next iteration\n",
    "        wordVecMat = newWordVecMat\n",
    "        # TODO: calculer similarité après chaque itération\n",
    "        # Stoping criterion\n",
    "        if np.linalg.norm(updates) < 1e-2:\n",
    "            break # TODO: return the embedding\n",
    "\n",
    "    # Convert the matrix back to a dictionary of word vectors\n",
    "    # retrofitted_wordVecs = dict(zip(wordList, newWordVecMat))\n",
    "\n",
    "    return newWordVecMat, updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = get_wordnet_lexicon(wordList, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sexual_urge': ['sex'],\n",
       " 'suck': ['nurse'],\n",
       " 'puke': ['cat'],\n",
       " 'love_life': ['love'],\n",
       " 'jazz': ['love'],\n",
       " 'Doctor_of_the_Church': ['doctor'],\n",
       " 'computing_machine': ['computer'],\n",
       " 'bozo': ['cat'],\n",
       " 'motorcar': ['car'],\n",
       " 'cast': ['cat'],\n",
       " 'railcar': ['car'],\n",
       " 'elevator_car': ['car'],\n",
       " 'wind_up': ['sex'],\n",
       " 'computer': ['figurer',\n",
       "  'data_processor',\n",
       "  'reckoner',\n",
       "  'information_processing_system',\n",
       "  'computing_machine',\n",
       "  'calculator',\n",
       "  'estimator',\n",
       "  'electronic_computer',\n",
       "  'computing_device'],\n",
       " 'airplane': ['plane'],\n",
       " 'vomit': ['cat'],\n",
       " 'retch': ['cat'],\n",
       " 'kat': ['cat'],\n",
       " 'Dr.': ['doctor'],\n",
       " 'know': ['love'],\n",
       " 'shave': ['plane'],\n",
       " 'aeroplane': ['plane'],\n",
       " 'lovemaking': ['love'],\n",
       " 'get_it_on': ['love'],\n",
       " 'bushel': ['doctor'],\n",
       " 'repair': ['doctor'],\n",
       " 'CT': ['cat'],\n",
       " 'medico': ['doctor'],\n",
       " 'lactate': ['nurse'],\n",
       " 'CAT': ['cat'],\n",
       " 'touch_on': ['doctor'],\n",
       " 'have_intercourse': ['love'],\n",
       " 'calculator': ['computer'],\n",
       " 'hump': ['love'],\n",
       " \"cat-o'-nine-tails\": ['cat'],\n",
       " 'true_cat': ['cat'],\n",
       " 'sophisticate': ['doctor'],\n",
       " 'keyboard': [],\n",
       " 'automobile': ['car'],\n",
       " 'roll_in_the_hay': ['love'],\n",
       " 'screw': ['love'],\n",
       " 'eff': ['love'],\n",
       " 'hombre': ['cat'],\n",
       " 'sexual_activity': ['sex'],\n",
       " 'sex_activity': ['sex'],\n",
       " 'honey': ['love'],\n",
       " 'figurer': ['computer'],\n",
       " 'erotic_love': ['love'],\n",
       " 'sexuality': ['sex'],\n",
       " 'entertain': ['nurse'],\n",
       " 'Caterpillar': ['cat'],\n",
       " 'give_suck': ['nurse'],\n",
       " 'big_cat': ['cat'],\n",
       " 'spue': ['cat'],\n",
       " 'planer': ['plane'],\n",
       " 'dearest': ['love'],\n",
       " 'honk': ['cat'],\n",
       " 'reckoner': ['computer'],\n",
       " 'sheet': ['plane'],\n",
       " 'turn_on': ['sex'],\n",
       " 'have_it_away': ['love'],\n",
       " 'get_laid': ['love'],\n",
       " 'plane': ['level',\n",
       "  'flat',\n",
       "  \"carpenter's_plane\",\n",
       "  'airplane',\n",
       "  'sheet',\n",
       "  'planing_machine',\n",
       "  'shave',\n",
       "  'woodworking_plane',\n",
       "  'aeroplane',\n",
       "  'skim',\n",
       "  'planer'],\n",
       " 'doctor_up': ['doctor'],\n",
       " 'be_intimate': ['love'],\n",
       " 'dear': ['love'],\n",
       " 'hold': ['nurse'],\n",
       " 'barf': ['cat'],\n",
       " 'wet-nurse': ['nurse'],\n",
       " 'mend': ['doctor'],\n",
       " 'cable_car': ['car'],\n",
       " 'nursemaid': ['nurse'],\n",
       " 'bonk': ['love'],\n",
       " 'sleep_with': ['love'],\n",
       " 'railway_car': ['car'],\n",
       " 'beloved': ['love'],\n",
       " 'make_love': ['love'],\n",
       " 'vomit_up': ['cat'],\n",
       " 'planing_machine': ['plane'],\n",
       " 'have_a_go_at_it': ['love'],\n",
       " 'be_sick': ['cat'],\n",
       " 'enjoy': ['love'],\n",
       " 'tiger': ['Panthera_tigris'],\n",
       " 'fuck': ['love'],\n",
       " 'machine': ['car'],\n",
       " 'suckle': ['nurse'],\n",
       " 'passion': ['love'],\n",
       " 'make_out': ['love'],\n",
       " 'sick': ['cat'],\n",
       " 'woodworking_plane': ['plane'],\n",
       " 'quat': ['cat'],\n",
       " 'excite': ['sex'],\n",
       " 'fix': ['doctor'],\n",
       " 'arouse': ['sex'],\n",
       " 'sex': ['sexual_urge',\n",
       "  'wind_up',\n",
       "  'arouse',\n",
       "  'sexuality',\n",
       "  'sexual_practice',\n",
       "  'turn_on',\n",
       "  'gender',\n",
       "  'excite',\n",
       "  'sexual_activity',\n",
       "  'sex_activity'],\n",
       " 'khat': ['cat'],\n",
       " 'do_it': ['love'],\n",
       " 'purge': ['cat'],\n",
       " 'bed': ['love'],\n",
       " 'upchuck': ['cat'],\n",
       " 'electronic_computer': ['computer'],\n",
       " 'computerized_tomography': ['cat'],\n",
       " 'physician': ['doctor'],\n",
       " 'computed_tomography': ['cat'],\n",
       " 'Doctor': ['doctor'],\n",
       " 'regurgitate': ['cat'],\n",
       " 'chuck': ['cat'],\n",
       " 'gondola': ['car'],\n",
       " 'gender': ['sex'],\n",
       " 'guy': ['cat'],\n",
       " 'level': ['plane'],\n",
       " 'flat': ['plane'],\n",
       " 'doc': ['doctor'],\n",
       " 'Arabian_tea': ['cat'],\n",
       " 'bang': ['love'],\n",
       " 'auto': ['car'],\n",
       " 'spew': ['cat'],\n",
       " 'railroad_car': ['car'],\n",
       " 'computing_device': ['computer'],\n",
       " 'throw_up': ['cat'],\n",
       " 'MD': ['doctor'],\n",
       " 'car': ['automobile',\n",
       "  'gondola',\n",
       "  'cable_car',\n",
       "  'auto',\n",
       "  'motorcar',\n",
       "  'railcar',\n",
       "  'railroad_car',\n",
       "  'machine',\n",
       "  'elevator_car',\n",
       "  'railway_car'],\n",
       " 'lie_with': ['love'],\n",
       " 'nanny': ['nurse'],\n",
       " 'sleep_together': ['love'],\n",
       " 'cat': ['sick',\n",
       "  'puke',\n",
       "  'bozo',\n",
       "  'cast',\n",
       "  'quat',\n",
       "  'Caterpillar',\n",
       "  'big_cat',\n",
       "  'spue',\n",
       "  'khat',\n",
       "  'purge',\n",
       "  'honk',\n",
       "  'vomit',\n",
       "  'retch',\n",
       "  'kat',\n",
       "  'upchuck',\n",
       "  'computerized_tomography',\n",
       "  'disgorge',\n",
       "  'computed_tomography',\n",
       "  'barf',\n",
       "  'African_tea',\n",
       "  'CT',\n",
       "  'regurgitate',\n",
       "  'chuck',\n",
       "  'CAT',\n",
       "  \"cat-o'-nine-tails\",\n",
       "  'computerized_axial_tomography',\n",
       "  'true_cat',\n",
       "  'guy',\n",
       "  'regorge',\n",
       "  'Arabian_tea',\n",
       "  'vomit_up',\n",
       "  'computed_axial_tomography',\n",
       "  'qat',\n",
       "  'be_sick',\n",
       "  'spew',\n",
       "  'hombre',\n",
       "  'throw_up'],\n",
       " 'furbish_up': ['doctor'],\n",
       " 'nurse': ['lactate',\n",
       "  'nanny',\n",
       "  'suck',\n",
       "  'entertain',\n",
       "  'nursemaid',\n",
       "  'wet-nurse',\n",
       "  'breastfeed',\n",
       "  'harbor',\n",
       "  'give_suck',\n",
       "  'harbour',\n",
       "  'hold',\n",
       "  'suckle'],\n",
       " 'estimator': ['computer'],\n",
       " 'skim': ['plane'],\n",
       " 'disgorge': ['cat'],\n",
       " 'love': ['passion',\n",
       "  'make_out',\n",
       "  'lie_with',\n",
       "  'erotic_love',\n",
       "  'love_life',\n",
       "  'jazz',\n",
       "  'sleep_together',\n",
       "  'dearest',\n",
       "  'do_it',\n",
       "  'know',\n",
       "  'have_it_away',\n",
       "  'get_laid',\n",
       "  'be_intimate',\n",
       "  'bed',\n",
       "  'dear',\n",
       "  'lovemaking',\n",
       "  'get_it_on',\n",
       "  'sexual_love',\n",
       "  'have_intercourse',\n",
       "  'bonk',\n",
       "  'hump',\n",
       "  'sleep_with',\n",
       "  'have_it_off',\n",
       "  'beloved',\n",
       "  'have_sex',\n",
       "  'make_love',\n",
       "  'bang',\n",
       "  'roll_in_the_hay',\n",
       "  'have_a_go_at_it',\n",
       "  'making_love',\n",
       "  'screw',\n",
       "  'enjoy',\n",
       "  'fuck',\n",
       "  'eff',\n",
       "  'honey'],\n",
       " 'African_tea': ['cat'],\n",
       " 'sexual_love': ['love'],\n",
       " 'data_processor': ['computer'],\n",
       " \"carpenter's_plane\": ['plane'],\n",
       " 'sexual_practice': ['sex'],\n",
       " 'breastfeed': ['nurse'],\n",
       " 'computerized_axial_tomography': ['cat'],\n",
       " 'harbor': ['nurse'],\n",
       " 'harbour': ['nurse'],\n",
       " 'regorge': ['cat'],\n",
       " 'have_it_off': ['love'],\n",
       " 'have_sex': ['love'],\n",
       " 'information_processing_system': ['computer'],\n",
       " 'restore': ['doctor'],\n",
       " 'computed_axial_tomography': ['cat'],\n",
       " 'making_love': ['love'],\n",
       " 'qat': ['cat'],\n",
       " 'Panthera_tigris': ['tiger'],\n",
       " 'doctor': ['Doctor',\n",
       "  'MD',\n",
       "  'repair',\n",
       "  'mend',\n",
       "  'medico',\n",
       "  'doc',\n",
       "  'bushel',\n",
       "  'furbish_up',\n",
       "  'restore',\n",
       "  'Dr.',\n",
       "  'Doctor_of_the_Church',\n",
       "  'touch_on',\n",
       "  'doctor_up',\n",
       "  'sophisticate',\n",
       "  'physician',\n",
       "  'fix']}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def generate_graph_from_synonyms(synonyms_dict):\n",
    "    graph = {}\n",
    "    \n",
    "    # Create a set of all unique words in the dictionary\n",
    "    words = set(synonyms_dict.keys()).union(*synonyms_dict.values())\n",
    "    \n",
    "    # Initialize an empty adjacency dictionary for each word\n",
    "    for word in words:\n",
    "        graph[word] = set()\n",
    "    \n",
    "    # Iterate through the synonyms dictionary\n",
    "    for word, synonyms in synonyms_dict.items():\n",
    "        # Add synonyms to the adjacency set for the word\n",
    "        graph[word].update(synonyms)\n",
    "        \n",
    "        # Add the word as a synonym to each synonym's adjacency set\n",
    "        for synonym in synonyms:\n",
    "            graph[synonym].add(word)\n",
    "    \n",
    "    # Convert the adjacency sets to lists\n",
    "    graph = {word: list(adjacency_set) for word, adjacency_set in graph.items()}\n",
    "    \n",
    "    return graph\n",
    "\n",
    "graph = generate_graph_from_synonyms(lexicon)\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_article(Q, Q_hat, graph, alpha, beta, num_iterations=10):\n",
    "    num_words = Q.shape[0]\n",
    "\n",
    "    for _ in range(num_iterations):\n",
    "        Q_new = np.zeros_like(Q)\n",
    "        for i in range(num_words):\n",
    "            neighbors = graph[i]\n",
    "            numerator = np.sum(beta[i, j] * Q[j] for j in neighbors) + alpha[i] * Q_hat[i]\n",
    "            denominator = np.sum(beta[i, j] for j in neighbors) + alpha[i]\n",
    "            Q_new[i] = numerator / denominator\n",
    "        Q = Q_new\n",
    "\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_toy_vecs, updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newVecs = retrofitting_wordVecs_article(wordVecMat, neighbors_matrix, graph, alpha=1, beta=1, num_iterations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 6\n",
      "Number of edges: 5\n",
      "Neighbors of cat: ['kitten', 'animal', 'pet']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words_to_keep = [\"cat\", \"kitten\", \"dog\", \"puppy\", \"animal\", \"pet\"]\n",
    "# Construct an empty graph\n",
    "graph = nx.Graph()\n",
    "\n",
    "# Add nodes to the graph\n",
    "graph.add_nodes_from(words_to_keep)\n",
    "\n",
    "# Add edges between related words\n",
    "graph.add_edges_from([('cat', 'kitten'), ('dog', 'puppy'), ('cat', 'animal'), ('dog', 'animal'), ('cat', 'pet')])\n",
    "\n",
    "# Print the graph information\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Access neighbors of a word\n",
    "word = 'cat'\n",
    "neighbors = graph.neighbors(word)\n",
    "print(\"Neighbors of\", word + \":\", list(neighbors))\n",
    "\n",
    "# Create the layout for the graph\n",
    "layout = nx.spring_layout(graph)\n",
    "\n",
    "# Draw the nodes\n",
    "nx.draw_networkx_nodes(graph, pos=layout, node_color='lightblue', node_size=500)\n",
    "\n",
    "# Draw the edges\n",
    "nx.draw_networkx_edges(graph, pos=layout, edge_color='gray')\n",
    "\n",
    "# Add labels to the nodes\n",
    "nx.draw_networkx_labels(graph, pos=layout, font_color='black')\n",
    "\n",
    "# Set plot properties\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00338463, -0.08622685,  0.16280252, ..., -0.24678802,\n",
       "          0.1382305 , -0.00531627],\n",
       "        [ 0.08007812, -0.06433105,  0.02783203, ..., -0.08123779,\n",
       "          0.03717041, -0.03466797],\n",
       "        [ 0.00255203,  0.02276611, -0.13401031, ..., -0.07601929,\n",
       "          0.05496216,  0.07133484],\n",
       "        ...,\n",
       "        [ 0.04763455,  0.11241319, -0.07042948, ..., -0.00129022,\n",
       "         -0.09945594, -0.13053046],\n",
       "        [-0.03367829,  0.04928064, -0.00994873, ...,  0.08418322,\n",
       "          0.06436348,  0.01234341],\n",
       "        [ 0.04439545, -0.02075195,  0.11517334, ..., -0.06329346,\n",
       "          0.06408691, -0.06994629]]),\n",
       " array([[-0.00169231, -0.04311343,  0.08140126, ..., -0.12339401,\n",
       "          0.06911525, -0.00265814],\n",
       "        [ 0.04003906, -0.03216553,  0.01391602, ..., -0.0406189 ,\n",
       "          0.01858521, -0.01733398],\n",
       "        [ 0.00127602,  0.01138306, -0.06700516, ..., -0.03800964,\n",
       "          0.02748108,  0.03566742],\n",
       "        ...,\n",
       "        [ 0.02381727,  0.0562066 , -0.03521474, ..., -0.00064511,\n",
       "         -0.04972797, -0.06526523],\n",
       "        [-0.01683915,  0.02464032, -0.00497437, ...,  0.04209161,\n",
       "          0.03218174,  0.0061717 ],\n",
       "        [ 0.02219772, -0.01037598,  0.05758667, ..., -0.03164673,\n",
       "          0.03204346, -0.03497314]]),\n",
       " array([[-0.00084616, -0.02155671,  0.04070063, ..., -0.06169701,\n",
       "          0.03455763, -0.00132907],\n",
       "        [ 0.02001953, -0.01608276,  0.00695801, ..., -0.02030945,\n",
       "          0.0092926 , -0.00866699],\n",
       "        [ 0.00063801,  0.00569153, -0.03350258, ..., -0.01900482,\n",
       "          0.01374054,  0.01783371],\n",
       "        ...,\n",
       "        [ 0.01190864,  0.0281033 , -0.01760737, ..., -0.00032255,\n",
       "         -0.02486398, -0.03263262],\n",
       "        [-0.00841957,  0.01232016, -0.00248718, ...,  0.0210458 ,\n",
       "          0.01609087,  0.00308585],\n",
       "        [ 0.01109886, -0.00518799,  0.02879333, ..., -0.01582336,\n",
       "          0.01602173, -0.01748657]]),\n",
       " array([[-0.00042308, -0.01077836,  0.02035031, ..., -0.0308485 ,\n",
       "          0.01727881, -0.00066453],\n",
       "        [ 0.01000977, -0.00804138,  0.003479  , ..., -0.01015472,\n",
       "          0.0046463 , -0.0043335 ],\n",
       "        [ 0.000319  ,  0.00284576, -0.01675129, ..., -0.00950241,\n",
       "          0.00687027,  0.00891685],\n",
       "        ...,\n",
       "        [ 0.00595432,  0.01405165, -0.00880369, ..., -0.00016128,\n",
       "         -0.01243199, -0.01631631],\n",
       "        [-0.00420979,  0.00616008, -0.00124359, ...,  0.0105229 ,\n",
       "          0.00804543,  0.00154293],\n",
       "        [ 0.00554943, -0.00259399,  0.01439667, ..., -0.00791168,\n",
       "          0.00801086, -0.00874329]]),\n",
       " array([[-2.11539096e-04, -5.38917829e-03,  1.01751575e-02, ...,\n",
       "         -1.54242516e-02,  8.63940627e-03, -3.32267140e-04],\n",
       "        [ 5.00488281e-03, -4.02069092e-03,  1.73950195e-03, ...,\n",
       "         -5.07736206e-03,  2.32315063e-03, -2.16674805e-03],\n",
       "        [ 1.59502029e-04,  1.42288208e-03, -8.37564468e-03, ...,\n",
       "         -4.75120544e-03,  3.43513489e-03,  4.45842743e-03],\n",
       "        ...,\n",
       "        [ 2.97715928e-03,  7.02582463e-03, -4.40184260e-03, ...,\n",
       "         -8.06384487e-05, -6.21599623e-03, -8.15815385e-03],\n",
       "        [-2.10489333e-03,  3.08004022e-03, -6.21795654e-04, ...,\n",
       "          5.26145101e-03,  4.02271748e-03,  7.71462917e-04],\n",
       "        [ 2.77471542e-03, -1.29699707e-03,  7.19833374e-03, ...,\n",
       "         -3.95584106e-03,  4.00543213e-03, -4.37164307e-03]]),\n",
       " array([[-1.05769548e-04, -2.69458914e-03,  5.08757873e-03, ...,\n",
       "         -7.71212578e-03,  4.31970314e-03, -1.66133570e-04],\n",
       "        [ 2.50244141e-03, -2.01034546e-03,  8.69750977e-04, ...,\n",
       "         -2.53868103e-03,  1.16157532e-03, -1.08337402e-03],\n",
       "        [ 7.97510147e-05,  7.11441040e-04, -4.18782234e-03, ...,\n",
       "         -2.37560272e-03,  1.71756744e-03,  2.22921371e-03],\n",
       "        ...,\n",
       "        [ 1.48857964e-03,  3.51291231e-03, -2.20092130e-03, ...,\n",
       "         -4.03192244e-05, -3.10799811e-03, -4.07907693e-03],\n",
       "        [-1.05244666e-03,  1.54002011e-03, -3.10897827e-04, ...,\n",
       "          2.63072550e-03,  2.01135874e-03,  3.85731459e-04],\n",
       "        [ 1.38735771e-03, -6.48498535e-04,  3.59916687e-03, ...,\n",
       "         -1.97792053e-03,  2.00271606e-03, -2.18582153e-03]]),\n",
       " array([[-5.28847740e-05, -1.34729457e-03,  2.54378936e-03, ...,\n",
       "         -3.85606289e-03,  2.15985157e-03, -8.30667850e-05],\n",
       "        [ 1.25122070e-03, -1.00517273e-03,  4.34875488e-04, ...,\n",
       "         -1.26934052e-03,  5.80787659e-04, -5.41687012e-04],\n",
       "        [ 3.98755074e-05,  3.55720520e-04, -2.09391117e-03, ...,\n",
       "         -1.18780136e-03,  8.58783722e-04,  1.11460686e-03],\n",
       "        ...,\n",
       "        [ 7.44289820e-04,  1.75645616e-03, -1.10046065e-03, ...,\n",
       "         -2.01596122e-05, -1.55399906e-03, -2.03953846e-03],\n",
       "        [-5.26223332e-04,  7.70010054e-04, -1.55448914e-04, ...,\n",
       "          1.31536275e-03,  1.00567937e-03,  1.92865729e-04],\n",
       "        [ 6.93678856e-04, -3.24249268e-04,  1.79958344e-03, ...,\n",
       "         -9.88960266e-04,  1.00135803e-03, -1.09291077e-03]]),\n",
       " array([[-2.64423870e-05, -6.73647286e-04,  1.27189468e-03, ...,\n",
       "         -1.92803144e-03,  1.07992578e-03, -4.15333925e-05],\n",
       "        [ 6.25610352e-04, -5.02586365e-04,  2.17437744e-04, ...,\n",
       "         -6.34670258e-04,  2.90393829e-04, -2.70843506e-04],\n",
       "        [ 1.99377537e-05,  1.77860260e-04, -1.04695559e-03, ...,\n",
       "         -5.93900681e-04,  4.29391861e-04,  5.57303429e-04],\n",
       "        ...,\n",
       "        [ 3.72144910e-04,  8.78228078e-04, -5.50230325e-04, ...,\n",
       "         -1.00798061e-05, -7.76999528e-04, -1.01976923e-03],\n",
       "        [-2.63111666e-04,  3.85005027e-04, -7.77244568e-05, ...,\n",
       "          6.57681376e-04,  5.02839684e-04,  9.64328647e-05],\n",
       "        [ 3.46839428e-04, -1.62124634e-04,  8.99791718e-04, ...,\n",
       "         -4.94480133e-04,  5.00679016e-04, -5.46455383e-04]]),\n",
       " array([[-1.32211935e-05, -3.36823643e-04,  6.35947341e-04, ...,\n",
       "         -9.64015722e-04,  5.39962892e-04, -2.07666963e-05],\n",
       "        [ 3.12805176e-04, -2.51293182e-04,  1.08718872e-04, ...,\n",
       "         -3.17335129e-04,  1.45196915e-04, -1.35421753e-04],\n",
       "        [ 9.96887684e-06,  8.89301300e-05, -5.23477793e-04, ...,\n",
       "         -2.96950340e-04,  2.14695930e-04,  2.78651714e-04],\n",
       "        ...,\n",
       "        [ 1.86072455e-04,  4.39114039e-04, -2.75115162e-04, ...,\n",
       "         -5.03990304e-06, -3.88499764e-04, -5.09884616e-04],\n",
       "        [-1.31555833e-04,  1.92502514e-04, -3.88622284e-05, ...,\n",
       "          3.28840688e-04,  2.51419842e-04,  4.82164323e-05],\n",
       "        [ 1.73419714e-04, -8.10623169e-05,  4.49895859e-04, ...,\n",
       "         -2.47240067e-04,  2.50339508e-04, -2.73227692e-04]]),\n",
       " array([[-6.61059676e-06, -1.68411822e-04,  3.17973670e-04, ...,\n",
       "         -4.82007861e-04,  2.69981446e-04, -1.03833481e-05],\n",
       "        [ 1.56402588e-04, -1.25646591e-04,  5.43594360e-05, ...,\n",
       "         -1.58667564e-04,  7.25984573e-05, -6.77108765e-05],\n",
       "        [ 4.98443842e-06,  4.44650650e-05, -2.61738896e-04, ...,\n",
       "         -1.48475170e-04,  1.07347965e-04,  1.39325857e-04],\n",
       "        ...,\n",
       "        [ 9.30362276e-05,  2.19557020e-04, -1.37557581e-04, ...,\n",
       "         -2.51995152e-06, -1.94249882e-04, -2.54942308e-04],\n",
       "        [-6.57779165e-05,  9.62512568e-05, -1.94311142e-05, ...,\n",
       "          1.64420344e-04,  1.25709921e-04,  2.41082162e-05],\n",
       "        [ 8.67098570e-05, -4.05311584e-05,  2.24947929e-04, ...,\n",
       "         -1.23620033e-04,  1.25169754e-04, -1.36613846e-04]])]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5173\n",
      "  - \"computer\": 0.1732\n",
      "  - \"keyboard\": 0.1834\n",
      "  - \"plane\": 0.1833\n",
      "  - \"car\": 0.2153\n",
      "  - \"doctor\": 0.1292\n",
      "  - \"nurse\": 0.1594\n",
      "  - \"love\": 0.1406\n",
      "  - \"sex\": 0.1368\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0677\n",
      "  - \"keyboard\": 0.0654\n",
      "  - \"plane\": 0.1660\n",
      "  - \"car\": 0.1672\n",
      "  - \"doctor\": 0.0835\n",
      "  - \"nurse\": 0.1111\n",
      "  - \"love\": 0.0871\n",
      "  - \"sex\": 0.2222\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732\n",
      "  - \"tiger\": 0.0677\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.3964\n",
      "  - \"plane\": 0.1909\n",
      "  - \"car\": 0.2461\n",
      "  - \"doctor\": 0.1628\n",
      "  - \"nurse\": 0.2178\n",
      "  - \"love\": 0.0573\n",
      "  - \"sex\": 0.1853\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834\n",
      "  - \"tiger\": 0.0654\n",
      "  - \"computer\": 0.3964\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1006\n",
      "  - \"car\": 0.1498\n",
      "  - \"doctor\": 0.0850\n",
      "  - \"nurse\": 0.1220\n",
      "  - \"love\": 0.1591\n",
      "  - \"sex\": 0.0943\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833\n",
      "  - \"tiger\": 0.1660\n",
      "  - \"computer\": 0.1909\n",
      "  - \"keyboard\": 0.1006\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.3780\n",
      "  - \"doctor\": 0.1879\n",
      "  - \"nurse\": 0.0978\n",
      "  - \"love\": 0.1080\n",
      "  - \"sex\": 0.0587\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153\n",
      "  - \"tiger\": 0.1672\n",
      "  - \"computer\": 0.2461\n",
      "  - \"keyboard\": 0.1498\n",
      "  - \"plane\": 0.3780\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1895\n",
      "  - \"nurse\": 0.1306\n",
      "  - \"love\": 0.0842\n",
      "  - \"sex\": 0.1169\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292\n",
      "  - \"tiger\": 0.0835\n",
      "  - \"computer\": 0.1628\n",
      "  - \"keyboard\": 0.0850\n",
      "  - \"plane\": 0.1879\n",
      "  - \"car\": 0.1895\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6320\n",
      "  - \"love\": 0.0831\n",
      "  - \"sex\": 0.1994\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594\n",
      "  - \"tiger\": 0.1111\n",
      "  - \"computer\": 0.2178\n",
      "  - \"keyboard\": 0.1220\n",
      "  - \"plane\": 0.0978\n",
      "  - \"car\": 0.1306\n",
      "  - \"doctor\": 0.6320\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.0631\n",
      "  - \"sex\": 0.1997\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406\n",
      "  - \"tiger\": 0.0871\n",
      "  - \"computer\": 0.0573\n",
      "  - \"keyboard\": 0.1591\n",
      "  - \"plane\": 0.1080\n",
      "  - \"car\": 0.0842\n",
      "  - \"doctor\": 0.0831\n",
      "  - \"nurse\": 0.0631\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.2639\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368\n",
      "  - \"tiger\": 0.2222\n",
      "  - \"computer\": 0.1853\n",
      "  - \"keyboard\": 0.0943\n",
      "  - \"plane\": 0.0587\n",
      "  - \"car\": 0.1169\n",
      "  - \"doctor\": 0.1994\n",
      "  - \"nurse\": 0.1997\n",
      "  - \"love\": 0.2639\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retrofitted_toy_matrix = convert_dict_to_matrix(retrofitted_toy_vecs)\n",
    "retrofitted_similarity_matrix = generate_cosine_similarity_matrix(toy_wordVecs)\n",
    "print_vec_similarities(toy_corpus, retrofitted_similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172961950302124"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrofitted_similarity_matrix[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"car\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"love\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5173 (Difference: 0.0000)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"car\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"love\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.1732 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0677 -> 0.0677 (Difference: 0.0000)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"car\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"love\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.1834 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0654 -> 0.0654 (Difference: 0.0000)\n",
      "  - \"computer\": 0.3964 -> 0.3964 (Difference: 0.0000)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"car\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"love\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.1833 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1660 -> 0.1660 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1909 -> 0.1909 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1006 -> 0.1006 (Difference: 0.0000)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"car\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"love\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"sex\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2153 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1672 -> 0.1672 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2461 -> 0.2461 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1498 -> 0.1498 (Difference: 0.0000)\n",
      "  - \"plane\": 0.3780 -> 0.3780 (Difference: 0.0000)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"love\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.1292 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0835 -> 0.0835 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1628 -> 0.1628 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0850 -> 0.0850 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1879 -> 0.1879 (Difference: 0.0000)\n",
      "  - \"car\": 0.1895 -> 0.1895 (Difference: 0.0000)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"love\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.1594 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.1111 -> 0.1111 (Difference: 0.0000)\n",
      "  - \"computer\": 0.2178 -> 0.2178 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1220 -> 0.1220 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0978 -> 0.0978 (Difference: 0.0000)\n",
      "  - \"car\": 0.1306 -> 0.1306 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.6320 -> 0.6320 (Difference: 0.0000)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"sex\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.1406 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.0871 -> 0.0871 (Difference: 0.0000)\n",
      "  - \"computer\": 0.0573 -> 0.0573 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.1591 -> 0.1591 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1080 -> 0.1080 (Difference: 0.0000)\n",
      "  - \"car\": 0.0842 -> 0.0842 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.0831 -> 0.0831 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.0631 -> 0.0631 (Difference: 0.0000)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.1368 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.2222 -> 0.2222 (Difference: 0.0000)\n",
      "  - \"computer\": 0.1853 -> 0.1853 (Difference: 0.0000)\n",
      "  - \"keyboard\": 0.0943 -> 0.0943 (Difference: 0.0000)\n",
      "  - \"plane\": 0.0587 -> 0.0587 (Difference: 0.0000)\n",
      "  - \"car\": 0.1169 -> 0.1169 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1994 -> 0.1994 (Difference: 0.0000)\n",
      "  - \"nurse\": 0.1997 -> 0.1997 (Difference: 0.0000)\n",
      "  - \"love\": 0.2639 -> 0.2639 (Difference: 0.0000)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "def print_vec_difference(wordList, similarity_matrix1, similarity_matrix2):\n",
    "    for i, word in enumerate(wordList):\n",
    "        print(f\"\\nSimilarities with \\\"{word}\\\":\")\n",
    "        for j, neighbor in enumerate(wordList):\n",
    "            similarity1 = similarity_matrix1[i, j]\n",
    "            similarity2 = similarity_matrix2[i, j]\n",
    "            difference = similarity2 - similarity1  # Calculate the difference\n",
    "            print(f\"  - \\\"{neighbor}\\\": {similarity1:.4f} -> {similarity2:.4f} (Difference: {difference:.4f})\")\n",
    "\n",
    "print_vec_difference(toy_corpus, similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Difference Matrix:\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print_similarity_difference(similarity_matrix, retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity between wordVecMat and retrofitted_toy_vec\n",
    "# similarity_score = cosine_similarity_matrix(wordVecMat, retrofitted_toy_vecs)\n",
    "# print(\"Cosine Similarity:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average embedding update: 0.12658860989283166\n"
     ]
    }
   ],
   "source": [
    "def measure_embedding_updates(original_matrix, retrofitted_matrix):\n",
    "    absolute_diff = np.abs(original_matrix - retrofitted_matrix)\n",
    "    mean_absolute_diff = np.mean(absolute_diff)\n",
    "    return mean_absolute_diff\n",
    "\n",
    "# Example usage\n",
    "update_measure = measure_embedding_updates(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Average embedding update:\", update_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation score: 0.42055888661904023\n",
      "Pearson correlation score: 0.4232245375810048\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "def spearman_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = spearmanr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "def pearson_measure_embedding_similarity(original_matrix, retrofitted_matrix):\n",
    "    original_flat = original_matrix.flatten()\n",
    "    retrofitted_flat = retrofitted_matrix.flatten()\n",
    "    correlation, _ = pearsonr(original_flat, retrofitted_flat)\n",
    "    return correlation\n",
    "\n",
    "similarity_score = spearman_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Spearman correlation score:\", similarity_score)\n",
    "similarity_score = pearson_measure_embedding_similarity(wordVecMat, retrofitted_toy_vecs)\n",
    "print(\"Pearson correlation score:\", similarity_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 0.1, 'nb_iter': 1}\n",
      "Best Spearman correlation score: 0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load human evaluation scores\n",
    "eval_file_path = r\"C:\\Users\\ninan\\OneDrive\\Bureau\\Université Paris Cité\\S2\\NLP project\\Improving-vector-space-representations-using-semantic-resources\\data\\English\\lexicon\\ws353_lexical_similarity.txt\"\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Find best values for hyperparameters\n",
    "best_similarity_score = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "iteration_count = 0\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1, 16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            cosine_sim = cosine_similarity(wordVecMat, retrofitted_toy_vec)\n",
    "\n",
    "            # Calculate Spearman correlation against human evaluation scores\n",
    "            eval_scores_list = []\n",
    "            cosine_sim_list = []\n",
    "            for (word1, word2), score in eval_scores.items():\n",
    "                if word1 in wordList and word2 in wordList:\n",
    "                    word1_index = wordList.index(word1)\n",
    "                    word2_index = wordList.index(word2)\n",
    "                    eval_scores_list.append(score)\n",
    "                    cosine_sim_list.append(cosine_sim[word1_index, word2_index])\n",
    "\n",
    "            # Check if there are valid pairs for comparison\n",
    "            if len(eval_scores_list) > 0 and len(cosine_sim_list) > 0:\n",
    "                correlation, _ = spearmanr(eval_scores_list, cosine_sim_list)\n",
    "                # print(\"alpha =\", alpha, \"beta =\", beta, \"nb_iter =\", nb_iter, \"correlation =\", correlation)\n",
    "\n",
    "                # Update best similarity score and parameters if improved\n",
    "                if correlation > best_similarity_score:\n",
    "                    best_similarity_score = correlation\n",
    "                    best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "            iteration_count += 1\n",
    "            if iteration_count >= 100:\n",
    "                break\n",
    "        if iteration_count >= 100:\n",
    "            break\n",
    "    if iteration_count >= 100:\n",
    "        break\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best Spearman correlation score:\", best_similarity_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'alpha': 0.1, 'beta': 1.1000000000000003, 'nb_iter': 15}\n",
      "Best embedding update: 0.12671235242449622\n"
     ]
    }
   ],
   "source": [
    "# Find best values for hyperparameters\n",
    "best_embed_update = -1  # Variable to store the best similarity score\n",
    "best_params = {}  # Dictionary to store the best hyperparameter values\n",
    "\n",
    "for alpha in np.arange(0.1, 5.1, 0.2):\n",
    "    for beta in np.arange(0.1, 5.1, 0.2):\n",
    "        for nb_iter in range(1,16):\n",
    "            retrofitted_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "            embed_update = measure_embedding_updates(wordVecMat, retrofitted_toy_vec)\n",
    "            # print(\" alpha =\", alpha, \" beta=\", beta, \"nb_iter =\", nb_iter, \" similarity score =\", similarity_score)\n",
    "            if embed_update > best_embed_update:\n",
    "                best_embed_update = embed_update\n",
    "                best_params = {'alpha': alpha, 'beta': beta, 'nb_iter': nb_iter}\n",
    "\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best embedding update:\", best_embed_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000\n",
      "  - \"tiger\": 0.5134\n",
      "  - \"computer\": 0.2147\n",
      "  - \"keyboard\": 0.2270\n",
      "  - \"plane\": 0.2878\n",
      "  - \"car\": 0.2492\n",
      "  - \"doctor\": 0.2437\n",
      "  - \"nurse\": 0.3233\n",
      "  - \"love\": 0.3254\n",
      "  - \"sex\": 0.2202\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5134\n",
      "  - \"tiger\": 1.0000\n",
      "  - \"computer\": 0.0783\n",
      "  - \"keyboard\": 0.1118\n",
      "  - \"plane\": 0.1769\n",
      "  - \"car\": 0.1518\n",
      "  - \"doctor\": 0.0866\n",
      "  - \"nurse\": 0.1714\n",
      "  - \"love\": 0.1518\n",
      "  - \"sex\": 0.2417\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.2147\n",
      "  - \"tiger\": 0.0783\n",
      "  - \"computer\": 1.0000\n",
      "  - \"keyboard\": 0.4058\n",
      "  - \"plane\": 0.2883\n",
      "  - \"car\": 0.3039\n",
      "  - \"doctor\": 0.2093\n",
      "  - \"nurse\": 0.2180\n",
      "  - \"love\": 0.1358\n",
      "  - \"sex\": 0.1602\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.2270\n",
      "  - \"tiger\": 0.1118\n",
      "  - \"computer\": 0.4058\n",
      "  - \"keyboard\": 1.0000\n",
      "  - \"plane\": 0.1872\n",
      "  - \"car\": 0.1700\n",
      "  - \"doctor\": 0.1131\n",
      "  - \"nurse\": 0.1637\n",
      "  - \"love\": 0.2198\n",
      "  - \"sex\": 0.1140\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.2878\n",
      "  - \"tiger\": 0.1769\n",
      "  - \"computer\": 0.2883\n",
      "  - \"keyboard\": 0.1872\n",
      "  - \"plane\": 1.0000\n",
      "  - \"car\": 0.4366\n",
      "  - \"doctor\": 0.2202\n",
      "  - \"nurse\": 0.1756\n",
      "  - \"love\": 0.1935\n",
      "  - \"sex\": 0.0994\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2492\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.3039\n",
      "  - \"keyboard\": 0.1700\n",
      "  - \"plane\": 0.4366\n",
      "  - \"car\": 1.0000\n",
      "  - \"doctor\": 0.1865\n",
      "  - \"nurse\": 0.1453\n",
      "  - \"love\": 0.1766\n",
      "  - \"sex\": 0.1273\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.2437\n",
      "  - \"tiger\": 0.0866\n",
      "  - \"computer\": 0.2093\n",
      "  - \"keyboard\": 0.1131\n",
      "  - \"plane\": 0.2202\n",
      "  - \"car\": 0.1865\n",
      "  - \"doctor\": 1.0000\n",
      "  - \"nurse\": 0.6105\n",
      "  - \"love\": 0.1844\n",
      "  - \"sex\": 0.1923\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.3233\n",
      "  - \"tiger\": 0.1714\n",
      "  - \"computer\": 0.2180\n",
      "  - \"keyboard\": 0.1637\n",
      "  - \"plane\": 0.1756\n",
      "  - \"car\": 0.1453\n",
      "  - \"doctor\": 0.6105\n",
      "  - \"nurse\": 1.0000\n",
      "  - \"love\": 0.2675\n",
      "  - \"sex\": 0.3084\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.3254\n",
      "  - \"tiger\": 0.1518\n",
      "  - \"computer\": 0.1358\n",
      "  - \"keyboard\": 0.2198\n",
      "  - \"plane\": 0.1935\n",
      "  - \"car\": 0.1766\n",
      "  - \"doctor\": 0.1844\n",
      "  - \"nurse\": 0.2675\n",
      "  - \"love\": 1.0000\n",
      "  - \"sex\": 0.3760\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.2202\n",
      "  - \"tiger\": 0.2417\n",
      "  - \"computer\": 0.1602\n",
      "  - \"keyboard\": 0.1140\n",
      "  - \"plane\": 0.0994\n",
      "  - \"car\": 0.1273\n",
      "  - \"doctor\": 0.1923\n",
      "  - \"nurse\": 0.3084\n",
      "  - \"love\": 0.3760\n",
      "  - \"sex\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_retrofitted_toy_matrix, new_updates = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha=0.1, beta=0.1, nb_iter=1)\n",
    "new_retrofitted_toy_dict = convert_matrix_to_dict(new_retrofitted_toy_matrix, wordList)\n",
    "new_retrofitted_similarity_matrix = generate_cosine_similarity_matrix(new_retrofitted_toy_dict)\n",
    "print_vec_similarities(toy_corpus, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between original and after tuning hyperparam\n",
    "print_vec_difference(toy_corpus, similarity_matrix, new_retrofitted_similarity_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarities with \"cat\":\n",
      "  - \"cat\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"tiger\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"computer\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"keyboard\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"plane\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"car\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"doctor\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"nurse\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"love\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"sex\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "\n",
      "Similarities with \"tiger\":\n",
      "  - \"cat\": 0.5173 -> 0.5134 (Difference: -0.0039)\n",
      "  - \"tiger\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"computer\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"keyboard\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"plane\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"car\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"doctor\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"nurse\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"love\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"sex\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "\n",
      "Similarities with \"computer\":\n",
      "  - \"cat\": 0.1732 -> 0.2147 (Difference: 0.0415)\n",
      "  - \"tiger\": 0.0677 -> 0.0783 (Difference: 0.0106)\n",
      "  - \"computer\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"keyboard\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"plane\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"car\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"doctor\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"nurse\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"love\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"sex\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "\n",
      "Similarities with \"keyboard\":\n",
      "  - \"cat\": 0.1834 -> 0.2270 (Difference: 0.0436)\n",
      "  - \"tiger\": 0.0654 -> 0.1118 (Difference: 0.0464)\n",
      "  - \"computer\": 0.3964 -> 0.4058 (Difference: 0.0094)\n",
      "  - \"keyboard\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"plane\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"car\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"doctor\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"nurse\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"love\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"sex\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "\n",
      "Similarities with \"plane\":\n",
      "  - \"cat\": 0.1833 -> 0.2878 (Difference: 0.1045)\n",
      "  - \"tiger\": 0.1660 -> 0.1769 (Difference: 0.0109)\n",
      "  - \"computer\": 0.1909 -> 0.2883 (Difference: 0.0974)\n",
      "  - \"keyboard\": 0.1006 -> 0.1872 (Difference: 0.0866)\n",
      "  - \"plane\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"car\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"doctor\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"nurse\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"love\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"sex\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "\n",
      "Similarities with \"car\":\n",
      "  - \"cat\": 0.2153 -> 0.2492 (Difference: 0.0339)\n",
      "  - \"tiger\": 0.1672 -> 0.1518 (Difference: -0.0154)\n",
      "  - \"computer\": 0.2461 -> 0.3039 (Difference: 0.0577)\n",
      "  - \"keyboard\": 0.1498 -> 0.1700 (Difference: 0.0201)\n",
      "  - \"plane\": 0.3780 -> 0.4366 (Difference: 0.0586)\n",
      "  - \"car\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"doctor\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"nurse\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"love\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"sex\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "\n",
      "Similarities with \"doctor\":\n",
      "  - \"cat\": 0.1292 -> 0.2437 (Difference: 0.1145)\n",
      "  - \"tiger\": 0.0835 -> 0.0866 (Difference: 0.0031)\n",
      "  - \"computer\": 0.1628 -> 0.2093 (Difference: 0.0465)\n",
      "  - \"keyboard\": 0.0850 -> 0.1131 (Difference: 0.0281)\n",
      "  - \"plane\": 0.1879 -> 0.2202 (Difference: 0.0323)\n",
      "  - \"car\": 0.1895 -> 0.1865 (Difference: -0.0031)\n",
      "  - \"doctor\": 1.0000 -> 1.0000 (Difference: -0.0000)\n",
      "  - \"nurse\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"love\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"sex\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "\n",
      "Similarities with \"nurse\":\n",
      "  - \"cat\": 0.1594 -> 0.3233 (Difference: 0.1639)\n",
      "  - \"tiger\": 0.1111 -> 0.1714 (Difference: 0.0603)\n",
      "  - \"computer\": 0.2178 -> 0.2180 (Difference: 0.0002)\n",
      "  - \"keyboard\": 0.1220 -> 0.1637 (Difference: 0.0417)\n",
      "  - \"plane\": 0.0978 -> 0.1756 (Difference: 0.0778)\n",
      "  - \"car\": 0.1306 -> 0.1453 (Difference: 0.0148)\n",
      "  - \"doctor\": 0.6320 -> 0.6105 (Difference: -0.0215)\n",
      "  - \"nurse\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"love\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"sex\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "\n",
      "Similarities with \"love\":\n",
      "  - \"cat\": 0.1406 -> 0.3254 (Difference: 0.1848)\n",
      "  - \"tiger\": 0.0871 -> 0.1518 (Difference: 0.0647)\n",
      "  - \"computer\": 0.0573 -> 0.1358 (Difference: 0.0784)\n",
      "  - \"keyboard\": 0.1591 -> 0.2198 (Difference: 0.0607)\n",
      "  - \"plane\": 0.1080 -> 0.1935 (Difference: 0.0855)\n",
      "  - \"car\": 0.0842 -> 0.1766 (Difference: 0.0924)\n",
      "  - \"doctor\": 0.0831 -> 0.1844 (Difference: 0.1013)\n",
      "  - \"nurse\": 0.0631 -> 0.2675 (Difference: 0.2044)\n",
      "  - \"love\": 1.0000 -> 1.0000 (Difference: 0.0000)\n",
      "  - \"sex\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "\n",
      "Similarities with \"sex\":\n",
      "  - \"cat\": 0.1368 -> 0.2202 (Difference: 0.0833)\n",
      "  - \"tiger\": 0.2222 -> 0.2417 (Difference: 0.0194)\n",
      "  - \"computer\": 0.1853 -> 0.1602 (Difference: -0.0251)\n",
      "  - \"keyboard\": 0.0943 -> 0.1140 (Difference: 0.0197)\n",
      "  - \"plane\": 0.0587 -> 0.0994 (Difference: 0.0407)\n",
      "  - \"car\": 0.1169 -> 0.1273 (Difference: 0.0104)\n",
      "  - \"doctor\": 0.1994 -> 0.1923 (Difference: -0.0071)\n",
      "  - \"nurse\": 0.1997 -> 0.3084 (Difference: 0.1087)\n",
      "  - \"love\": 0.2639 -> 0.3760 (Difference: 0.1121)\n",
      "  - \"sex\": 1.0000 -> 1.0000 (Difference: 0.0000)\n"
     ]
    }
   ],
   "source": [
    "# Difference between retrofitted embeddings and after tuning hyperaparams\n",
    "print_vec_difference(toy_corpus, retrofitted_similarity_matrix, new_retrofitted_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>Before: 0.29245239862991185, After: 1.00000000...</td>\n",
       "      <td>Before: 0.35037322527996934, After: 0.20200897...</td>\n",
       "      <td>Before: 0.06136659928459301, After: 0.19719178...</td>\n",
       "      <td>Before: 0.18344955625364173, After: 0.20547455...</td>\n",
       "      <td>Before: 0.21134097025538556, After: 0.39445950...</td>\n",
       "      <td>Before: 0.136072027917602, After: 0.2634861035...</td>\n",
       "      <td>Before: 0.16547475026405636, After: 0.34338708...</td>\n",
       "      <td>Before: 0.24690899138830727, After: 0.54854860...</td>\n",
       "      <td>Before: 0.2989067535773432, After: 0.594053102...</td>\n",
       "      <td>Before: 0.1093022564011111, After: 0.259890845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Before: 0.17347637872059773, After: 0.20200897...</td>\n",
       "      <td>Before: 0.48802072485209846, After: 1.00000000...</td>\n",
       "      <td>Before: 0.02942476361382193, After: 0.09025702...</td>\n",
       "      <td>Before: 0.06542581824273716, After: 0.18313975...</td>\n",
       "      <td>Before: 0.15090617196611955, After: 0.07307479...</td>\n",
       "      <td>Before: 0.16119598769364896, After: 0.10033040...</td>\n",
       "      <td>Before: 0.0774108002811773, After: 0.089083542...</td>\n",
       "      <td>Before: 0.1697249630498177, After: 0.202597136...</td>\n",
       "      <td>Before: 0.17516455047450735, After: 0.19102605...</td>\n",
       "      <td>Before: 0.14518818082220147, After: 0.18807845...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>Before: 0.18984798734723213, After: 0.19719178...</td>\n",
       "      <td>Before: 0.05360514929979338, After: 0.09025702...</td>\n",
       "      <td>Before: 0.3047689400402037, After: 1.0</td>\n",
       "      <td>Before: 0.39639163439495995, After: 0.23934215...</td>\n",
       "      <td>Before: 0.28314903703275535, After: 0.40858220...</td>\n",
       "      <td>Before: 0.26826894486108244, After: 0.22732308...</td>\n",
       "      <td>Before: 0.18039329196329013, After: 0.20986951...</td>\n",
       "      <td>Before: 0.09297679298707379, After: 0.12068024...</td>\n",
       "      <td>Before: 0.1168711356729625, After: 0.234808759...</td>\n",
       "      <td>Before: 0.1158779845883439, After: 0.076953257...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>Before: 0.20546589125510897, After: 0.20547455...</td>\n",
       "      <td>Before: 0.18314156317766062, After: 0.18313975...</td>\n",
       "      <td>Before: 0.2393287663091698, After: 0.239342157...</td>\n",
       "      <td>Before: 0.9999999999999996, After: 1.0</td>\n",
       "      <td>Before: 0.28971014677665063, After: 0.28970944...</td>\n",
       "      <td>Before: 0.15750632650840493, After: 0.15750846...</td>\n",
       "      <td>Before: 0.13804955762057758, After: 0.13804958...</td>\n",
       "      <td>Before: 0.16678031434047627, After: 0.16678347...</td>\n",
       "      <td>Before: 0.27407501845767246, After: 0.27407454...</td>\n",
       "      <td>Before: 0.10639718565916091, After: 0.10639914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>Before: 0.16761576142114898, After: 0.39445950...</td>\n",
       "      <td>Before: 0.06730278214710199, After: 0.07307479...</td>\n",
       "      <td>Before: 0.06606645196552532, After: 0.40858220...</td>\n",
       "      <td>Before: 0.10055138151211143, After: 0.28970944...</td>\n",
       "      <td>Before: 0.38405259310022044, After: 1.00000000...</td>\n",
       "      <td>Before: 0.3219357387657039, After: 0.354037032...</td>\n",
       "      <td>Before: 0.15146728859985834, After: 0.21833826...</td>\n",
       "      <td>Before: 0.10589313234551631, After: 0.28236372...</td>\n",
       "      <td>Before: 0.1936940498815496, After: 0.328525840...</td>\n",
       "      <td>Before: 0.05697047025775614, After: 0.11862340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>Before: 0.15859645192729996, After: 0.26348610...</td>\n",
       "      <td>Before: -0.049076379792710186, After: 0.100330...</td>\n",
       "      <td>Before: 0.13968323112249992, After: 0.22732308...</td>\n",
       "      <td>Before: 0.14983822223318854, After: 0.15750846...</td>\n",
       "      <td>Before: 0.2597415410728325, After: 0.354037032...</td>\n",
       "      <td>Before: 0.6158574248530795, After: 1.000000000...</td>\n",
       "      <td>Before: 0.13778205919388814, After: 0.19190468...</td>\n",
       "      <td>Before: 0.0865221800713605, After: 0.160778501...</td>\n",
       "      <td>Before: 0.22133439390681858, After: 0.24947266...</td>\n",
       "      <td>Before: 0.059270287407368415, After: 0.0662935...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>Before: 0.25878907406446877, After: 0.34338708...</td>\n",
       "      <td>Before: 0.017639064485218965, After: 0.0890835...</td>\n",
       "      <td>Before: 0.0978054983995635, After: 0.209869514...</td>\n",
       "      <td>Before: 0.08500327165730943, After: 0.13804958...</td>\n",
       "      <td>Before: 0.13439994429915442, After: 0.21833826...</td>\n",
       "      <td>Before: 0.09431570687955, After: 0.19190468704...</td>\n",
       "      <td>Before: 0.6128107065755533, After: 1.0</td>\n",
       "      <td>Before: 0.27845097194129365, After: 0.34448646...</td>\n",
       "      <td>Before: 0.19325643013428553, After: 0.33078374...</td>\n",
       "      <td>Before: 0.0745189116843016, After: 0.175547118...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>Before: 0.18217682480604822, After: 0.54854860...</td>\n",
       "      <td>Before: 0.07222178145580241, After: 0.20259713...</td>\n",
       "      <td>Before: 0.11697573887301807, After: 0.12068024...</td>\n",
       "      <td>Before: 0.12199094008346709, After: 0.16678347...</td>\n",
       "      <td>Before: 0.12790409339777273, After: 0.28236372...</td>\n",
       "      <td>Before: 0.07363428182232754, After: 0.16077850...</td>\n",
       "      <td>Before: 0.4308149649767604, After: 0.344486463...</td>\n",
       "      <td>Before: 0.378466332225932, After: 1.0000000000...</td>\n",
       "      <td>Before: 0.1708752362535986, After: 0.544714533...</td>\n",
       "      <td>Before: 0.1264203000118017, After: 0.409129275...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>Before: 0.241072229246228, After: 0.5940531024...</td>\n",
       "      <td>Before: 0.10199943514005788, After: 0.19102605...</td>\n",
       "      <td>Before: 0.0730022470894344, After: 0.234808759...</td>\n",
       "      <td>Before: 0.15911448638969528, After: 0.27407454...</td>\n",
       "      <td>Before: 0.09505575751009387, After: 0.32852584...</td>\n",
       "      <td>Before: 0.11200247669649024, After: 0.24947266...</td>\n",
       "      <td>Before: 0.14771102908578468, After: 0.33078374...</td>\n",
       "      <td>Before: 0.3033847603340788, After: 0.544714533...</td>\n",
       "      <td>Before: 0.6110191309495465, After: 0.999999999...</td>\n",
       "      <td>Before: 0.30399420253175347, After: 0.36164712...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>Before: 0.225917972105598, After: 0.2598908452...</td>\n",
       "      <td>Before: 0.1655264826766013, After: 0.188078452...</td>\n",
       "      <td>Before: 0.036750539503579295, After: 0.0769532...</td>\n",
       "      <td>Before: 0.09429740737651135, After: 0.10639914...</td>\n",
       "      <td>Before: 0.10212970436490482, After: 0.11862340...</td>\n",
       "      <td>Before: 0.13403080874265905, After: 0.06629354...</td>\n",
       "      <td>Before: 0.1436405909297276, After: 0.175547118...</td>\n",
       "      <td>Before: 0.26868181343357167, After: 0.40912927...</td>\n",
       "      <td>Before: 0.3049306009871644, After: 0.361647126...</td>\n",
       "      <td>Before: 0.4896246955281065, After: 1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        cat  \\\n",
       "cat       Before: 0.29245239862991185, After: 1.00000000...   \n",
       "tiger     Before: 0.17347637872059773, After: 0.20200897...   \n",
       "computer  Before: 0.18984798734723213, After: 0.19719178...   \n",
       "keyboard  Before: 0.20546589125510897, After: 0.20547455...   \n",
       "plane     Before: 0.16761576142114898, After: 0.39445950...   \n",
       "car       Before: 0.15859645192729996, After: 0.26348610...   \n",
       "doctor    Before: 0.25878907406446877, After: 0.34338708...   \n",
       "nurse     Before: 0.18217682480604822, After: 0.54854860...   \n",
       "love      Before: 0.241072229246228, After: 0.5940531024...   \n",
       "sex       Before: 0.225917972105598, After: 0.2598908452...   \n",
       "\n",
       "                                                      tiger  \\\n",
       "cat       Before: 0.35037322527996934, After: 0.20200897...   \n",
       "tiger     Before: 0.48802072485209846, After: 1.00000000...   \n",
       "computer  Before: 0.05360514929979338, After: 0.09025702...   \n",
       "keyboard  Before: 0.18314156317766062, After: 0.18313975...   \n",
       "plane     Before: 0.06730278214710199, After: 0.07307479...   \n",
       "car       Before: -0.049076379792710186, After: 0.100330...   \n",
       "doctor    Before: 0.017639064485218965, After: 0.0890835...   \n",
       "nurse     Before: 0.07222178145580241, After: 0.20259713...   \n",
       "love      Before: 0.10199943514005788, After: 0.19102605...   \n",
       "sex       Before: 0.1655264826766013, After: 0.188078452...   \n",
       "\n",
       "                                                   computer  \\\n",
       "cat       Before: 0.06136659928459301, After: 0.19719178...   \n",
       "tiger     Before: 0.02942476361382193, After: 0.09025702...   \n",
       "computer             Before: 0.3047689400402037, After: 1.0   \n",
       "keyboard  Before: 0.2393287663091698, After: 0.239342157...   \n",
       "plane     Before: 0.06606645196552532, After: 0.40858220...   \n",
       "car       Before: 0.13968323112249992, After: 0.22732308...   \n",
       "doctor    Before: 0.0978054983995635, After: 0.209869514...   \n",
       "nurse     Before: 0.11697573887301807, After: 0.12068024...   \n",
       "love      Before: 0.0730022470894344, After: 0.234808759...   \n",
       "sex       Before: 0.036750539503579295, After: 0.0769532...   \n",
       "\n",
       "                                                   keyboard  \\\n",
       "cat       Before: 0.18344955625364173, After: 0.20547455...   \n",
       "tiger     Before: 0.06542581824273716, After: 0.18313975...   \n",
       "computer  Before: 0.39639163439495995, After: 0.23934215...   \n",
       "keyboard             Before: 0.9999999999999996, After: 1.0   \n",
       "plane     Before: 0.10055138151211143, After: 0.28970944...   \n",
       "car       Before: 0.14983822223318854, After: 0.15750846...   \n",
       "doctor    Before: 0.08500327165730943, After: 0.13804958...   \n",
       "nurse     Before: 0.12199094008346709, After: 0.16678347...   \n",
       "love      Before: 0.15911448638969528, After: 0.27407454...   \n",
       "sex       Before: 0.09429740737651135, After: 0.10639914...   \n",
       "\n",
       "                                                      plane  \\\n",
       "cat       Before: 0.21134097025538556, After: 0.39445950...   \n",
       "tiger     Before: 0.15090617196611955, After: 0.07307479...   \n",
       "computer  Before: 0.28314903703275535, After: 0.40858220...   \n",
       "keyboard  Before: 0.28971014677665063, After: 0.28970944...   \n",
       "plane     Before: 0.38405259310022044, After: 1.00000000...   \n",
       "car       Before: 0.2597415410728325, After: 0.354037032...   \n",
       "doctor    Before: 0.13439994429915442, After: 0.21833826...   \n",
       "nurse     Before: 0.12790409339777273, After: 0.28236372...   \n",
       "love      Before: 0.09505575751009387, After: 0.32852584...   \n",
       "sex       Before: 0.10212970436490482, After: 0.11862340...   \n",
       "\n",
       "                                                        car  \\\n",
       "cat       Before: 0.136072027917602, After: 0.2634861035...   \n",
       "tiger     Before: 0.16119598769364896, After: 0.10033040...   \n",
       "computer  Before: 0.26826894486108244, After: 0.22732308...   \n",
       "keyboard  Before: 0.15750632650840493, After: 0.15750846...   \n",
       "plane     Before: 0.3219357387657039, After: 0.354037032...   \n",
       "car       Before: 0.6158574248530795, After: 1.000000000...   \n",
       "doctor    Before: 0.09431570687955, After: 0.19190468704...   \n",
       "nurse     Before: 0.07363428182232754, After: 0.16077850...   \n",
       "love      Before: 0.11200247669649024, After: 0.24947266...   \n",
       "sex       Before: 0.13403080874265905, After: 0.06629354...   \n",
       "\n",
       "                                                     doctor  \\\n",
       "cat       Before: 0.16547475026405636, After: 0.34338708...   \n",
       "tiger     Before: 0.0774108002811773, After: 0.089083542...   \n",
       "computer  Before: 0.18039329196329013, After: 0.20986951...   \n",
       "keyboard  Before: 0.13804955762057758, After: 0.13804958...   \n",
       "plane     Before: 0.15146728859985834, After: 0.21833826...   \n",
       "car       Before: 0.13778205919388814, After: 0.19190468...   \n",
       "doctor               Before: 0.6128107065755533, After: 1.0   \n",
       "nurse     Before: 0.4308149649767604, After: 0.344486463...   \n",
       "love      Before: 0.14771102908578468, After: 0.33078374...   \n",
       "sex       Before: 0.1436405909297276, After: 0.175547118...   \n",
       "\n",
       "                                                      nurse  \\\n",
       "cat       Before: 0.24690899138830727, After: 0.54854860...   \n",
       "tiger     Before: 0.1697249630498177, After: 0.202597136...   \n",
       "computer  Before: 0.09297679298707379, After: 0.12068024...   \n",
       "keyboard  Before: 0.16678031434047627, After: 0.16678347...   \n",
       "plane     Before: 0.10589313234551631, After: 0.28236372...   \n",
       "car       Before: 0.0865221800713605, After: 0.160778501...   \n",
       "doctor    Before: 0.27845097194129365, After: 0.34448646...   \n",
       "nurse     Before: 0.378466332225932, After: 1.0000000000...   \n",
       "love      Before: 0.3033847603340788, After: 0.544714533...   \n",
       "sex       Before: 0.26868181343357167, After: 0.40912927...   \n",
       "\n",
       "                                                       love  \\\n",
       "cat       Before: 0.2989067535773432, After: 0.594053102...   \n",
       "tiger     Before: 0.17516455047450735, After: 0.19102605...   \n",
       "computer  Before: 0.1168711356729625, After: 0.234808759...   \n",
       "keyboard  Before: 0.27407501845767246, After: 0.27407454...   \n",
       "plane     Before: 0.1936940498815496, After: 0.328525840...   \n",
       "car       Before: 0.22133439390681858, After: 0.24947266...   \n",
       "doctor    Before: 0.19325643013428553, After: 0.33078374...   \n",
       "nurse     Before: 0.1708752362535986, After: 0.544714533...   \n",
       "love      Before: 0.6110191309495465, After: 0.999999999...   \n",
       "sex       Before: 0.3049306009871644, After: 0.361647126...   \n",
       "\n",
       "                                                        sex  \n",
       "cat       Before: 0.1093022564011111, After: 0.259890845...  \n",
       "tiger     Before: 0.14518818082220147, After: 0.18807845...  \n",
       "computer  Before: 0.1158779845883439, After: 0.076953257...  \n",
       "keyboard  Before: 0.10639718565916091, After: 0.10639914...  \n",
       "plane     Before: 0.05697047025775614, After: 0.11862340...  \n",
       "car       Before: 0.059270287407368415, After: 0.0662935...  \n",
       "doctor    Before: 0.0745189116843016, After: 0.175547118...  \n",
       "nurse     Before: 0.1264203000118017, After: 0.409129275...  \n",
       "love      Before: 0.30399420253175347, After: 0.36164712...  \n",
       "sex                  Before: 0.4896246955281065, After: 1.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score before retrofitting\n",
    "        similarity_before = cosine_sim[word1_index, word2_index]\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Before: {similarity_before}, After: {similarity_after}\"\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>tiger</th>\n",
       "      <th>computer</th>\n",
       "      <th>keyboard</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>doctor</th>\n",
       "      <th>nurse</th>\n",
       "      <th>love</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>Retrofitting: 0.20, Human: 0.73</td>\n",
       "      <td>Retrofitting: 1.00, Human: 1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.24, Human: 0.76</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyboard</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plane</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.35, Human: 0.58</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>car</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doctor</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.34, Human: 0.70</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nurse</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Retrofitting: 0.36, Human: 0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cat                            tiger  \\\n",
       "cat                                  None                             None   \n",
       "tiger     Retrofitting: 0.20, Human: 0.73  Retrofitting: 1.00, Human: 1.00   \n",
       "computer                             None                             None   \n",
       "keyboard                             None                             None   \n",
       "plane                                None                             None   \n",
       "car                                  None                             None   \n",
       "doctor                               None                             None   \n",
       "nurse                                None                             None   \n",
       "love                                 None                             None   \n",
       "sex                                  None                             None   \n",
       "\n",
       "         computer                         keyboard plane  \\\n",
       "cat          None                             None  None   \n",
       "tiger        None                             None  None   \n",
       "computer     None  Retrofitting: 0.24, Human: 0.76  None   \n",
       "keyboard     None                             None  None   \n",
       "plane        None                             None  None   \n",
       "car          None                             None  None   \n",
       "doctor       None                             None  None   \n",
       "nurse        None                             None  None   \n",
       "love         None                             None  None   \n",
       "sex          None                             None  None   \n",
       "\n",
       "                                      car doctor  \\\n",
       "cat                                  None   None   \n",
       "tiger                                None   None   \n",
       "computer                             None   None   \n",
       "keyboard                             None   None   \n",
       "plane     Retrofitting: 0.35, Human: 0.58   None   \n",
       "car                                  None   None   \n",
       "doctor                               None   None   \n",
       "nurse                                None   None   \n",
       "love                                 None   None   \n",
       "sex                                  None   None   \n",
       "\n",
       "                                    nurse  love  \\\n",
       "cat                                  None  None   \n",
       "tiger                                None  None   \n",
       "computer                             None  None   \n",
       "keyboard                             None  None   \n",
       "plane                                None  None   \n",
       "car                                  None  None   \n",
       "doctor    Retrofitting: 0.34, Human: 0.70  None   \n",
       "nurse                                None  None   \n",
       "love                                 None  None   \n",
       "sex                                  None  None   \n",
       "\n",
       "                                      sex  \n",
       "cat                                  None  \n",
       "tiger                                None  \n",
       "computer                             None  \n",
       "keyboard                             None  \n",
       "plane                                None  \n",
       "car                                  None  \n",
       "doctor                               None  \n",
       "nurse                                None  \n",
       "love      Retrofitting: 0.36, Human: 0.68  \n",
       "sex                                  None  "
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the evaluation scores from the file\n",
    "eval_scores = {}\n",
    "with open(eval_file_path, 'r') as eval_file:\n",
    "    for line in eval_file:\n",
    "        word1, word2, score = line.strip().split('\\t')\n",
    "        eval_scores[(word1, word2)] = float(score)\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(index=wordList, columns=wordList)\n",
    "\n",
    "# Loop over each word pair and calculate similarity scores\n",
    "for word1 in wordList:\n",
    "    for word2 in wordList:\n",
    "        word1_index = wordList.index(word1)\n",
    "        word2_index = wordList.index(word2)\n",
    "        \n",
    "        # Calculate similarity score after retrofitting\n",
    "        retrofit_toy_vec, _ = retrofitting_wordVecs(wordVecMat, neighbors_matrix, alpha, beta, nb_iter)\n",
    "        word1_vec = retrofit_toy_vec[word1_index].reshape(1, -1)\n",
    "        word2_vec = retrofit_toy_vec[word2_index].reshape(1, -1)\n",
    "        similarity_after = cosine_similarity(word1_vec, word2_vec)[0, 0]\n",
    "        \n",
    "        # Retrieve the evaluation score for the word pair\n",
    "        score = eval_scores.get((word1, word2))\n",
    "\n",
    "        # Scale the human score between 0 and 1\n",
    "        if score is not None:\n",
    "            scaled_score = score / 10.0\n",
    "        else:\n",
    "            scaled_score = None\n",
    "        \n",
    "        # Store the scores in the DataFrame\n",
    "        results_df.loc[word1, word2] = f\"Retrofitting: {similarity_after:.2f}, Human: {scaled_score:.2f}\" if scaled_score is not None else None\n",
    "\n",
    "# Print the results DataFrame\n",
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n"
     ]
    }
   ],
   "source": [
    "wordVecs_gensim = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "lexical_similarity = read_lexicon(\"../data/English/lexicon/ws353_lexical_similarity.txt\")\n",
    "output_file = \"../data/English/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_neighbors_embedding_matrix0(wordVecs, wordList, relation_type):\n",
    "    # Retrieve synonyms for each word\n",
    "    neighbors_dict = get_wordnet_lexicon(wordList, relation_type)\n",
    "\n",
    "    # Create a set of valid neighbors\n",
    "    valid_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors) & set(wordList)\n",
    "    \n",
    "    # Get the embedding size\n",
    "    embedding_size = 250 #wordVecs[next(iter(wordVecs))].shape[0]\n",
    "    \n",
    "    # Compute average embedding\n",
    "    average_embeddings = []\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        if neighbors and any(neighbor in valid_neighbors for neighbor in neighbors):\n",
    "            embeddings = np.array([\n",
    "                wordVecs[wordList.index(neighbor)]\n",
    "                for neighbor in neighbors\n",
    "                if neighbor in valid_neighbors\n",
    "            ])\n",
    "            average_embedding = np.mean(embeddings, axis=0)\n",
    "            average_embeddings.append(average_embedding)\n",
    "    \n",
    "    # Create the word embedding matrix\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "\n",
    "    return neighbors_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_dict = get_wordnet_lexicon(wordList, \"synononys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_neighbors_embedding_matrix(wordVecMat, wordList, neighbors_dict):\n",
    "    valid_neighbors = set(neighbor for neighbors in neighbors_dict.values() for neighbor in neighbors) & set(wordList)\n",
    "\n",
    "    embedding_size = wordVecMat.shape[1]\n",
    "    average_embeddings = []\n",
    "\n",
    "    for word in wordList:\n",
    "        neighbors = neighbors_dict.get(word, [])\n",
    "        if neighbors and any(neighbor in valid_neighbors for neighbor in neighbors):\n",
    "            embeddings = np.array([\n",
    "                wordVecMat[wordList.index(neighbor)] if neighbor in wordList else np.zeros(embedding_size)\n",
    "                for neighbor in neighbors\n",
    "                if neighbor in valid_neighbors\n",
    "            ])\n",
    "            if embeddings.size > 0:\n",
    "                average_embedding = np.mean(embeddings, axis=0)\n",
    "                average_embeddings.append(average_embedding)\n",
    "        else:\n",
    "            average_embeddings.append(np.zeros(embedding_size))\n",
    "\n",
    "    neighbors_embedding_matrix = np.vstack(average_embeddings)\n",
    "    return neighbors_embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList_gensim = get_embeddings_words(wordVecs_gensim)\n",
    "wordVecMat_gensim = convert_dict_to_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07520224 0.07037208 0.0224631  ... 0.03620975 0.02141031 0.15191107]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Create a small subset of wordVecs dictionary\n",
    "subset_wordVecs = {word: wordVecs_gensim[word] for word in wordList_gensim[:100]}\n",
    "subset_wordVecMat = wordVecMat_gensim[:100] \n",
    "\n",
    "# Create a small subset of wordList\n",
    "subset_wordList = wordList_gensim[:100]\n",
    "\n",
    "# Test the function on the subset\n",
    "neighbors_matrix = retrieve_neighbors_embedding_matrix(subset_wordVecMat, subset_wordList, \"synonyms\")\n",
    "\n",
    "# Print the result\n",
    "print(neighbors_matrix)\n",
    "print(type(neighbors_matrix))  \n",
    "print(neighbors_matrix.shape)  \n",
    "print(neighbors_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_matrix_gensim = retrieve_neighbors_embedding_matrix(wordVecMat_gensim, wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(neighbors_matrix_gensim))  \n",
    "print(neighbors_matrix_gensim.shape)  \n",
    "print(neighbors_matrix_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(125776, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat_gensim))  \n",
    "print(wordVecMat_gensim.shape) \n",
    "print(wordVecMat_gensim.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10, 300)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(type(wordVecMat))  \n",
    "print(wordVecMat.shape) \n",
    "print(wordVecMat.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_gensim = get_wordnet_lexicon(wordList_gensim, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)\n",
    "# retrofitted_similarity_matrix_gensim = generate_cosine_similarity_matrix(wordVecs_gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrofitting_wordVecs_test(wordVecMat, neighbors_embedding_matrix, alpha=1, beta=1, nb_iter=10):\n",
    "    newWordVecMat = np.copy(wordVecMat)\n",
    "    for _ in range(nb_iter):\n",
    "        updates = alpha * neighbors_embedding_matrix + beta * newWordVecMat\n",
    "        newWordVecMat = updates / (alpha + beta)\n",
    "\n",
    "    return newWordVecMat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "(50, 250)\n",
      "2\n",
      "\n",
      "Similarities with \",\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"the\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \".\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"of\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"-\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"and\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"in\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"to\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"'\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"a\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \")\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"(\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"is\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3347\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.3513\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 1.0000\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.5131\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3345\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.5131\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"s\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"for\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"was\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3347\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.3513\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 1.0000\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.5131\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3345\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.5131\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"on\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"that\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"as\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 0.3347\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 0.3347\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 1.0000\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.5032\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 0.3347\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.3516\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 0.3347\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.2837\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.3516\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"it\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"with\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"by\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"\"\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"at\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"he\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"from\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"be\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"this\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"i\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 0.3513\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 0.3513\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.5032\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 1.0000\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 0.3513\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.4003\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 0.3513\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3112\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.4003\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"an\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"his\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"are\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3347\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.3513\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 1.0000\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.5131\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3345\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.5131\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"not\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"has\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 0.5131\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 0.5131\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3516\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.4003\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 0.5131\n",
      "  - \"not\": nan\n",
      "  - \"has\": 1.0000\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 0.5131\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3972\n",
      "  - \"who\": nan\n",
      "  - \"had\": 1.0000\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"have\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"but\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"or\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"utc\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"which\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"were\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3347\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.3513\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 1.0000\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.5131\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3345\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.5131\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"–\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"said\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"they\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"also\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"one\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 0.3345\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 0.3345\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.2837\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.3112\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 0.3345\n",
      "  - \"not\": nan\n",
      "  - \"has\": 0.3972\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 0.3345\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 1.0000\n",
      "  - \"who\": nan\n",
      "  - \"had\": 0.3972\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"who\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"had\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": 0.5131\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": 0.5131\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": 0.3516\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": 0.4003\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": 0.5131\n",
      "  - \"not\": nan\n",
      "  - \"has\": 1.0000\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": 0.5131\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": 0.3972\n",
      "  - \"who\": nan\n",
      "  - \"had\": 1.0000\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"talk\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"new\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n",
      "Similarities with \"their\":\n",
      "  - \",\": nan\n",
      "  - \"the\": nan\n",
      "  - \".\": nan\n",
      "  - \"of\": nan\n",
      "  - \"-\": nan\n",
      "  - \"and\": nan\n",
      "  - \"in\": nan\n",
      "  - \"to\": nan\n",
      "  - \"'\": nan\n",
      "  - \"a\": nan\n",
      "  - \")\": nan\n",
      "  - \"(\": nan\n",
      "  - \"is\": nan\n",
      "  - \"s\": nan\n",
      "  - \"for\": nan\n",
      "  - \"was\": nan\n",
      "  - \"on\": nan\n",
      "  - \"that\": nan\n",
      "  - \"as\": nan\n",
      "  - \"it\": nan\n",
      "  - \"with\": nan\n",
      "  - \"by\": nan\n",
      "  - \"\"\": nan\n",
      "  - \"at\": nan\n",
      "  - \"he\": nan\n",
      "  - \"from\": nan\n",
      "  - \"be\": nan\n",
      "  - \"this\": nan\n",
      "  - \"i\": nan\n",
      "  - \"an\": nan\n",
      "  - \"his\": nan\n",
      "  - \"are\": nan\n",
      "  - \"not\": nan\n",
      "  - \"has\": nan\n",
      "  - \"have\": nan\n",
      "  - \"but\": nan\n",
      "  - \"or\": nan\n",
      "  - \"utc\": nan\n",
      "  - \"which\": nan\n",
      "  - \"were\": nan\n",
      "  - \"–\": nan\n",
      "  - \"said\": nan\n",
      "  - \"they\": nan\n",
      "  - \"also\": nan\n",
      "  - \"one\": nan\n",
      "  - \"who\": nan\n",
      "  - \"had\": nan\n",
      "  - \"talk\": nan\n",
      "  - \"new\": nan\n",
      "  - \"their\": nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ninan\\AppData\\Local\\Temp\\ipykernel_14036\\4190515266.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  similarity = dot_product / norm_product\n"
     ]
    }
   ],
   "source": [
    "test_subset_wordVecs = {word: wordVecs_gensim[word] for word in wordList_gensim[:50]}\n",
    "test_subset_wordVecMat = wordVecMat_gensim[:50] \n",
    "\n",
    "test_subset_wordList = wordList_gensim[:50]\n",
    "\n",
    "test_subset_neighbors_matrix= retrieve_neighbors_embedding_matrix(test_subset_wordVecMat, test_subset_wordList, \"synonyms\")\n",
    "\n",
    "print(test_subset_neighbors_matrix)\n",
    "print(type(test_subset_neighbors_matrix))  \n",
    "print(test_subset_neighbors_matrix.shape)  \n",
    "print(test_subset_neighbors_matrix.ndim) \n",
    "\n",
    "print('')\n",
    "test_before_retrofitted_gensim_dict = convert_matrix_to_dict(test_subset_neighbors_matrix, subset_wordList)\n",
    "test_before_retrofitted_gensim_similarity_matrix = generate_cosine_similarity_matrix(test_before_retrofitted_gensim_dict)\n",
    "print_vec_similarities(test_subset_wordList, test_before_retrofitted_gensim_similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_wordVecs_gensim = retrofitting_wordVecs_test(wordVecMat_gensim, neighbors_matrix_gensim, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_cosine_similarity(X, Y, sample_size=10000):\n",
    "    np.random.seed(42)  # Set a random seed for reproducibility\n",
    "    sample_X = X[np.random.choice(X.shape[0], sample_size, replace=False)]\n",
    "    sample_Y = Y[np.random.choice(Y.shape[0], sample_size, replace=False)]\n",
    "    similarities = cosine_similarity(sample_X, sample_Y)\n",
    "    avg_cos_similarity = np.mean(similarities)\n",
    "    return avg_cos_similarity\n",
    "\n",
    "# Compute the average cosine similarity using a random sample\n",
    "avg_cos_similarity = calculate_average_cosine_similarity(wordVecMat_gensim, retrofitted_wordVecs_gensim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15219916974877842"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cos_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "<class 'numpy.ndarray'>\n",
      "(50, 250)\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "subset_retrofitted_wordVecs = {word: wordVecs_gensim[word] for word in wordList_gensim[:50]}\n",
    "subset_retrofitted_wordVecMat = retrofitted_wordVecs_gensim[:50] \n",
    "\n",
    "subset_retrofitted_wordList = wordList_gensim[:50]\n",
    "\n",
    "neighbors_matrix = retrieve_neighbors_embedding_matrix(subset_retrofitted_wordVecMat, subset_retrofitted_wordList, \"synonyms\")\n",
    "\n",
    "print(neighbors_matrix)\n",
    "print(type(neighbors_matrix))  \n",
    "print(neighbors_matrix.shape)  \n",
    "print(neighbors_matrix.ndim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarities with \",\":\n",
      "  - \",\": 1.0000\n",
      "  - \"the\": 0.5246\n",
      "  - \".\": 0.8301\n",
      "  - \"of\": 0.5214\n",
      "  - \"-\": 0.7543\n",
      "  - \"and\": 0.6395\n",
      "  - \"in\": 0.2513\n",
      "  - \"to\": 0.4614\n",
      "  - \"'\": 0.5109\n",
      "  - \"a\": 0.2590\n",
      "  - \")\": 0.6108\n",
      "  - \"(\": 0.5921\n",
      "  - \"is\": 0.3816\n",
      "  - \"s\": 0.4876\n",
      "  - \"for\": 0.4648\n",
      "  - \"was\": 0.3816\n",
      "  - \"on\": 0.4349\n",
      "  - \"that\": 0.4100\n",
      "  - \"as\": 0.4145\n",
      "  - \"it\": 0.4465\n",
      "  - \"with\": 0.4828\n",
      "  - \"by\": 0.3419\n",
      "  - \"\"\": 0.3507\n",
      "  - \"at\": 0.1697\n",
      "  - \"he\": 0.1751\n",
      "  - \"from\": 0.4830\n",
      "  - \"be\": 0.4334\n",
      "  - \"this\": 0.3865\n",
      "  - \"i\": 0.5108\n",
      "  - \"an\": 0.4290\n",
      "  - \"his\": 0.4085\n",
      "  - \"are\": 0.3950\n",
      "  - \"not\": 0.3820\n",
      "  - \"has\": 0.4384\n",
      "  - \"have\": 0.4196\n",
      "  - \"but\": 0.3880\n",
      "  - \"or\": 0.2505\n",
      "  - \"utc\": 0.3256\n",
      "  - \"which\": 0.3898\n",
      "  - \"were\": 0.3814\n",
      "  - \"–\": 0.4485\n",
      "  - \"said\": 0.3963\n",
      "  - \"they\": 0.3911\n",
      "  - \"also\": 0.4595\n",
      "  - \"one\": 0.3827\n",
      "  - \"who\": 0.3217\n",
      "  - \"had\": 0.4383\n",
      "  - \"talk\": 0.5002\n",
      "  - \"new\": 0.4197\n",
      "  - \"their\": 0.3509\n",
      "\n",
      "Similarities with \"the\":\n",
      "  - \",\": 0.5246\n",
      "  - \"the\": 1.0000\n",
      "  - \".\": 0.5650\n",
      "  - \"of\": 0.6847\n",
      "  - \"-\": 0.4697\n",
      "  - \"and\": 0.6368\n",
      "  - \"in\": 0.2247\n",
      "  - \"to\": 0.5324\n",
      "  - \"'\": 0.4664\n",
      "  - \"a\": 0.1968\n",
      "  - \")\": 0.3871\n",
      "  - \"(\": 0.3989\n",
      "  - \"is\": 0.4825\n",
      "  - \"s\": 0.4564\n",
      "  - \"for\": 0.4985\n",
      "  - \"was\": 0.4825\n",
      "  - \"on\": 0.4726\n",
      "  - \"that\": 0.5602\n",
      "  - \"as\": 0.3967\n",
      "  - \"it\": 0.5828\n",
      "  - \"with\": 0.5103\n",
      "  - \"by\": 0.4023\n",
      "  - \"\"\": 0.3547\n",
      "  - \"at\": 0.1728\n",
      "  - \"he\": 0.1546\n",
      "  - \"from\": 0.4914\n",
      "  - \"be\": 0.4736\n",
      "  - \"this\": 0.5624\n",
      "  - \"i\": 0.5961\n",
      "  - \"an\": 0.5235\n",
      "  - \"his\": 0.4642\n",
      "  - \"are\": 0.4913\n",
      "  - \"not\": 0.3055\n",
      "  - \"has\": 0.5026\n",
      "  - \"have\": 0.4697\n",
      "  - \"but\": 0.4674\n",
      "  - \"or\": 0.2330\n",
      "  - \"utc\": 0.2050\n",
      "  - \"which\": 0.6465\n",
      "  - \"were\": 0.4823\n",
      "  - \"–\": 0.3194\n",
      "  - \"said\": 0.3737\n",
      "  - \"they\": 0.4527\n",
      "  - \"also\": 0.5038\n",
      "  - \"one\": 0.3915\n",
      "  - \"who\": 0.3617\n",
      "  - \"had\": 0.5026\n",
      "  - \"talk\": 0.4029\n",
      "  - \"new\": 0.4347\n",
      "  - \"their\": 0.5333\n",
      "\n",
      "Similarities with \".\":\n",
      "  - \",\": 0.8301\n",
      "  - \"the\": 0.5650\n",
      "  - \".\": 1.0000\n",
      "  - \"of\": 0.5061\n",
      "  - \"-\": 0.7595\n",
      "  - \"and\": 0.5901\n",
      "  - \"in\": 0.2450\n",
      "  - \"to\": 0.4963\n",
      "  - \"'\": 0.5376\n",
      "  - \"a\": 0.2986\n",
      "  - \")\": 0.5742\n",
      "  - \"(\": 0.5698\n",
      "  - \"is\": 0.4528\n",
      "  - \"s\": 0.4917\n",
      "  - \"for\": 0.4884\n",
      "  - \"was\": 0.4528\n",
      "  - \"on\": 0.4031\n",
      "  - \"that\": 0.4804\n",
      "  - \"as\": 0.4505\n",
      "  - \"it\": 0.4876\n",
      "  - \"with\": 0.4638\n",
      "  - \"by\": 0.4057\n",
      "  - \"\"\": 0.3175\n",
      "  - \"at\": 0.1964\n",
      "  - \"he\": 0.2055\n",
      "  - \"from\": 0.4680\n",
      "  - \"be\": 0.4283\n",
      "  - \"this\": 0.4908\n",
      "  - \"i\": 0.5432\n",
      "  - \"an\": 0.4060\n",
      "  - \"his\": 0.3845\n",
      "  - \"are\": 0.4708\n",
      "  - \"not\": 0.3738\n",
      "  - \"has\": 0.4949\n",
      "  - \"have\": 0.4588\n",
      "  - \"but\": 0.4326\n",
      "  - \"or\": 0.2369\n",
      "  - \"utc\": 0.3789\n",
      "  - \"which\": 0.4946\n",
      "  - \"were\": 0.4527\n",
      "  - \"–\": 0.4081\n",
      "  - \"said\": 0.4198\n",
      "  - \"they\": 0.3677\n",
      "  - \"also\": 0.5254\n",
      "  - \"one\": 0.4000\n",
      "  - \"who\": 0.3527\n",
      "  - \"had\": 0.4948\n",
      "  - \"talk\": 0.4511\n",
      "  - \"new\": 0.4260\n",
      "  - \"their\": 0.3642\n",
      "\n",
      "Similarities with \"of\":\n",
      "  - \",\": 0.5214\n",
      "  - \"the\": 0.6847\n",
      "  - \".\": 0.5061\n",
      "  - \"of\": 1.0000\n",
      "  - \"-\": 0.4564\n",
      "  - \"and\": 0.6066\n",
      "  - \"in\": 0.1767\n",
      "  - \"to\": 0.4347\n",
      "  - \"'\": 0.4375\n",
      "  - \"a\": 0.1793\n",
      "  - \")\": 0.4465\n",
      "  - \"(\": 0.4424\n",
      "  - \"is\": 0.3636\n",
      "  - \"s\": 0.4005\n",
      "  - \"for\": 0.4764\n",
      "  - \"was\": 0.3635\n",
      "  - \"on\": 0.4311\n",
      "  - \"that\": 0.4399\n",
      "  - \"as\": 0.3332\n",
      "  - \"it\": 0.4193\n",
      "  - \"with\": 0.4502\n",
      "  - \"by\": 0.3738\n",
      "  - \"\"\": 0.3230\n",
      "  - \"at\": 0.1856\n",
      "  - \"he\": 0.1062\n",
      "  - \"from\": 0.5273\n",
      "  - \"be\": 0.4473\n",
      "  - \"this\": 0.3750\n",
      "  - \"i\": 0.4690\n",
      "  - \"an\": 0.4119\n",
      "  - \"his\": 0.3677\n",
      "  - \"are\": 0.3708\n",
      "  - \"not\": 0.3028\n",
      "  - \"has\": 0.4317\n",
      "  - \"have\": 0.4164\n",
      "  - \"but\": 0.4082\n",
      "  - \"or\": 0.2291\n",
      "  - \"utc\": 0.1789\n",
      "  - \"which\": 0.5006\n",
      "  - \"were\": 0.3634\n",
      "  - \"–\": 0.3121\n",
      "  - \"said\": 0.3320\n",
      "  - \"they\": 0.3076\n",
      "  - \"also\": 0.4768\n",
      "  - \"one\": 0.3212\n",
      "  - \"who\": 0.3380\n",
      "  - \"had\": 0.4316\n",
      "  - \"talk\": 0.3811\n",
      "  - \"new\": 0.3665\n",
      "  - \"their\": 0.3765\n",
      "\n",
      "Similarities with \"-\":\n",
      "  - \",\": 0.7543\n",
      "  - \"the\": 0.4697\n",
      "  - \".\": 0.7595\n",
      "  - \"of\": 0.4564\n",
      "  - \"-\": 1.0000\n",
      "  - \"and\": 0.5056\n",
      "  - \"in\": 0.2497\n",
      "  - \"to\": 0.4707\n",
      "  - \"'\": 0.4843\n",
      "  - \"a\": 0.2863\n",
      "  - \")\": 0.5834\n",
      "  - \"(\": 0.5638\n",
      "  - \"is\": 0.3125\n",
      "  - \"s\": 0.4667\n",
      "  - \"for\": 0.4293\n",
      "  - \"was\": 0.3125\n",
      "  - \"on\": 0.3676\n",
      "  - \"that\": 0.3770\n",
      "  - \"as\": 0.4102\n",
      "  - \"it\": 0.3762\n",
      "  - \"with\": 0.4224\n",
      "  - \"by\": 0.3120\n",
      "  - \"\"\": 0.2872\n",
      "  - \"at\": 0.1619\n",
      "  - \"he\": 0.1734\n",
      "  - \"from\": 0.4166\n",
      "  - \"be\": 0.3526\n",
      "  - \"this\": 0.4014\n",
      "  - \"i\": 0.4900\n",
      "  - \"an\": 0.3810\n",
      "  - \"his\": 0.3274\n",
      "  - \"are\": 0.3327\n",
      "  - \"not\": 0.3788\n",
      "  - \"has\": 0.3885\n",
      "  - \"have\": 0.3748\n",
      "  - \"but\": 0.3707\n",
      "  - \"or\": 0.1981\n",
      "  - \"utc\": 0.3464\n",
      "  - \"which\": 0.3681\n",
      "  - \"were\": 0.3123\n",
      "  - \"–\": 0.4731\n",
      "  - \"said\": 0.3787\n",
      "  - \"they\": 0.3213\n",
      "  - \"also\": 0.4504\n",
      "  - \"one\": 0.3203\n",
      "  - \"who\": 0.2722\n",
      "  - \"had\": 0.3884\n",
      "  - \"talk\": 0.3888\n",
      "  - \"new\": 0.3479\n",
      "  - \"their\": 0.2973\n",
      "\n",
      "Similarities with \"and\":\n",
      "  - \",\": 0.6395\n",
      "  - \"the\": 0.6368\n",
      "  - \".\": 0.5901\n",
      "  - \"of\": 0.6066\n",
      "  - \"-\": 0.5056\n",
      "  - \"and\": 1.0000\n",
      "  - \"in\": 0.2148\n",
      "  - \"to\": 0.5599\n",
      "  - \"'\": 0.4414\n",
      "  - \"a\": 0.2084\n",
      "  - \")\": 0.3939\n",
      "  - \"(\": 0.4213\n",
      "  - \"is\": 0.4118\n",
      "  - \"s\": 0.4124\n",
      "  - \"for\": 0.5425\n",
      "  - \"was\": 0.4118\n",
      "  - \"on\": 0.5675\n",
      "  - \"that\": 0.5361\n",
      "  - \"as\": 0.4095\n",
      "  - \"it\": 0.4787\n",
      "  - \"with\": 0.6079\n",
      "  - \"by\": 0.4140\n",
      "  - \"\"\": 0.3856\n",
      "  - \"at\": 0.1263\n",
      "  - \"he\": 0.0985\n",
      "  - \"from\": 0.5066\n",
      "  - \"be\": 0.4394\n",
      "  - \"this\": 0.3748\n",
      "  - \"i\": 0.5249\n",
      "  - \"an\": 0.4609\n",
      "  - \"his\": 0.4821\n",
      "  - \"are\": 0.4188\n",
      "  - \"not\": 0.3481\n",
      "  - \"has\": 0.5328\n",
      "  - \"have\": 0.4990\n",
      "  - \"but\": 0.4163\n",
      "  - \"or\": 0.2170\n",
      "  - \"utc\": 0.2434\n",
      "  - \"which\": 0.6658\n",
      "  - \"were\": 0.4117\n",
      "  - \"–\": 0.4187\n",
      "  - \"said\": 0.3915\n",
      "  - \"they\": 0.4807\n",
      "  - \"also\": 0.5930\n",
      "  - \"one\": 0.4087\n",
      "  - \"who\": 0.4885\n",
      "  - \"had\": 0.5328\n",
      "  - \"talk\": 0.4190\n",
      "  - \"new\": 0.4898\n",
      "  - \"their\": 0.5092\n",
      "\n",
      "Similarities with \"in\":\n",
      "  - \",\": 0.2513\n",
      "  - \"the\": 0.2247\n",
      "  - \".\": 0.2450\n",
      "  - \"of\": 0.1767\n",
      "  - \"-\": 0.2497\n",
      "  - \"and\": 0.2148\n",
      "  - \"in\": 1.0000\n",
      "  - \"to\": 0.2051\n",
      "  - \"'\": 0.1099\n",
      "  - \"a\": 0.5135\n",
      "  - \")\": 0.1274\n",
      "  - \"(\": 0.1176\n",
      "  - \"is\": 0.2766\n",
      "  - \"s\": 0.5407\n",
      "  - \"for\": 0.1466\n",
      "  - \"was\": 0.2766\n",
      "  - \"on\": 0.3302\n",
      "  - \"that\": 0.2019\n",
      "  - \"as\": 0.5438\n",
      "  - \"it\": 0.1933\n",
      "  - \"with\": 0.2540\n",
      "  - \"by\": 0.2892\n",
      "  - \"\"\": 0.2068\n",
      "  - \"at\": 0.3655\n",
      "  - \"he\": 0.4988\n",
      "  - \"from\": 0.1856\n",
      "  - \"be\": 0.4193\n",
      "  - \"this\": 0.1592\n",
      "  - \"i\": 0.4278\n",
      "  - \"an\": 0.1556\n",
      "  - \"his\": 0.1190\n",
      "  - \"are\": 0.2883\n",
      "  - \"not\": 0.1372\n",
      "  - \"has\": 0.3017\n",
      "  - \"have\": 0.3185\n",
      "  - \"but\": 0.2775\n",
      "  - \"or\": 0.1555\n",
      "  - \"utc\": 0.1033\n",
      "  - \"which\": 0.3084\n",
      "  - \"were\": 0.2766\n",
      "  - \"–\": 0.1124\n",
      "  - \"said\": 0.2414\n",
      "  - \"they\": 0.1494\n",
      "  - \"also\": 0.2825\n",
      "  - \"one\": 0.3917\n",
      "  - \"who\": 0.0832\n",
      "  - \"had\": 0.3017\n",
      "  - \"talk\": 0.2621\n",
      "  - \"new\": 0.3667\n",
      "  - \"their\": 0.1554\n",
      "\n",
      "Similarities with \"to\":\n",
      "  - \",\": 0.4614\n",
      "  - \"the\": 0.5324\n",
      "  - \".\": 0.4963\n",
      "  - \"of\": 0.4347\n",
      "  - \"-\": 0.4707\n",
      "  - \"and\": 0.5599\n",
      "  - \"in\": 0.2051\n",
      "  - \"to\": 1.0000\n",
      "  - \"'\": 0.3801\n",
      "  - \"a\": 0.1733\n",
      "  - \")\": 0.3440\n",
      "  - \"(\": 0.3160\n",
      "  - \"is\": 0.4222\n",
      "  - \"s\": 0.3403\n",
      "  - \"for\": 0.4566\n",
      "  - \"was\": 0.4223\n",
      "  - \"on\": 0.4250\n",
      "  - \"that\": 0.5090\n",
      "  - \"as\": 0.3246\n",
      "  - \"it\": 0.4368\n",
      "  - \"with\": 0.4628\n",
      "  - \"by\": 0.4013\n",
      "  - \"\"\": 0.2845\n",
      "  - \"at\": 0.1109\n",
      "  - \"he\": 0.1132\n",
      "  - \"from\": 0.4317\n",
      "  - \"be\": 0.3913\n",
      "  - \"this\": 0.4455\n",
      "  - \"i\": 0.4236\n",
      "  - \"an\": 0.3668\n",
      "  - \"his\": 0.3972\n",
      "  - \"are\": 0.4281\n",
      "  - \"not\": 0.2775\n",
      "  - \"has\": 0.5111\n",
      "  - \"have\": 0.5137\n",
      "  - \"but\": 0.4539\n",
      "  - \"or\": 0.2262\n",
      "  - \"utc\": 0.2090\n",
      "  - \"which\": 0.4803\n",
      "  - \"were\": 0.4222\n",
      "  - \"–\": 0.2479\n",
      "  - \"said\": 0.4005\n",
      "  - \"they\": 0.4824\n",
      "  - \"also\": 0.4573\n",
      "  - \"one\": 0.2730\n",
      "  - \"who\": 0.3530\n",
      "  - \"had\": 0.5111\n",
      "  - \"talk\": 0.3547\n",
      "  - \"new\": 0.3804\n",
      "  - \"their\": 0.4696\n",
      "\n",
      "Similarities with \"'\":\n",
      "  - \",\": 0.5109\n",
      "  - \"the\": 0.4664\n",
      "  - \".\": 0.5376\n",
      "  - \"of\": 0.4375\n",
      "  - \"-\": 0.4843\n",
      "  - \"and\": 0.4414\n",
      "  - \"in\": 0.1099\n",
      "  - \"to\": 0.3801\n",
      "  - \"'\": 1.0000\n",
      "  - \"a\": 0.2186\n",
      "  - \")\": 0.5649\n",
      "  - \"(\": 0.5630\n",
      "  - \"is\": 0.3452\n",
      "  - \"s\": 0.3446\n",
      "  - \"for\": 0.4026\n",
      "  - \"was\": 0.3450\n",
      "  - \"on\": 0.2472\n",
      "  - \"that\": 0.4177\n",
      "  - \"as\": 0.3475\n",
      "  - \"it\": 0.4801\n",
      "  - \"with\": 0.3314\n",
      "  - \"by\": 0.3699\n",
      "  - \"\"\": 0.2645\n",
      "  - \"at\": 0.1577\n",
      "  - \"he\": 0.0867\n",
      "  - \"from\": 0.3471\n",
      "  - \"be\": 0.3323\n",
      "  - \"this\": 0.3885\n",
      "  - \"i\": 0.4622\n",
      "  - \"an\": 0.4047\n",
      "  - \"his\": 0.2922\n",
      "  - \"are\": 0.3560\n",
      "  - \"not\": 0.3107\n",
      "  - \"has\": 0.3937\n",
      "  - \"have\": 0.3688\n",
      "  - \"but\": 0.4280\n",
      "  - \"or\": 0.1373\n",
      "  - \"utc\": 0.2767\n",
      "  - \"which\": 0.3376\n",
      "  - \"were\": 0.3448\n",
      "  - \"–\": 0.4101\n",
      "  - \"said\": 0.4038\n",
      "  - \"they\": 0.3221\n",
      "  - \"also\": 0.3988\n",
      "  - \"one\": 0.2953\n",
      "  - \"who\": 0.3351\n",
      "  - \"had\": 0.3936\n",
      "  - \"talk\": 0.3855\n",
      "  - \"new\": 0.3170\n",
      "  - \"their\": 0.2767\n",
      "\n",
      "Similarities with \"a\":\n",
      "  - \",\": 0.2590\n",
      "  - \"the\": 0.1968\n",
      "  - \".\": 0.2986\n",
      "  - \"of\": 0.1793\n",
      "  - \"-\": 0.2863\n",
      "  - \"and\": 0.2084\n",
      "  - \"in\": 0.5135\n",
      "  - \"to\": 0.1733\n",
      "  - \"'\": 0.2186\n",
      "  - \"a\": 1.0000\n",
      "  - \")\": 0.2456\n",
      "  - \"(\": 0.2530\n",
      "  - \"is\": 0.2389\n",
      "  - \"s\": 0.5696\n",
      "  - \"for\": 0.2116\n",
      "  - \"was\": 0.2388\n",
      "  - \"on\": 0.1742\n",
      "  - \"that\": 0.1880\n",
      "  - \"as\": 0.8904\n",
      "  - \"it\": 0.2146\n",
      "  - \"with\": 0.1496\n",
      "  - \"by\": 0.2058\n",
      "  - \"\"\": 0.1744\n",
      "  - \"at\": 0.5083\n",
      "  - \"he\": 0.5441\n",
      "  - \"from\": 0.1497\n",
      "  - \"be\": 0.3966\n",
      "  - \"this\": 0.1677\n",
      "  - \"i\": 0.4549\n",
      "  - \"an\": 0.1562\n",
      "  - \"his\": 0.1459\n",
      "  - \"are\": 0.2525\n",
      "  - \"not\": 0.1746\n",
      "  - \"has\": 0.2867\n",
      "  - \"have\": 0.3176\n",
      "  - \"but\": 0.2807\n",
      "  - \"or\": 0.2404\n",
      "  - \"utc\": 0.2056\n",
      "  - \"which\": 0.2329\n",
      "  - \"were\": 0.2387\n",
      "  - \"–\": 0.1771\n",
      "  - \"said\": 0.2871\n",
      "  - \"they\": 0.1446\n",
      "  - \"also\": 0.2827\n",
      "  - \"one\": 0.3693\n",
      "  - \"who\": 0.1317\n",
      "  - \"had\": 0.2866\n",
      "  - \"talk\": 0.2882\n",
      "  - \"new\": 0.2816\n",
      "  - \"their\": 0.0989\n",
      "\n",
      "Similarities with \")\":\n",
      "  - \",\": 0.6108\n",
      "  - \"the\": 0.3871\n",
      "  - \".\": 0.5742\n",
      "  - \"of\": 0.4465\n",
      "  - \"-\": 0.5834\n",
      "  - \"and\": 0.3939\n",
      "  - \"in\": 0.1274\n",
      "  - \"to\": 0.3440\n",
      "  - \"'\": 0.5649\n",
      "  - \"a\": 0.2456\n",
      "  - \")\": 1.0000\n",
      "  - \"(\": 0.8799\n",
      "  - \"is\": 0.2720\n",
      "  - \"s\": 0.3829\n",
      "  - \"for\": 0.4241\n",
      "  - \"was\": 0.2719\n",
      "  - \"on\": 0.2167\n",
      "  - \"that\": 0.2885\n",
      "  - \"as\": 0.3483\n",
      "  - \"it\": 0.3392\n",
      "  - \"with\": 0.3389\n",
      "  - \"by\": 0.2683\n",
      "  - \"\"\": 0.2565\n",
      "  - \"at\": 0.1691\n",
      "  - \"he\": 0.1528\n",
      "  - \"from\": 0.3885\n",
      "  - \"be\": 0.3099\n",
      "  - \"this\": 0.3964\n",
      "  - \"i\": 0.4218\n",
      "  - \"an\": 0.3219\n",
      "  - \"his\": 0.1946\n",
      "  - \"are\": 0.2839\n",
      "  - \"not\": 0.2986\n",
      "  - \"has\": 0.3401\n",
      "  - \"have\": 0.3187\n",
      "  - \"but\": 0.3450\n",
      "  - \"or\": 0.1840\n",
      "  - \"utc\": 0.4105\n",
      "  - \"which\": 0.3048\n",
      "  - \"were\": 0.2717\n",
      "  - \"–\": 0.5241\n",
      "  - \"said\": 0.3232\n",
      "  - \"they\": 0.2250\n",
      "  - \"also\": 0.3506\n",
      "  - \"one\": 0.2512\n",
      "  - \"who\": 0.3488\n",
      "  - \"had\": 0.3399\n",
      "  - \"talk\": 0.3800\n",
      "  - \"new\": 0.2479\n",
      "  - \"their\": 0.1785\n",
      "\n",
      "Similarities with \"(\":\n",
      "  - \",\": 0.5921\n",
      "  - \"the\": 0.3989\n",
      "  - \".\": 0.5698\n",
      "  - \"of\": 0.4424\n",
      "  - \"-\": 0.5638\n",
      "  - \"and\": 0.4213\n",
      "  - \"in\": 0.1176\n",
      "  - \"to\": 0.3160\n",
      "  - \"'\": 0.5630\n",
      "  - \"a\": 0.2530\n",
      "  - \")\": 0.8799\n",
      "  - \"(\": 1.0000\n",
      "  - \"is\": 0.3204\n",
      "  - \"s\": 0.3672\n",
      "  - \"for\": 0.3903\n",
      "  - \"was\": 0.3204\n",
      "  - \"on\": 0.2199\n",
      "  - \"that\": 0.2523\n",
      "  - \"as\": 0.3418\n",
      "  - \"it\": 0.3327\n",
      "  - \"with\": 0.3059\n",
      "  - \"by\": 0.2850\n",
      "  - \"\"\": 0.2682\n",
      "  - \"at\": 0.1674\n",
      "  - \"he\": 0.1421\n",
      "  - \"from\": 0.3929\n",
      "  - \"be\": 0.3085\n",
      "  - \"this\": 0.3956\n",
      "  - \"i\": 0.4034\n",
      "  - \"an\": 0.3330\n",
      "  - \"his\": 0.2103\n",
      "  - \"are\": 0.3317\n",
      "  - \"not\": 0.2930\n",
      "  - \"has\": 0.3493\n",
      "  - \"have\": 0.3200\n",
      "  - \"but\": 0.3250\n",
      "  - \"or\": 0.1788\n",
      "  - \"utc\": 0.4313\n",
      "  - \"which\": 0.2855\n",
      "  - \"were\": 0.3202\n",
      "  - \"–\": 0.5239\n",
      "  - \"said\": 0.3396\n",
      "  - \"they\": 0.2134\n",
      "  - \"also\": 0.3229\n",
      "  - \"one\": 0.2469\n",
      "  - \"who\": 0.3307\n",
      "  - \"had\": 0.3491\n",
      "  - \"talk\": 0.3654\n",
      "  - \"new\": 0.2669\n",
      "  - \"their\": 0.1947\n",
      "\n",
      "Similarities with \"is\":\n",
      "  - \",\": 0.3816\n",
      "  - \"the\": 0.4825\n",
      "  - \".\": 0.4528\n",
      "  - \"of\": 0.3636\n",
      "  - \"-\": 0.3125\n",
      "  - \"and\": 0.4118\n",
      "  - \"in\": 0.2766\n",
      "  - \"to\": 0.4222\n",
      "  - \"'\": 0.3452\n",
      "  - \"a\": 0.2389\n",
      "  - \")\": 0.2720\n",
      "  - \"(\": 0.3204\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": 0.3926\n",
      "  - \"for\": 0.3898\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": 0.2943\n",
      "  - \"that\": 0.5506\n",
      "  - \"as\": 0.4141\n",
      "  - \"it\": 0.4773\n",
      "  - \"with\": 0.3602\n",
      "  - \"by\": 0.3870\n",
      "  - \"\"\": 0.3427\n",
      "  - \"at\": 0.1975\n",
      "  - \"he\": 0.2125\n",
      "  - \"from\": 0.2969\n",
      "  - \"be\": 0.7308\n",
      "  - \"this\": 0.4822\n",
      "  - \"i\": 0.5110\n",
      "  - \"an\": 0.3158\n",
      "  - \"his\": 0.2738\n",
      "  - \"are\": 0.9983\n",
      "  - \"not\": 0.3578\n",
      "  - \"has\": 0.7213\n",
      "  - \"have\": 0.6807\n",
      "  - \"but\": 0.5200\n",
      "  - \"or\": 0.1870\n",
      "  - \"utc\": 0.2591\n",
      "  - \"which\": 0.4842\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": 0.1668\n",
      "  - \"said\": 0.5828\n",
      "  - \"they\": 0.4645\n",
      "  - \"also\": 0.5164\n",
      "  - \"one\": 0.4361\n",
      "  - \"who\": 0.2469\n",
      "  - \"had\": 0.7212\n",
      "  - \"talk\": 0.4389\n",
      "  - \"new\": 0.4207\n",
      "  - \"their\": 0.4329\n",
      "\n",
      "Similarities with \"s\":\n",
      "  - \",\": 0.4876\n",
      "  - \"the\": 0.4564\n",
      "  - \".\": 0.4917\n",
      "  - \"of\": 0.4005\n",
      "  - \"-\": 0.4667\n",
      "  - \"and\": 0.4124\n",
      "  - \"in\": 0.5407\n",
      "  - \"to\": 0.3403\n",
      "  - \"'\": 0.3446\n",
      "  - \"a\": 0.5696\n",
      "  - \")\": 0.3829\n",
      "  - \"(\": 0.3672\n",
      "  - \"is\": 0.3926\n",
      "  - \"s\": 1.0000\n",
      "  - \"for\": 0.2838\n",
      "  - \"was\": 0.3926\n",
      "  - \"on\": 0.4370\n",
      "  - \"that\": 0.3744\n",
      "  - \"as\": 0.6734\n",
      "  - \"it\": 0.3805\n",
      "  - \"with\": 0.3604\n",
      "  - \"by\": 0.3514\n",
      "  - \"\"\": 0.3177\n",
      "  - \"at\": 0.4444\n",
      "  - \"he\": 0.5577\n",
      "  - \"from\": 0.3964\n",
      "  - \"be\": 0.5340\n",
      "  - \"this\": 0.3646\n",
      "  - \"i\": 0.5869\n",
      "  - \"an\": 0.3567\n",
      "  - \"his\": 0.2634\n",
      "  - \"are\": 0.4071\n",
      "  - \"not\": 0.2645\n",
      "  - \"has\": 0.4155\n",
      "  - \"have\": 0.4054\n",
      "  - \"but\": 0.4198\n",
      "  - \"or\": 0.2151\n",
      "  - \"utc\": 0.2473\n",
      "  - \"which\": 0.4184\n",
      "  - \"were\": 0.3924\n",
      "  - \"–\": 0.2965\n",
      "  - \"said\": 0.4118\n",
      "  - \"they\": 0.2846\n",
      "  - \"also\": 0.4226\n",
      "  - \"one\": 0.4774\n",
      "  - \"who\": 0.2279\n",
      "  - \"had\": 0.4155\n",
      "  - \"talk\": 0.4585\n",
      "  - \"new\": 0.4600\n",
      "  - \"their\": 0.2693\n",
      "\n",
      "Similarities with \"for\":\n",
      "  - \",\": 0.4648\n",
      "  - \"the\": 0.4985\n",
      "  - \".\": 0.4884\n",
      "  - \"of\": 0.4764\n",
      "  - \"-\": 0.4293\n",
      "  - \"and\": 0.5425\n",
      "  - \"in\": 0.1466\n",
      "  - \"to\": 0.4566\n",
      "  - \"'\": 0.4026\n",
      "  - \"a\": 0.2116\n",
      "  - \")\": 0.4241\n",
      "  - \"(\": 0.3903\n",
      "  - \"is\": 0.3898\n",
      "  - \"s\": 0.2838\n",
      "  - \"for\": 1.0000\n",
      "  - \"was\": 0.3899\n",
      "  - \"on\": 0.3143\n",
      "  - \"that\": 0.4263\n",
      "  - \"as\": 0.3470\n",
      "  - \"it\": 0.3472\n",
      "  - \"with\": 0.4430\n",
      "  - \"by\": 0.3757\n",
      "  - \"\"\": 0.3066\n",
      "  - \"at\": 0.1552\n",
      "  - \"he\": 0.1272\n",
      "  - \"from\": 0.4067\n",
      "  - \"be\": 0.4053\n",
      "  - \"this\": 0.3820\n",
      "  - \"i\": 0.4705\n",
      "  - \"an\": 0.3802\n",
      "  - \"his\": 0.3596\n",
      "  - \"are\": 0.3947\n",
      "  - \"not\": 0.3491\n",
      "  - \"has\": 0.4731\n",
      "  - \"have\": 0.4587\n",
      "  - \"but\": 0.4333\n",
      "  - \"or\": 0.1720\n",
      "  - \"utc\": 0.2402\n",
      "  - \"which\": 0.4294\n",
      "  - \"were\": 0.3898\n",
      "  - \"–\": 0.3485\n",
      "  - \"said\": 0.3358\n",
      "  - \"they\": 0.3271\n",
      "  - \"also\": 0.4483\n",
      "  - \"one\": 0.3632\n",
      "  - \"who\": 0.3697\n",
      "  - \"had\": 0.4730\n",
      "  - \"talk\": 0.2959\n",
      "  - \"new\": 0.3484\n",
      "  - \"their\": 0.3851\n",
      "\n",
      "Similarities with \"was\":\n",
      "  - \",\": 0.3816\n",
      "  - \"the\": 0.4825\n",
      "  - \".\": 0.4528\n",
      "  - \"of\": 0.3635\n",
      "  - \"-\": 0.3125\n",
      "  - \"and\": 0.4118\n",
      "  - \"in\": 0.2766\n",
      "  - \"to\": 0.4223\n",
      "  - \"'\": 0.3450\n",
      "  - \"a\": 0.2388\n",
      "  - \")\": 0.2719\n",
      "  - \"(\": 0.3204\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": 0.3926\n",
      "  - \"for\": 0.3899\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": 0.2943\n",
      "  - \"that\": 0.5505\n",
      "  - \"as\": 0.4140\n",
      "  - \"it\": 0.4772\n",
      "  - \"with\": 0.3602\n",
      "  - \"by\": 0.3869\n",
      "  - \"\"\": 0.3427\n",
      "  - \"at\": 0.1974\n",
      "  - \"he\": 0.2125\n",
      "  - \"from\": 0.2970\n",
      "  - \"be\": 0.7307\n",
      "  - \"this\": 0.4822\n",
      "  - \"i\": 0.5110\n",
      "  - \"an\": 0.3157\n",
      "  - \"his\": 0.2740\n",
      "  - \"are\": 0.9983\n",
      "  - \"not\": 0.3577\n",
      "  - \"has\": 0.7213\n",
      "  - \"have\": 0.6807\n",
      "  - \"but\": 0.5199\n",
      "  - \"or\": 0.1871\n",
      "  - \"utc\": 0.2590\n",
      "  - \"which\": 0.4842\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": 0.1669\n",
      "  - \"said\": 0.5827\n",
      "  - \"they\": 0.4646\n",
      "  - \"also\": 0.5163\n",
      "  - \"one\": 0.4361\n",
      "  - \"who\": 0.2470\n",
      "  - \"had\": 0.7212\n",
      "  - \"talk\": 0.4389\n",
      "  - \"new\": 0.4209\n",
      "  - \"their\": 0.4330\n",
      "\n",
      "Similarities with \"on\":\n",
      "  - \",\": 0.4349\n",
      "  - \"the\": 0.4726\n",
      "  - \".\": 0.4031\n",
      "  - \"of\": 0.4311\n",
      "  - \"-\": 0.3676\n",
      "  - \"and\": 0.5675\n",
      "  - \"in\": 0.3302\n",
      "  - \"to\": 0.4250\n",
      "  - \"'\": 0.2472\n",
      "  - \"a\": 0.1742\n",
      "  - \")\": 0.2167\n",
      "  - \"(\": 0.2199\n",
      "  - \"is\": 0.2943\n",
      "  - \"s\": 0.4370\n",
      "  - \"for\": 0.3143\n",
      "  - \"was\": 0.2943\n",
      "  - \"on\": 1.0000\n",
      "  - \"that\": 0.3993\n",
      "  - \"as\": 0.3298\n",
      "  - \"it\": 0.2886\n",
      "  - \"with\": 0.4493\n",
      "  - \"by\": 0.3729\n",
      "  - \"\"\": 0.2356\n",
      "  - \"at\": 0.1007\n",
      "  - \"he\": 0.1052\n",
      "  - \"from\": 0.4178\n",
      "  - \"be\": 0.3627\n",
      "  - \"this\": 0.2443\n",
      "  - \"i\": 0.4229\n",
      "  - \"an\": 0.3135\n",
      "  - \"his\": 0.3055\n",
      "  - \"are\": 0.3042\n",
      "  - \"not\": 0.1725\n",
      "  - \"has\": 0.3678\n",
      "  - \"have\": 0.3202\n",
      "  - \"but\": 0.3342\n",
      "  - \"or\": 0.0962\n",
      "  - \"utc\": 0.1040\n",
      "  - \"which\": 0.4264\n",
      "  - \"were\": 0.2943\n",
      "  - \"–\": 0.1894\n",
      "  - \"said\": 0.2868\n",
      "  - \"they\": 0.2906\n",
      "  - \"also\": 0.4718\n",
      "  - \"one\": 0.2771\n",
      "  - \"who\": 0.2743\n",
      "  - \"had\": 0.3678\n",
      "  - \"talk\": 0.3002\n",
      "  - \"new\": 0.3480\n",
      "  - \"their\": 0.3593\n",
      "\n",
      "Similarities with \"that\":\n",
      "  - \",\": 0.4100\n",
      "  - \"the\": 0.5602\n",
      "  - \".\": 0.4804\n",
      "  - \"of\": 0.4399\n",
      "  - \"-\": 0.3770\n",
      "  - \"and\": 0.5361\n",
      "  - \"in\": 0.2019\n",
      "  - \"to\": 0.5090\n",
      "  - \"'\": 0.4177\n",
      "  - \"a\": 0.1880\n",
      "  - \")\": 0.2885\n",
      "  - \"(\": 0.2523\n",
      "  - \"is\": 0.5506\n",
      "  - \"s\": 0.3744\n",
      "  - \"for\": 0.4263\n",
      "  - \"was\": 0.5505\n",
      "  - \"on\": 0.3993\n",
      "  - \"that\": 1.0000\n",
      "  - \"as\": 0.3962\n",
      "  - \"it\": 0.5371\n",
      "  - \"with\": 0.4780\n",
      "  - \"by\": 0.4325\n",
      "  - \"\"\": 0.3851\n",
      "  - \"at\": 0.1843\n",
      "  - \"he\": 0.2048\n",
      "  - \"from\": 0.3905\n",
      "  - \"be\": 0.5075\n",
      "  - \"this\": 0.5993\n",
      "  - \"i\": 0.5234\n",
      "  - \"an\": 0.4072\n",
      "  - \"his\": 0.3790\n",
      "  - \"are\": 0.5557\n",
      "  - \"not\": 0.3602\n",
      "  - \"has\": 0.6088\n",
      "  - \"have\": 0.5443\n",
      "  - \"but\": 0.6550\n",
      "  - \"or\": 0.1472\n",
      "  - \"utc\": 0.2412\n",
      "  - \"which\": 0.7366\n",
      "  - \"were\": 0.5505\n",
      "  - \"–\": 0.1914\n",
      "  - \"said\": 0.5430\n",
      "  - \"they\": 0.5066\n",
      "  - \"also\": 0.6204\n",
      "  - \"one\": 0.4020\n",
      "  - \"who\": 0.4302\n",
      "  - \"had\": 0.6087\n",
      "  - \"talk\": 0.4158\n",
      "  - \"new\": 0.4176\n",
      "  - \"their\": 0.4321\n",
      "\n",
      "Similarities with \"as\":\n",
      "  - \",\": 0.4145\n",
      "  - \"the\": 0.3967\n",
      "  - \".\": 0.4505\n",
      "  - \"of\": 0.3332\n",
      "  - \"-\": 0.4102\n",
      "  - \"and\": 0.4095\n",
      "  - \"in\": 0.5438\n",
      "  - \"to\": 0.3246\n",
      "  - \"'\": 0.3475\n",
      "  - \"a\": 0.8904\n",
      "  - \")\": 0.3483\n",
      "  - \"(\": 0.3418\n",
      "  - \"is\": 0.4141\n",
      "  - \"s\": 0.6734\n",
      "  - \"for\": 0.3470\n",
      "  - \"was\": 0.4140\n",
      "  - \"on\": 0.3298\n",
      "  - \"that\": 0.3962\n",
      "  - \"as\": 1.0000\n",
      "  - \"it\": 0.3773\n",
      "  - \"with\": 0.3293\n",
      "  - \"by\": 0.3680\n",
      "  - \"\"\": 0.2888\n",
      "  - \"at\": 0.5601\n",
      "  - \"he\": 0.5682\n",
      "  - \"from\": 0.2739\n",
      "  - \"be\": 0.5506\n",
      "  - \"this\": 0.3327\n",
      "  - \"i\": 0.6351\n",
      "  - \"an\": 0.3423\n",
      "  - \"his\": 0.2753\n",
      "  - \"are\": 0.4285\n",
      "  - \"not\": 0.2999\n",
      "  - \"has\": 0.4605\n",
      "  - \"have\": 0.4739\n",
      "  - \"but\": 0.4687\n",
      "  - \"or\": 0.2816\n",
      "  - \"utc\": 0.2338\n",
      "  - \"which\": 0.4314\n",
      "  - \"were\": 0.4139\n",
      "  - \"–\": 0.2428\n",
      "  - \"said\": 0.4531\n",
      "  - \"they\": 0.2947\n",
      "  - \"also\": 0.5190\n",
      "  - \"one\": 0.4738\n",
      "  - \"who\": 0.2627\n",
      "  - \"had\": 0.4604\n",
      "  - \"talk\": 0.4259\n",
      "  - \"new\": 0.4355\n",
      "  - \"their\": 0.2368\n",
      "\n",
      "Similarities with \"it\":\n",
      "  - \",\": 0.4465\n",
      "  - \"the\": 0.5828\n",
      "  - \".\": 0.4876\n",
      "  - \"of\": 0.4193\n",
      "  - \"-\": 0.3762\n",
      "  - \"and\": 0.4787\n",
      "  - \"in\": 0.1933\n",
      "  - \"to\": 0.4368\n",
      "  - \"'\": 0.4801\n",
      "  - \"a\": 0.2146\n",
      "  - \")\": 0.3392\n",
      "  - \"(\": 0.3327\n",
      "  - \"is\": 0.4773\n",
      "  - \"s\": 0.3805\n",
      "  - \"for\": 0.3472\n",
      "  - \"was\": 0.4772\n",
      "  - \"on\": 0.2886\n",
      "  - \"that\": 0.5371\n",
      "  - \"as\": 0.3773\n",
      "  - \"it\": 1.0000\n",
      "  - \"with\": 0.3541\n",
      "  - \"by\": 0.3404\n",
      "  - \"\"\": 0.2548\n",
      "  - \"at\": 0.1781\n",
      "  - \"he\": 0.1600\n",
      "  - \"from\": 0.3687\n",
      "  - \"be\": 0.3607\n",
      "  - \"this\": 0.6052\n",
      "  - \"i\": 0.4794\n",
      "  - \"an\": 0.4183\n",
      "  - \"his\": 0.2834\n",
      "  - \"are\": 0.4832\n",
      "  - \"not\": 0.2568\n",
      "  - \"has\": 0.4526\n",
      "  - \"have\": 0.3939\n",
      "  - \"but\": 0.5003\n",
      "  - \"or\": 0.1316\n",
      "  - \"utc\": 0.2442\n",
      "  - \"which\": 0.5677\n",
      "  - \"were\": 0.4770\n",
      "  - \"–\": 0.1565\n",
      "  - \"said\": 0.4098\n",
      "  - \"they\": 0.4417\n",
      "  - \"also\": 0.4659\n",
      "  - \"one\": 0.3020\n",
      "  - \"who\": 0.2633\n",
      "  - \"had\": 0.4525\n",
      "  - \"talk\": 0.3664\n",
      "  - \"new\": 0.3915\n",
      "  - \"their\": 0.3008\n",
      "\n",
      "Similarities with \"with\":\n",
      "  - \",\": 0.4828\n",
      "  - \"the\": 0.5103\n",
      "  - \".\": 0.4638\n",
      "  - \"of\": 0.4502\n",
      "  - \"-\": 0.4224\n",
      "  - \"and\": 0.6079\n",
      "  - \"in\": 0.2540\n",
      "  - \"to\": 0.4628\n",
      "  - \"'\": 0.3314\n",
      "  - \"a\": 0.1496\n",
      "  - \")\": 0.3389\n",
      "  - \"(\": 0.3059\n",
      "  - \"is\": 0.3602\n",
      "  - \"s\": 0.3604\n",
      "  - \"for\": 0.4430\n",
      "  - \"was\": 0.3602\n",
      "  - \"on\": 0.4493\n",
      "  - \"that\": 0.4780\n",
      "  - \"as\": 0.3293\n",
      "  - \"it\": 0.3541\n",
      "  - \"with\": 1.0000\n",
      "  - \"by\": 0.3233\n",
      "  - \"\"\": 0.2737\n",
      "  - \"at\": 0.1362\n",
      "  - \"he\": 0.1623\n",
      "  - \"from\": 0.4548\n",
      "  - \"be\": 0.4104\n",
      "  - \"this\": 0.3701\n",
      "  - \"i\": 0.4862\n",
      "  - \"an\": 0.3966\n",
      "  - \"his\": 0.3652\n",
      "  - \"are\": 0.3686\n",
      "  - \"not\": 0.3156\n",
      "  - \"has\": 0.4983\n",
      "  - \"have\": 0.4656\n",
      "  - \"but\": 0.3929\n",
      "  - \"or\": 0.1877\n",
      "  - \"utc\": 0.1654\n",
      "  - \"which\": 0.5273\n",
      "  - \"were\": 0.3602\n",
      "  - \"–\": 0.2693\n",
      "  - \"said\": 0.3315\n",
      "  - \"they\": 0.3914\n",
      "  - \"also\": 0.4747\n",
      "  - \"one\": 0.3555\n",
      "  - \"who\": 0.3918\n",
      "  - \"had\": 0.4983\n",
      "  - \"talk\": 0.3167\n",
      "  - \"new\": 0.3922\n",
      "  - \"their\": 0.4425\n",
      "\n",
      "Similarities with \"by\":\n",
      "  - \",\": 0.3419\n",
      "  - \"the\": 0.4023\n",
      "  - \".\": 0.4057\n",
      "  - \"of\": 0.3738\n",
      "  - \"-\": 0.3120\n",
      "  - \"and\": 0.4140\n",
      "  - \"in\": 0.2892\n",
      "  - \"to\": 0.4013\n",
      "  - \"'\": 0.3699\n",
      "  - \"a\": 0.2058\n",
      "  - \")\": 0.2683\n",
      "  - \"(\": 0.2850\n",
      "  - \"is\": 0.3870\n",
      "  - \"s\": 0.3514\n",
      "  - \"for\": 0.3757\n",
      "  - \"was\": 0.3869\n",
      "  - \"on\": 0.3729\n",
      "  - \"that\": 0.4325\n",
      "  - \"as\": 0.3680\n",
      "  - \"it\": 0.3404\n",
      "  - \"with\": 0.3233\n",
      "  - \"by\": 1.0000\n",
      "  - \"\"\": 0.2252\n",
      "  - \"at\": 0.2069\n",
      "  - \"he\": 0.1647\n",
      "  - \"from\": 0.3366\n",
      "  - \"be\": 0.3993\n",
      "  - \"this\": 0.3555\n",
      "  - \"i\": 0.4147\n",
      "  - \"an\": 0.2476\n",
      "  - \"his\": 0.3263\n",
      "  - \"are\": 0.3944\n",
      "  - \"not\": 0.2339\n",
      "  - \"has\": 0.5067\n",
      "  - \"have\": 0.4905\n",
      "  - \"but\": 0.5585\n",
      "  - \"or\": 0.1664\n",
      "  - \"utc\": 0.2030\n",
      "  - \"which\": 0.3886\n",
      "  - \"were\": 0.3869\n",
      "  - \"–\": 0.3194\n",
      "  - \"said\": 0.4435\n",
      "  - \"they\": 0.3377\n",
      "  - \"also\": 0.5549\n",
      "  - \"one\": 0.3009\n",
      "  - \"who\": 0.3325\n",
      "  - \"had\": 0.5067\n",
      "  - \"talk\": 0.3733\n",
      "  - \"new\": 0.3676\n",
      "  - \"their\": 0.3590\n",
      "\n",
      "Similarities with \"\"\":\n",
      "  - \",\": 0.3507\n",
      "  - \"the\": 0.3547\n",
      "  - \".\": 0.3175\n",
      "  - \"of\": 0.3230\n",
      "  - \"-\": 0.2872\n",
      "  - \"and\": 0.3856\n",
      "  - \"in\": 0.2068\n",
      "  - \"to\": 0.2845\n",
      "  - \"'\": 0.2645\n",
      "  - \"a\": 0.1744\n",
      "  - \")\": 0.2565\n",
      "  - \"(\": 0.2682\n",
      "  - \"is\": 0.3427\n",
      "  - \"s\": 0.3177\n",
      "  - \"for\": 0.3066\n",
      "  - \"was\": 0.3427\n",
      "  - \"on\": 0.2356\n",
      "  - \"that\": 0.3851\n",
      "  - \"as\": 0.2888\n",
      "  - \"it\": 0.2548\n",
      "  - \"with\": 0.2737\n",
      "  - \"by\": 0.2252\n",
      "  - \"\"\": 1.0000\n",
      "  - \"at\": 0.0565\n",
      "  - \"he\": 0.1095\n",
      "  - \"from\": 0.2612\n",
      "  - \"be\": 0.4301\n",
      "  - \"this\": 0.2880\n",
      "  - \"i\": 0.4412\n",
      "  - \"an\": 0.2753\n",
      "  - \"his\": 0.3284\n",
      "  - \"are\": 0.3478\n",
      "  - \"not\": 0.1399\n",
      "  - \"has\": 0.3738\n",
      "  - \"have\": 0.3895\n",
      "  - \"but\": 0.3549\n",
      "  - \"or\": 0.1669\n",
      "  - \"utc\": 0.2090\n",
      "  - \"which\": 0.3948\n",
      "  - \"were\": 0.3426\n",
      "  - \"–\": 0.2880\n",
      "  - \"said\": 0.4387\n",
      "  - \"they\": 0.2696\n",
      "  - \"also\": 0.3692\n",
      "  - \"one\": 0.5039\n",
      "  - \"who\": 0.2298\n",
      "  - \"had\": 0.3737\n",
      "  - \"talk\": 0.4546\n",
      "  - \"new\": 0.4277\n",
      "  - \"their\": 0.3309\n",
      "\n",
      "Similarities with \"at\":\n",
      "  - \",\": 0.1697\n",
      "  - \"the\": 0.1728\n",
      "  - \".\": 0.1964\n",
      "  - \"of\": 0.1856\n",
      "  - \"-\": 0.1619\n",
      "  - \"and\": 0.1263\n",
      "  - \"in\": 0.3655\n",
      "  - \"to\": 0.1109\n",
      "  - \"'\": 0.1577\n",
      "  - \"a\": 0.5083\n",
      "  - \")\": 0.1691\n",
      "  - \"(\": 0.1674\n",
      "  - \"is\": 0.1975\n",
      "  - \"s\": 0.4444\n",
      "  - \"for\": 0.1552\n",
      "  - \"was\": 0.1974\n",
      "  - \"on\": 0.1007\n",
      "  - \"that\": 0.1843\n",
      "  - \"as\": 0.5601\n",
      "  - \"it\": 0.1781\n",
      "  - \"with\": 0.1362\n",
      "  - \"by\": 0.2069\n",
      "  - \"\"\": 0.0565\n",
      "  - \"at\": 1.0000\n",
      "  - \"he\": 0.5944\n",
      "  - \"from\": 0.1194\n",
      "  - \"be\": 0.3335\n",
      "  - \"this\": 0.1743\n",
      "  - \"i\": 0.4144\n",
      "  - \"an\": 0.1571\n",
      "  - \"his\": 0.1479\n",
      "  - \"are\": 0.2028\n",
      "  - \"not\": 0.2261\n",
      "  - \"has\": 0.2564\n",
      "  - \"have\": 0.2486\n",
      "  - \"but\": 0.2445\n",
      "  - \"or\": 0.1631\n",
      "  - \"utc\": 0.1675\n",
      "  - \"which\": 0.1447\n",
      "  - \"were\": 0.1973\n",
      "  - \"–\": 0.0870\n",
      "  - \"said\": 0.2932\n",
      "  - \"they\": 0.1537\n",
      "  - \"also\": 0.2797\n",
      "  - \"one\": 0.2400\n",
      "  - \"who\": 0.1408\n",
      "  - \"had\": 0.2564\n",
      "  - \"talk\": 0.2297\n",
      "  - \"new\": 0.2436\n",
      "  - \"their\": 0.1039\n",
      "\n",
      "Similarities with \"he\":\n",
      "  - \",\": 0.1751\n",
      "  - \"the\": 0.1546\n",
      "  - \".\": 0.2055\n",
      "  - \"of\": 0.1062\n",
      "  - \"-\": 0.1734\n",
      "  - \"and\": 0.0985\n",
      "  - \"in\": 0.4988\n",
      "  - \"to\": 0.1132\n",
      "  - \"'\": 0.0867\n",
      "  - \"a\": 0.5441\n",
      "  - \")\": 0.1528\n",
      "  - \"(\": 0.1421\n",
      "  - \"is\": 0.2125\n",
      "  - \"s\": 0.5577\n",
      "  - \"for\": 0.1272\n",
      "  - \"was\": 0.2125\n",
      "  - \"on\": 0.1052\n",
      "  - \"that\": 0.2048\n",
      "  - \"as\": 0.5682\n",
      "  - \"it\": 0.1600\n",
      "  - \"with\": 0.1623\n",
      "  - \"by\": 0.1647\n",
      "  - \"\"\": 0.1095\n",
      "  - \"at\": 0.5944\n",
      "  - \"he\": 1.0000\n",
      "  - \"from\": 0.1218\n",
      "  - \"be\": 0.3306\n",
      "  - \"this\": 0.1630\n",
      "  - \"i\": 0.3814\n",
      "  - \"an\": 0.1098\n",
      "  - \"his\": 0.1046\n",
      "  - \"are\": 0.2173\n",
      "  - \"not\": 0.1312\n",
      "  - \"has\": 0.2410\n",
      "  - \"have\": 0.2519\n",
      "  - \"but\": 0.2141\n",
      "  - \"or\": 0.1906\n",
      "  - \"utc\": 0.1165\n",
      "  - \"which\": 0.1546\n",
      "  - \"were\": 0.2124\n",
      "  - \"–\": 0.0735\n",
      "  - \"said\": 0.2361\n",
      "  - \"they\": 0.1400\n",
      "  - \"also\": 0.2368\n",
      "  - \"one\": 0.2766\n",
      "  - \"who\": 0.0901\n",
      "  - \"had\": 0.2410\n",
      "  - \"talk\": 0.2412\n",
      "  - \"new\": 0.3060\n",
      "  - \"their\": 0.0817\n",
      "\n",
      "Similarities with \"from\":\n",
      "  - \",\": 0.4830\n",
      "  - \"the\": 0.4914\n",
      "  - \".\": 0.4680\n",
      "  - \"of\": 0.5273\n",
      "  - \"-\": 0.4166\n",
      "  - \"and\": 0.5066\n",
      "  - \"in\": 0.1856\n",
      "  - \"to\": 0.4317\n",
      "  - \"'\": 0.3471\n",
      "  - \"a\": 0.1497\n",
      "  - \")\": 0.3885\n",
      "  - \"(\": 0.3929\n",
      "  - \"is\": 0.2969\n",
      "  - \"s\": 0.3964\n",
      "  - \"for\": 0.4067\n",
      "  - \"was\": 0.2970\n",
      "  - \"on\": 0.4178\n",
      "  - \"that\": 0.3905\n",
      "  - \"as\": 0.2739\n",
      "  - \"it\": 0.3687\n",
      "  - \"with\": 0.4548\n",
      "  - \"by\": 0.3366\n",
      "  - \"\"\": 0.2612\n",
      "  - \"at\": 0.1194\n",
      "  - \"he\": 0.1218\n",
      "  - \"from\": 1.0000\n",
      "  - \"be\": 0.3395\n",
      "  - \"this\": 0.3277\n",
      "  - \"i\": 0.3729\n",
      "  - \"an\": 0.3671\n",
      "  - \"his\": 0.3798\n",
      "  - \"are\": 0.3031\n",
      "  - \"not\": 0.2659\n",
      "  - \"has\": 0.4002\n",
      "  - \"have\": 0.3590\n",
      "  - \"but\": 0.3763\n",
      "  - \"or\": 0.1795\n",
      "  - \"utc\": 0.1741\n",
      "  - \"which\": 0.4547\n",
      "  - \"were\": 0.2969\n",
      "  - \"–\": 0.3096\n",
      "  - \"said\": 0.3545\n",
      "  - \"they\": 0.3252\n",
      "  - \"also\": 0.4101\n",
      "  - \"one\": 0.2094\n",
      "  - \"who\": 0.3789\n",
      "  - \"had\": 0.4002\n",
      "  - \"talk\": 0.3230\n",
      "  - \"new\": 0.3601\n",
      "  - \"their\": 0.3191\n",
      "\n",
      "Similarities with \"be\":\n",
      "  - \",\": 0.4334\n",
      "  - \"the\": 0.4736\n",
      "  - \".\": 0.4283\n",
      "  - \"of\": 0.4473\n",
      "  - \"-\": 0.3526\n",
      "  - \"and\": 0.4394\n",
      "  - \"in\": 0.4193\n",
      "  - \"to\": 0.3913\n",
      "  - \"'\": 0.3323\n",
      "  - \"a\": 0.3966\n",
      "  - \")\": 0.3099\n",
      "  - \"(\": 0.3085\n",
      "  - \"is\": 0.7308\n",
      "  - \"s\": 0.5340\n",
      "  - \"for\": 0.4053\n",
      "  - \"was\": 0.7307\n",
      "  - \"on\": 0.3627\n",
      "  - \"that\": 0.5075\n",
      "  - \"as\": 0.5506\n",
      "  - \"it\": 0.3607\n",
      "  - \"with\": 0.4104\n",
      "  - \"by\": 0.3993\n",
      "  - \"\"\": 0.4301\n",
      "  - \"at\": 0.3335\n",
      "  - \"he\": 0.3306\n",
      "  - \"from\": 0.3395\n",
      "  - \"be\": 1.0000\n",
      "  - \"this\": 0.3783\n",
      "  - \"i\": 0.5834\n",
      "  - \"an\": 0.3209\n",
      "  - \"his\": 0.2693\n",
      "  - \"are\": 0.7334\n",
      "  - \"not\": 0.3684\n",
      "  - \"has\": 0.7296\n",
      "  - \"have\": 0.7328\n",
      "  - \"but\": 0.5171\n",
      "  - \"or\": 0.2005\n",
      "  - \"utc\": 0.1780\n",
      "  - \"which\": 0.4688\n",
      "  - \"were\": 0.7308\n",
      "  - \"–\": 0.1964\n",
      "  - \"said\": 0.6312\n",
      "  - \"they\": 0.4338\n",
      "  - \"also\": 0.5747\n",
      "  - \"one\": 0.5646\n",
      "  - \"who\": 0.2508\n",
      "  - \"had\": 0.7296\n",
      "  - \"talk\": 0.5520\n",
      "  - \"new\": 0.4306\n",
      "  - \"their\": 0.4431\n",
      "\n",
      "Similarities with \"this\":\n",
      "  - \",\": 0.3865\n",
      "  - \"the\": 0.5624\n",
      "  - \".\": 0.4908\n",
      "  - \"of\": 0.3750\n",
      "  - \"-\": 0.4014\n",
      "  - \"and\": 0.3748\n",
      "  - \"in\": 0.1592\n",
      "  - \"to\": 0.4455\n",
      "  - \"'\": 0.3885\n",
      "  - \"a\": 0.1677\n",
      "  - \")\": 0.3964\n",
      "  - \"(\": 0.3956\n",
      "  - \"is\": 0.4822\n",
      "  - \"s\": 0.3646\n",
      "  - \"for\": 0.3820\n",
      "  - \"was\": 0.4822\n",
      "  - \"on\": 0.2443\n",
      "  - \"that\": 0.5993\n",
      "  - \"as\": 0.3327\n",
      "  - \"it\": 0.6052\n",
      "  - \"with\": 0.3701\n",
      "  - \"by\": 0.3555\n",
      "  - \"\"\": 0.2880\n",
      "  - \"at\": 0.1743\n",
      "  - \"he\": 0.1630\n",
      "  - \"from\": 0.3277\n",
      "  - \"be\": 0.3783\n",
      "  - \"this\": 1.0000\n",
      "  - \"i\": 0.4542\n",
      "  - \"an\": 0.3515\n",
      "  - \"his\": 0.3377\n",
      "  - \"are\": 0.4887\n",
      "  - \"not\": 0.3439\n",
      "  - \"has\": 0.4839\n",
      "  - \"have\": 0.4002\n",
      "  - \"but\": 0.5257\n",
      "  - \"or\": 0.1316\n",
      "  - \"utc\": 0.4021\n",
      "  - \"which\": 0.5679\n",
      "  - \"were\": 0.4821\n",
      "  - \"–\": 0.1735\n",
      "  - \"said\": 0.4210\n",
      "  - \"they\": 0.3588\n",
      "  - \"also\": 0.4808\n",
      "  - \"one\": 0.3286\n",
      "  - \"who\": 0.2629\n",
      "  - \"had\": 0.4838\n",
      "  - \"talk\": 0.3718\n",
      "  - \"new\": 0.3471\n",
      "  - \"their\": 0.3742\n",
      "\n",
      "Similarities with \"i\":\n",
      "  - \",\": 0.5108\n",
      "  - \"the\": 0.5961\n",
      "  - \".\": 0.5432\n",
      "  - \"of\": 0.4690\n",
      "  - \"-\": 0.4900\n",
      "  - \"and\": 0.5249\n",
      "  - \"in\": 0.4278\n",
      "  - \"to\": 0.4236\n",
      "  - \"'\": 0.4622\n",
      "  - \"a\": 0.4549\n",
      "  - \")\": 0.4218\n",
      "  - \"(\": 0.4034\n",
      "  - \"is\": 0.5110\n",
      "  - \"s\": 0.5869\n",
      "  - \"for\": 0.4705\n",
      "  - \"was\": 0.5110\n",
      "  - \"on\": 0.4229\n",
      "  - \"that\": 0.5234\n",
      "  - \"as\": 0.6351\n",
      "  - \"it\": 0.4794\n",
      "  - \"with\": 0.4862\n",
      "  - \"by\": 0.4147\n",
      "  - \"\"\": 0.4412\n",
      "  - \"at\": 0.4144\n",
      "  - \"he\": 0.3814\n",
      "  - \"from\": 0.3729\n",
      "  - \"be\": 0.5834\n",
      "  - \"this\": 0.4542\n",
      "  - \"i\": 1.0000\n",
      "  - \"an\": 0.4463\n",
      "  - \"his\": 0.3963\n",
      "  - \"are\": 0.5231\n",
      "  - \"not\": 0.3886\n",
      "  - \"has\": 0.5564\n",
      "  - \"have\": 0.5548\n",
      "  - \"but\": 0.5398\n",
      "  - \"or\": 0.2680\n",
      "  - \"utc\": 0.2628\n",
      "  - \"which\": 0.5698\n",
      "  - \"were\": 0.5108\n",
      "  - \"–\": 0.3195\n",
      "  - \"said\": 0.4997\n",
      "  - \"they\": 0.3825\n",
      "  - \"also\": 0.5579\n",
      "  - \"one\": 0.6814\n",
      "  - \"who\": 0.3564\n",
      "  - \"had\": 0.5564\n",
      "  - \"talk\": 0.5091\n",
      "  - \"new\": 0.5310\n",
      "  - \"their\": 0.4224\n",
      "\n",
      "Similarities with \"an\":\n",
      "  - \",\": 0.4290\n",
      "  - \"the\": 0.5235\n",
      "  - \".\": 0.4060\n",
      "  - \"of\": 0.4119\n",
      "  - \"-\": 0.3810\n",
      "  - \"and\": 0.4609\n",
      "  - \"in\": 0.1556\n",
      "  - \"to\": 0.3668\n",
      "  - \"'\": 0.4047\n",
      "  - \"a\": 0.1562\n",
      "  - \")\": 0.3219\n",
      "  - \"(\": 0.3330\n",
      "  - \"is\": 0.3158\n",
      "  - \"s\": 0.3567\n",
      "  - \"for\": 0.3802\n",
      "  - \"was\": 0.3157\n",
      "  - \"on\": 0.3135\n",
      "  - \"that\": 0.4072\n",
      "  - \"as\": 0.3423\n",
      "  - \"it\": 0.4183\n",
      "  - \"with\": 0.3966\n",
      "  - \"by\": 0.2476\n",
      "  - \"\"\": 0.2753\n",
      "  - \"at\": 0.1571\n",
      "  - \"he\": 0.1098\n",
      "  - \"from\": 0.3671\n",
      "  - \"be\": 0.3209\n",
      "  - \"this\": 0.3515\n",
      "  - \"i\": 0.4463\n",
      "  - \"an\": 1.0000\n",
      "  - \"his\": 0.3208\n",
      "  - \"are\": 0.3254\n",
      "  - \"not\": 0.3023\n",
      "  - \"has\": 0.3457\n",
      "  - \"have\": 0.3304\n",
      "  - \"but\": 0.3720\n",
      "  - \"or\": 0.2132\n",
      "  - \"utc\": 0.1510\n",
      "  - \"which\": 0.4345\n",
      "  - \"were\": 0.3154\n",
      "  - \"–\": 0.2469\n",
      "  - \"said\": 0.3186\n",
      "  - \"they\": 0.2894\n",
      "  - \"also\": 0.3810\n",
      "  - \"one\": 0.2965\n",
      "  - \"who\": 0.3418\n",
      "  - \"had\": 0.3456\n",
      "  - \"talk\": 0.3273\n",
      "  - \"new\": 0.3415\n",
      "  - \"their\": 0.3010\n",
      "\n",
      "Similarities with \"his\":\n",
      "  - \",\": 0.4085\n",
      "  - \"the\": 0.4642\n",
      "  - \".\": 0.3845\n",
      "  - \"of\": 0.3677\n",
      "  - \"-\": 0.3274\n",
      "  - \"and\": 0.4821\n",
      "  - \"in\": 0.1190\n",
      "  - \"to\": 0.3972\n",
      "  - \"'\": 0.2922\n",
      "  - \"a\": 0.1459\n",
      "  - \")\": 0.1946\n",
      "  - \"(\": 0.2103\n",
      "  - \"is\": 0.2738\n",
      "  - \"s\": 0.2634\n",
      "  - \"for\": 0.3596\n",
      "  - \"was\": 0.2740\n",
      "  - \"on\": 0.3055\n",
      "  - \"that\": 0.3790\n",
      "  - \"as\": 0.2753\n",
      "  - \"it\": 0.2834\n",
      "  - \"with\": 0.3652\n",
      "  - \"by\": 0.3263\n",
      "  - \"\"\": 0.3284\n",
      "  - \"at\": 0.1479\n",
      "  - \"he\": 0.1046\n",
      "  - \"from\": 0.3798\n",
      "  - \"be\": 0.2693\n",
      "  - \"this\": 0.3377\n",
      "  - \"i\": 0.3963\n",
      "  - \"an\": 0.3208\n",
      "  - \"his\": 1.0000\n",
      "  - \"are\": 0.2782\n",
      "  - \"not\": 0.1874\n",
      "  - \"has\": 0.3747\n",
      "  - \"have\": 0.3817\n",
      "  - \"but\": 0.3366\n",
      "  - \"or\": 0.2411\n",
      "  - \"utc\": 0.1727\n",
      "  - \"which\": 0.4056\n",
      "  - \"were\": 0.2738\n",
      "  - \"–\": 0.2412\n",
      "  - \"said\": 0.2885\n",
      "  - \"they\": 0.3635\n",
      "  - \"also\": 0.3798\n",
      "  - \"one\": 0.3791\n",
      "  - \"who\": 0.4254\n",
      "  - \"had\": 0.3748\n",
      "  - \"talk\": 0.3329\n",
      "  - \"new\": 0.3720\n",
      "  - \"their\": 0.5999\n",
      "\n",
      "Similarities with \"are\":\n",
      "  - \",\": 0.3950\n",
      "  - \"the\": 0.4913\n",
      "  - \".\": 0.4708\n",
      "  - \"of\": 0.3708\n",
      "  - \"-\": 0.3327\n",
      "  - \"and\": 0.4188\n",
      "  - \"in\": 0.2883\n",
      "  - \"to\": 0.4281\n",
      "  - \"'\": 0.3560\n",
      "  - \"a\": 0.2525\n",
      "  - \")\": 0.2839\n",
      "  - \"(\": 0.3317\n",
      "  - \"is\": 0.9983\n",
      "  - \"s\": 0.4071\n",
      "  - \"for\": 0.3947\n",
      "  - \"was\": 0.9983\n",
      "  - \"on\": 0.3042\n",
      "  - \"that\": 0.5557\n",
      "  - \"as\": 0.4285\n",
      "  - \"it\": 0.4832\n",
      "  - \"with\": 0.3686\n",
      "  - \"by\": 0.3944\n",
      "  - \"\"\": 0.3478\n",
      "  - \"at\": 0.2028\n",
      "  - \"he\": 0.2173\n",
      "  - \"from\": 0.3031\n",
      "  - \"be\": 0.7334\n",
      "  - \"this\": 0.4887\n",
      "  - \"i\": 0.5231\n",
      "  - \"an\": 0.3254\n",
      "  - \"his\": 0.2782\n",
      "  - \"are\": 1.0000\n",
      "  - \"not\": 0.3628\n",
      "  - \"has\": 0.7255\n",
      "  - \"have\": 0.6835\n",
      "  - \"but\": 0.5270\n",
      "  - \"or\": 0.1887\n",
      "  - \"utc\": 0.2633\n",
      "  - \"which\": 0.4941\n",
      "  - \"were\": 0.9983\n",
      "  - \"–\": 0.1739\n",
      "  - \"said\": 0.5895\n",
      "  - \"they\": 0.4682\n",
      "  - \"also\": 0.5268\n",
      "  - \"one\": 0.4477\n",
      "  - \"who\": 0.2515\n",
      "  - \"had\": 0.7254\n",
      "  - \"talk\": 0.4440\n",
      "  - \"new\": 0.4270\n",
      "  - \"their\": 0.4379\n",
      "\n",
      "Similarities with \"not\":\n",
      "  - \",\": 0.3820\n",
      "  - \"the\": 0.3055\n",
      "  - \".\": 0.3738\n",
      "  - \"of\": 0.3028\n",
      "  - \"-\": 0.3788\n",
      "  - \"and\": 0.3481\n",
      "  - \"in\": 0.1372\n",
      "  - \"to\": 0.2775\n",
      "  - \"'\": 0.3107\n",
      "  - \"a\": 0.1746\n",
      "  - \")\": 0.2986\n",
      "  - \"(\": 0.2930\n",
      "  - \"is\": 0.3578\n",
      "  - \"s\": 0.2645\n",
      "  - \"for\": 0.3491\n",
      "  - \"was\": 0.3577\n",
      "  - \"on\": 0.1725\n",
      "  - \"that\": 0.3602\n",
      "  - \"as\": 0.2999\n",
      "  - \"it\": 0.2568\n",
      "  - \"with\": 0.3156\n",
      "  - \"by\": 0.2339\n",
      "  - \"\"\": 0.1399\n",
      "  - \"at\": 0.2261\n",
      "  - \"he\": 0.1312\n",
      "  - \"from\": 0.2659\n",
      "  - \"be\": 0.3684\n",
      "  - \"this\": 0.3439\n",
      "  - \"i\": 0.3886\n",
      "  - \"an\": 0.3023\n",
      "  - \"his\": 0.1874\n",
      "  - \"are\": 0.3628\n",
      "  - \"not\": 1.0000\n",
      "  - \"has\": 0.3585\n",
      "  - \"have\": 0.3197\n",
      "  - \"but\": 0.4109\n",
      "  - \"or\": 0.1481\n",
      "  - \"utc\": 0.2526\n",
      "  - \"which\": 0.3695\n",
      "  - \"were\": 0.3576\n",
      "  - \"–\": 0.1529\n",
      "  - \"said\": 0.3162\n",
      "  - \"they\": 0.2695\n",
      "  - \"also\": 0.3773\n",
      "  - \"one\": 0.2280\n",
      "  - \"who\": 0.2458\n",
      "  - \"had\": 0.3583\n",
      "  - \"talk\": 0.2725\n",
      "  - \"new\": 0.2613\n",
      "  - \"their\": 0.2851\n",
      "\n",
      "Similarities with \"has\":\n",
      "  - \",\": 0.4384\n",
      "  - \"the\": 0.5026\n",
      "  - \".\": 0.4949\n",
      "  - \"of\": 0.4317\n",
      "  - \"-\": 0.3885\n",
      "  - \"and\": 0.5328\n",
      "  - \"in\": 0.3017\n",
      "  - \"to\": 0.5111\n",
      "  - \"'\": 0.3937\n",
      "  - \"a\": 0.2867\n",
      "  - \")\": 0.3401\n",
      "  - \"(\": 0.3493\n",
      "  - \"is\": 0.7213\n",
      "  - \"s\": 0.4155\n",
      "  - \"for\": 0.4731\n",
      "  - \"was\": 0.7213\n",
      "  - \"on\": 0.3678\n",
      "  - \"that\": 0.6088\n",
      "  - \"as\": 0.4605\n",
      "  - \"it\": 0.4526\n",
      "  - \"with\": 0.4983\n",
      "  - \"by\": 0.5067\n",
      "  - \"\"\": 0.3738\n",
      "  - \"at\": 0.2564\n",
      "  - \"he\": 0.2410\n",
      "  - \"from\": 0.4002\n",
      "  - \"be\": 0.7296\n",
      "  - \"this\": 0.4839\n",
      "  - \"i\": 0.5564\n",
      "  - \"an\": 0.3457\n",
      "  - \"his\": 0.3747\n",
      "  - \"are\": 0.7255\n",
      "  - \"not\": 0.3585\n",
      "  - \"has\": 1.0000\n",
      "  - \"have\": 0.8997\n",
      "  - \"but\": 0.5927\n",
      "  - \"or\": 0.2261\n",
      "  - \"utc\": 0.2927\n",
      "  - \"which\": 0.5153\n",
      "  - \"were\": 0.7214\n",
      "  - \"–\": 0.2297\n",
      "  - \"said\": 0.6696\n",
      "  - \"they\": 0.5599\n",
      "  - \"also\": 0.6235\n",
      "  - \"one\": 0.4413\n",
      "  - \"who\": 0.3782\n",
      "  - \"had\": 1.0000\n",
      "  - \"talk\": 0.5572\n",
      "  - \"new\": 0.4962\n",
      "  - \"their\": 0.5452\n",
      "\n",
      "Similarities with \"have\":\n",
      "  - \",\": 0.4196\n",
      "  - \"the\": 0.4697\n",
      "  - \".\": 0.4588\n",
      "  - \"of\": 0.4164\n",
      "  - \"-\": 0.3748\n",
      "  - \"and\": 0.4990\n",
      "  - \"in\": 0.3185\n",
      "  - \"to\": 0.5137\n",
      "  - \"'\": 0.3688\n",
      "  - \"a\": 0.3176\n",
      "  - \")\": 0.3187\n",
      "  - \"(\": 0.3200\n",
      "  - \"is\": 0.6807\n",
      "  - \"s\": 0.4054\n",
      "  - \"for\": 0.4587\n",
      "  - \"was\": 0.6807\n",
      "  - \"on\": 0.3202\n",
      "  - \"that\": 0.5443\n",
      "  - \"as\": 0.4739\n",
      "  - \"it\": 0.3939\n",
      "  - \"with\": 0.4656\n",
      "  - \"by\": 0.4905\n",
      "  - \"\"\": 0.3895\n",
      "  - \"at\": 0.2486\n",
      "  - \"he\": 0.2519\n",
      "  - \"from\": 0.3590\n",
      "  - \"be\": 0.7328\n",
      "  - \"this\": 0.4002\n",
      "  - \"i\": 0.5548\n",
      "  - \"an\": 0.3304\n",
      "  - \"his\": 0.3817\n",
      "  - \"are\": 0.6835\n",
      "  - \"not\": 0.3197\n",
      "  - \"has\": 0.8997\n",
      "  - \"have\": 1.0000\n",
      "  - \"but\": 0.5562\n",
      "  - \"or\": 0.2716\n",
      "  - \"utc\": 0.2413\n",
      "  - \"which\": 0.4564\n",
      "  - \"were\": 0.6806\n",
      "  - \"–\": 0.2194\n",
      "  - \"said\": 0.6683\n",
      "  - \"they\": 0.4922\n",
      "  - \"also\": 0.5956\n",
      "  - \"one\": 0.4623\n",
      "  - \"who\": 0.3333\n",
      "  - \"had\": 0.8998\n",
      "  - \"talk\": 0.6051\n",
      "  - \"new\": 0.5264\n",
      "  - \"their\": 0.5227\n",
      "\n",
      "Similarities with \"but\":\n",
      "  - \",\": 0.3880\n",
      "  - \"the\": 0.4674\n",
      "  - \".\": 0.4326\n",
      "  - \"of\": 0.4082\n",
      "  - \"-\": 0.3707\n",
      "  - \"and\": 0.4163\n",
      "  - \"in\": 0.2775\n",
      "  - \"to\": 0.4539\n",
      "  - \"'\": 0.4280\n",
      "  - \"a\": 0.2807\n",
      "  - \")\": 0.3450\n",
      "  - \"(\": 0.3250\n",
      "  - \"is\": 0.5200\n",
      "  - \"s\": 0.4198\n",
      "  - \"for\": 0.4333\n",
      "  - \"was\": 0.5199\n",
      "  - \"on\": 0.3342\n",
      "  - \"that\": 0.6550\n",
      "  - \"as\": 0.4687\n",
      "  - \"it\": 0.5003\n",
      "  - \"with\": 0.3929\n",
      "  - \"by\": 0.5585\n",
      "  - \"\"\": 0.3549\n",
      "  - \"at\": 0.2445\n",
      "  - \"he\": 0.2141\n",
      "  - \"from\": 0.3763\n",
      "  - \"be\": 0.5171\n",
      "  - \"this\": 0.5257\n",
      "  - \"i\": 0.5398\n",
      "  - \"an\": 0.3720\n",
      "  - \"his\": 0.3366\n",
      "  - \"are\": 0.5270\n",
      "  - \"not\": 0.4109\n",
      "  - \"has\": 0.5927\n",
      "  - \"have\": 0.5562\n",
      "  - \"but\": 1.0000\n",
      "  - \"or\": 0.1609\n",
      "  - \"utc\": 0.3201\n",
      "  - \"which\": 0.5267\n",
      "  - \"were\": 0.5198\n",
      "  - \"–\": 0.2145\n",
      "  - \"said\": 0.6658\n",
      "  - \"they\": 0.4721\n",
      "  - \"also\": 0.7090\n",
      "  - \"one\": 0.4112\n",
      "  - \"who\": 0.3546\n",
      "  - \"had\": 0.5927\n",
      "  - \"talk\": 0.4710\n",
      "  - \"new\": 0.4345\n",
      "  - \"their\": 0.4198\n",
      "\n",
      "Similarities with \"or\":\n",
      "  - \",\": 0.2505\n",
      "  - \"the\": 0.2330\n",
      "  - \".\": 0.2369\n",
      "  - \"of\": 0.2291\n",
      "  - \"-\": 0.1981\n",
      "  - \"and\": 0.2170\n",
      "  - \"in\": 0.1555\n",
      "  - \"to\": 0.2262\n",
      "  - \"'\": 0.1373\n",
      "  - \"a\": 0.2404\n",
      "  - \")\": 0.1840\n",
      "  - \"(\": 0.1788\n",
      "  - \"is\": 0.1870\n",
      "  - \"s\": 0.2151\n",
      "  - \"for\": 0.1720\n",
      "  - \"was\": 0.1871\n",
      "  - \"on\": 0.0962\n",
      "  - \"that\": 0.1472\n",
      "  - \"as\": 0.2816\n",
      "  - \"it\": 0.1316\n",
      "  - \"with\": 0.1877\n",
      "  - \"by\": 0.1664\n",
      "  - \"\"\": 0.1669\n",
      "  - \"at\": 0.1631\n",
      "  - \"he\": 0.1906\n",
      "  - \"from\": 0.1795\n",
      "  - \"be\": 0.2005\n",
      "  - \"this\": 0.1316\n",
      "  - \"i\": 0.2680\n",
      "  - \"an\": 0.2132\n",
      "  - \"his\": 0.2411\n",
      "  - \"are\": 0.1887\n",
      "  - \"not\": 0.1481\n",
      "  - \"has\": 0.2261\n",
      "  - \"have\": 0.2716\n",
      "  - \"but\": 0.1609\n",
      "  - \"or\": 1.0000\n",
      "  - \"utc\": 0.0585\n",
      "  - \"which\": 0.1611\n",
      "  - \"were\": 0.1869\n",
      "  - \"–\": 0.1512\n",
      "  - \"said\": 0.1575\n",
      "  - \"they\": 0.1396\n",
      "  - \"also\": 0.1947\n",
      "  - \"one\": 0.1494\n",
      "  - \"who\": 0.1733\n",
      "  - \"had\": 0.2261\n",
      "  - \"talk\": 0.2565\n",
      "  - \"new\": 0.2344\n",
      "  - \"their\": 0.1260\n",
      "\n",
      "Similarities with \"utc\":\n",
      "  - \",\": 0.3256\n",
      "  - \"the\": 0.2050\n",
      "  - \".\": 0.3789\n",
      "  - \"of\": 0.1789\n",
      "  - \"-\": 0.3464\n",
      "  - \"and\": 0.2434\n",
      "  - \"in\": 0.1033\n",
      "  - \"to\": 0.2090\n",
      "  - \"'\": 0.2767\n",
      "  - \"a\": 0.2056\n",
      "  - \")\": 0.4105\n",
      "  - \"(\": 0.4313\n",
      "  - \"is\": 0.2591\n",
      "  - \"s\": 0.2473\n",
      "  - \"for\": 0.2402\n",
      "  - \"was\": 0.2590\n",
      "  - \"on\": 0.1040\n",
      "  - \"that\": 0.2412\n",
      "  - \"as\": 0.2338\n",
      "  - \"it\": 0.2442\n",
      "  - \"with\": 0.1654\n",
      "  - \"by\": 0.2030\n",
      "  - \"\"\": 0.2090\n",
      "  - \"at\": 0.1675\n",
      "  - \"he\": 0.1165\n",
      "  - \"from\": 0.1741\n",
      "  - \"be\": 0.1780\n",
      "  - \"this\": 0.4021\n",
      "  - \"i\": 0.2628\n",
      "  - \"an\": 0.1510\n",
      "  - \"his\": 0.1727\n",
      "  - \"are\": 0.2633\n",
      "  - \"not\": 0.2526\n",
      "  - \"has\": 0.2927\n",
      "  - \"have\": 0.2413\n",
      "  - \"but\": 0.3201\n",
      "  - \"or\": 0.0585\n",
      "  - \"utc\": 1.0000\n",
      "  - \"which\": 0.2403\n",
      "  - \"were\": 0.2589\n",
      "  - \"–\": 0.2553\n",
      "  - \"said\": 0.3227\n",
      "  - \"they\": 0.1739\n",
      "  - \"also\": 0.2712\n",
      "  - \"one\": 0.1986\n",
      "  - \"who\": 0.2416\n",
      "  - \"had\": 0.2925\n",
      "  - \"talk\": 0.3404\n",
      "  - \"new\": 0.1797\n",
      "  - \"their\": 0.1598\n",
      "\n",
      "Similarities with \"which\":\n",
      "  - \",\": 0.3898\n",
      "  - \"the\": 0.6465\n",
      "  - \".\": 0.4946\n",
      "  - \"of\": 0.5006\n",
      "  - \"-\": 0.3681\n",
      "  - \"and\": 0.6658\n",
      "  - \"in\": 0.3084\n",
      "  - \"to\": 0.4803\n",
      "  - \"'\": 0.3376\n",
      "  - \"a\": 0.2329\n",
      "  - \")\": 0.3048\n",
      "  - \"(\": 0.2855\n",
      "  - \"is\": 0.4842\n",
      "  - \"s\": 0.4184\n",
      "  - \"for\": 0.4294\n",
      "  - \"was\": 0.4842\n",
      "  - \"on\": 0.4264\n",
      "  - \"that\": 0.7366\n",
      "  - \"as\": 0.4314\n",
      "  - \"it\": 0.5677\n",
      "  - \"with\": 0.5273\n",
      "  - \"by\": 0.3886\n",
      "  - \"\"\": 0.3948\n",
      "  - \"at\": 0.1447\n",
      "  - \"he\": 0.1546\n",
      "  - \"from\": 0.4547\n",
      "  - \"be\": 0.4688\n",
      "  - \"this\": 0.5679\n",
      "  - \"i\": 0.5698\n",
      "  - \"an\": 0.4345\n",
      "  - \"his\": 0.4056\n",
      "  - \"are\": 0.4941\n",
      "  - \"not\": 0.3695\n",
      "  - \"has\": 0.5153\n",
      "  - \"have\": 0.4564\n",
      "  - \"but\": 0.5267\n",
      "  - \"or\": 0.1611\n",
      "  - \"utc\": 0.2403\n",
      "  - \"which\": 1.0000\n",
      "  - \"were\": 0.4841\n",
      "  - \"–\": 0.2389\n",
      "  - \"said\": 0.4043\n",
      "  - \"they\": 0.4494\n",
      "  - \"also\": 0.5732\n",
      "  - \"one\": 0.4195\n",
      "  - \"who\": 0.4463\n",
      "  - \"had\": 0.5152\n",
      "  - \"talk\": 0.3774\n",
      "  - \"new\": 0.4570\n",
      "  - \"their\": 0.4440\n",
      "\n",
      "Similarities with \"were\":\n",
      "  - \",\": 0.3814\n",
      "  - \"the\": 0.4823\n",
      "  - \".\": 0.4527\n",
      "  - \"of\": 0.3634\n",
      "  - \"-\": 0.3123\n",
      "  - \"and\": 0.4117\n",
      "  - \"in\": 0.2766\n",
      "  - \"to\": 0.4222\n",
      "  - \"'\": 0.3448\n",
      "  - \"a\": 0.2387\n",
      "  - \")\": 0.2717\n",
      "  - \"(\": 0.3202\n",
      "  - \"is\": 1.0000\n",
      "  - \"s\": 0.3924\n",
      "  - \"for\": 0.3898\n",
      "  - \"was\": 1.0000\n",
      "  - \"on\": 0.2943\n",
      "  - \"that\": 0.5505\n",
      "  - \"as\": 0.4139\n",
      "  - \"it\": 0.4770\n",
      "  - \"with\": 0.3602\n",
      "  - \"by\": 0.3869\n",
      "  - \"\"\": 0.3426\n",
      "  - \"at\": 0.1973\n",
      "  - \"he\": 0.2124\n",
      "  - \"from\": 0.2969\n",
      "  - \"be\": 0.7308\n",
      "  - \"this\": 0.4821\n",
      "  - \"i\": 0.5108\n",
      "  - \"an\": 0.3154\n",
      "  - \"his\": 0.2738\n",
      "  - \"are\": 0.9983\n",
      "  - \"not\": 0.3576\n",
      "  - \"has\": 0.7214\n",
      "  - \"have\": 0.6806\n",
      "  - \"but\": 0.5198\n",
      "  - \"or\": 0.1869\n",
      "  - \"utc\": 0.2589\n",
      "  - \"which\": 0.4841\n",
      "  - \"were\": 1.0000\n",
      "  - \"–\": 0.1667\n",
      "  - \"said\": 0.5827\n",
      "  - \"they\": 0.4647\n",
      "  - \"also\": 0.5163\n",
      "  - \"one\": 0.4360\n",
      "  - \"who\": 0.2469\n",
      "  - \"had\": 0.7213\n",
      "  - \"talk\": 0.4388\n",
      "  - \"new\": 0.4208\n",
      "  - \"their\": 0.4333\n",
      "\n",
      "Similarities with \"–\":\n",
      "  - \",\": 0.4485\n",
      "  - \"the\": 0.3194\n",
      "  - \".\": 0.4081\n",
      "  - \"of\": 0.3121\n",
      "  - \"-\": 0.4731\n",
      "  - \"and\": 0.4187\n",
      "  - \"in\": 0.1124\n",
      "  - \"to\": 0.2479\n",
      "  - \"'\": 0.4101\n",
      "  - \"a\": 0.1771\n",
      "  - \")\": 0.5241\n",
      "  - \"(\": 0.5239\n",
      "  - \"is\": 0.1668\n",
      "  - \"s\": 0.2965\n",
      "  - \"for\": 0.3485\n",
      "  - \"was\": 0.1669\n",
      "  - \"on\": 0.1894\n",
      "  - \"that\": 0.1914\n",
      "  - \"as\": 0.2428\n",
      "  - \"it\": 0.1565\n",
      "  - \"with\": 0.2693\n",
      "  - \"by\": 0.3194\n",
      "  - \"\"\": 0.2880\n",
      "  - \"at\": 0.0870\n",
      "  - \"he\": 0.0735\n",
      "  - \"from\": 0.3096\n",
      "  - \"be\": 0.1964\n",
      "  - \"this\": 0.1735\n",
      "  - \"i\": 0.3195\n",
      "  - \"an\": 0.2469\n",
      "  - \"his\": 0.2412\n",
      "  - \"are\": 0.1739\n",
      "  - \"not\": 0.1529\n",
      "  - \"has\": 0.2297\n",
      "  - \"have\": 0.2194\n",
      "  - \"but\": 0.2145\n",
      "  - \"or\": 0.1512\n",
      "  - \"utc\": 0.2553\n",
      "  - \"which\": 0.2389\n",
      "  - \"were\": 0.1667\n",
      "  - \"–\": 1.0000\n",
      "  - \"said\": 0.2417\n",
      "  - \"they\": 0.1853\n",
      "  - \"also\": 0.2502\n",
      "  - \"one\": 0.2895\n",
      "  - \"who\": 0.3039\n",
      "  - \"had\": 0.2297\n",
      "  - \"talk\": 0.3015\n",
      "  - \"new\": 0.2158\n",
      "  - \"their\": 0.2003\n",
      "\n",
      "Similarities with \"said\":\n",
      "  - \",\": 0.3963\n",
      "  - \"the\": 0.3737\n",
      "  - \".\": 0.4198\n",
      "  - \"of\": 0.3320\n",
      "  - \"-\": 0.3787\n",
      "  - \"and\": 0.3915\n",
      "  - \"in\": 0.2414\n",
      "  - \"to\": 0.4005\n",
      "  - \"'\": 0.4038\n",
      "  - \"a\": 0.2871\n",
      "  - \")\": 0.3232\n",
      "  - \"(\": 0.3396\n",
      "  - \"is\": 0.5828\n",
      "  - \"s\": 0.4118\n",
      "  - \"for\": 0.3358\n",
      "  - \"was\": 0.5827\n",
      "  - \"on\": 0.2868\n",
      "  - \"that\": 0.5430\n",
      "  - \"as\": 0.4531\n",
      "  - \"it\": 0.4098\n",
      "  - \"with\": 0.3315\n",
      "  - \"by\": 0.4435\n",
      "  - \"\"\": 0.4387\n",
      "  - \"at\": 0.2932\n",
      "  - \"he\": 0.2361\n",
      "  - \"from\": 0.3545\n",
      "  - \"be\": 0.6312\n",
      "  - \"this\": 0.4210\n",
      "  - \"i\": 0.4997\n",
      "  - \"an\": 0.3186\n",
      "  - \"his\": 0.2885\n",
      "  - \"are\": 0.5895\n",
      "  - \"not\": 0.3162\n",
      "  - \"has\": 0.6696\n",
      "  - \"have\": 0.6683\n",
      "  - \"but\": 0.6658\n",
      "  - \"or\": 0.1575\n",
      "  - \"utc\": 0.3227\n",
      "  - \"which\": 0.4043\n",
      "  - \"were\": 0.5827\n",
      "  - \"–\": 0.2417\n",
      "  - \"said\": 1.0000\n",
      "  - \"they\": 0.4272\n",
      "  - \"also\": 0.6484\n",
      "  - \"one\": 0.4096\n",
      "  - \"who\": 0.3536\n",
      "  - \"had\": 0.6697\n",
      "  - \"talk\": 0.6535\n",
      "  - \"new\": 0.3497\n",
      "  - \"their\": 0.3254\n",
      "\n",
      "Similarities with \"they\":\n",
      "  - \",\": 0.3911\n",
      "  - \"the\": 0.4527\n",
      "  - \".\": 0.3677\n",
      "  - \"of\": 0.3076\n",
      "  - \"-\": 0.3213\n",
      "  - \"and\": 0.4807\n",
      "  - \"in\": 0.1494\n",
      "  - \"to\": 0.4824\n",
      "  - \"'\": 0.3221\n",
      "  - \"a\": 0.1446\n",
      "  - \")\": 0.2250\n",
      "  - \"(\": 0.2134\n",
      "  - \"is\": 0.4645\n",
      "  - \"s\": 0.2846\n",
      "  - \"for\": 0.3271\n",
      "  - \"was\": 0.4646\n",
      "  - \"on\": 0.2906\n",
      "  - \"that\": 0.5066\n",
      "  - \"as\": 0.2947\n",
      "  - \"it\": 0.4417\n",
      "  - \"with\": 0.3914\n",
      "  - \"by\": 0.3377\n",
      "  - \"\"\": 0.2696\n",
      "  - \"at\": 0.1537\n",
      "  - \"he\": 0.1400\n",
      "  - \"from\": 0.3252\n",
      "  - \"be\": 0.4338\n",
      "  - \"this\": 0.3588\n",
      "  - \"i\": 0.3825\n",
      "  - \"an\": 0.2894\n",
      "  - \"his\": 0.3635\n",
      "  - \"are\": 0.4682\n",
      "  - \"not\": 0.2695\n",
      "  - \"has\": 0.5599\n",
      "  - \"have\": 0.4922\n",
      "  - \"but\": 0.4721\n",
      "  - \"or\": 0.1396\n",
      "  - \"utc\": 0.1739\n",
      "  - \"which\": 0.4494\n",
      "  - \"were\": 0.4647\n",
      "  - \"–\": 0.1853\n",
      "  - \"said\": 0.4272\n",
      "  - \"they\": 1.0000\n",
      "  - \"also\": 0.4445\n",
      "  - \"one\": 0.2670\n",
      "  - \"who\": 0.4517\n",
      "  - \"had\": 0.5600\n",
      "  - \"talk\": 0.3484\n",
      "  - \"new\": 0.4113\n",
      "  - \"their\": 0.6740\n",
      "\n",
      "Similarities with \"also\":\n",
      "  - \",\": 0.4595\n",
      "  - \"the\": 0.5038\n",
      "  - \".\": 0.5254\n",
      "  - \"of\": 0.4768\n",
      "  - \"-\": 0.4504\n",
      "  - \"and\": 0.5930\n",
      "  - \"in\": 0.2825\n",
      "  - \"to\": 0.4573\n",
      "  - \"'\": 0.3988\n",
      "  - \"a\": 0.2827\n",
      "  - \")\": 0.3506\n",
      "  - \"(\": 0.3229\n",
      "  - \"is\": 0.5164\n",
      "  - \"s\": 0.4226\n",
      "  - \"for\": 0.4483\n",
      "  - \"was\": 0.5163\n",
      "  - \"on\": 0.4718\n",
      "  - \"that\": 0.6204\n",
      "  - \"as\": 0.5190\n",
      "  - \"it\": 0.4659\n",
      "  - \"with\": 0.4747\n",
      "  - \"by\": 0.5549\n",
      "  - \"\"\": 0.3692\n",
      "  - \"at\": 0.2797\n",
      "  - \"he\": 0.2368\n",
      "  - \"from\": 0.4101\n",
      "  - \"be\": 0.5747\n",
      "  - \"this\": 0.4808\n",
      "  - \"i\": 0.5579\n",
      "  - \"an\": 0.3810\n",
      "  - \"his\": 0.3798\n",
      "  - \"are\": 0.5268\n",
      "  - \"not\": 0.3773\n",
      "  - \"has\": 0.6235\n",
      "  - \"have\": 0.5956\n",
      "  - \"but\": 0.7090\n",
      "  - \"or\": 0.1947\n",
      "  - \"utc\": 0.2712\n",
      "  - \"which\": 0.5732\n",
      "  - \"were\": 0.5163\n",
      "  - \"–\": 0.2502\n",
      "  - \"said\": 0.6484\n",
      "  - \"they\": 0.4445\n",
      "  - \"also\": 1.0000\n",
      "  - \"one\": 0.4365\n",
      "  - \"who\": 0.3858\n",
      "  - \"had\": 0.6234\n",
      "  - \"talk\": 0.5008\n",
      "  - \"new\": 0.4566\n",
      "  - \"their\": 0.3958\n",
      "\n",
      "Similarities with \"one\":\n",
      "  - \",\": 0.3827\n",
      "  - \"the\": 0.3915\n",
      "  - \".\": 0.4000\n",
      "  - \"of\": 0.3212\n",
      "  - \"-\": 0.3203\n",
      "  - \"and\": 0.4087\n",
      "  - \"in\": 0.3917\n",
      "  - \"to\": 0.2730\n",
      "  - \"'\": 0.2953\n",
      "  - \"a\": 0.3693\n",
      "  - \")\": 0.2512\n",
      "  - \"(\": 0.2469\n",
      "  - \"is\": 0.4361\n",
      "  - \"s\": 0.4774\n",
      "  - \"for\": 0.3632\n",
      "  - \"was\": 0.4361\n",
      "  - \"on\": 0.2771\n",
      "  - \"that\": 0.4020\n",
      "  - \"as\": 0.4738\n",
      "  - \"it\": 0.3020\n",
      "  - \"with\": 0.3555\n",
      "  - \"by\": 0.3009\n",
      "  - \"\"\": 0.5039\n",
      "  - \"at\": 0.2400\n",
      "  - \"he\": 0.2766\n",
      "  - \"from\": 0.2094\n",
      "  - \"be\": 0.5646\n",
      "  - \"this\": 0.3286\n",
      "  - \"i\": 0.6814\n",
      "  - \"an\": 0.2965\n",
      "  - \"his\": 0.3791\n",
      "  - \"are\": 0.4477\n",
      "  - \"not\": 0.2280\n",
      "  - \"has\": 0.4413\n",
      "  - \"have\": 0.4623\n",
      "  - \"but\": 0.4112\n",
      "  - \"or\": 0.1494\n",
      "  - \"utc\": 0.1986\n",
      "  - \"which\": 0.4195\n",
      "  - \"were\": 0.4360\n",
      "  - \"–\": 0.2895\n",
      "  - \"said\": 0.4096\n",
      "  - \"they\": 0.2670\n",
      "  - \"also\": 0.4365\n",
      "  - \"one\": 1.0000\n",
      "  - \"who\": 0.2848\n",
      "  - \"had\": 0.4413\n",
      "  - \"talk\": 0.4496\n",
      "  - \"new\": 0.5107\n",
      "  - \"their\": 0.3331\n",
      "\n",
      "Similarities with \"who\":\n",
      "  - \",\": 0.3217\n",
      "  - \"the\": 0.3617\n",
      "  - \".\": 0.3527\n",
      "  - \"of\": 0.3380\n",
      "  - \"-\": 0.2722\n",
      "  - \"and\": 0.4885\n",
      "  - \"in\": 0.0832\n",
      "  - \"to\": 0.3530\n",
      "  - \"'\": 0.3351\n",
      "  - \"a\": 0.1317\n",
      "  - \")\": 0.3488\n",
      "  - \"(\": 0.3307\n",
      "  - \"is\": 0.2469\n",
      "  - \"s\": 0.2279\n",
      "  - \"for\": 0.3697\n",
      "  - \"was\": 0.2470\n",
      "  - \"on\": 0.2743\n",
      "  - \"that\": 0.4302\n",
      "  - \"as\": 0.2627\n",
      "  - \"it\": 0.2633\n",
      "  - \"with\": 0.3918\n",
      "  - \"by\": 0.3325\n",
      "  - \"\"\": 0.2298\n",
      "  - \"at\": 0.1408\n",
      "  - \"he\": 0.0901\n",
      "  - \"from\": 0.3789\n",
      "  - \"be\": 0.2508\n",
      "  - \"this\": 0.2629\n",
      "  - \"i\": 0.3564\n",
      "  - \"an\": 0.3418\n",
      "  - \"his\": 0.4254\n",
      "  - \"are\": 0.2515\n",
      "  - \"not\": 0.2458\n",
      "  - \"has\": 0.3782\n",
      "  - \"have\": 0.3333\n",
      "  - \"but\": 0.3546\n",
      "  - \"or\": 0.1733\n",
      "  - \"utc\": 0.2416\n",
      "  - \"which\": 0.4463\n",
      "  - \"were\": 0.2469\n",
      "  - \"–\": 0.3039\n",
      "  - \"said\": 0.3536\n",
      "  - \"they\": 0.4517\n",
      "  - \"also\": 0.3858\n",
      "  - \"one\": 0.2848\n",
      "  - \"who\": 1.0000\n",
      "  - \"had\": 0.3783\n",
      "  - \"talk\": 0.3242\n",
      "  - \"new\": 0.3572\n",
      "  - \"their\": 0.3646\n",
      "\n",
      "Similarities with \"had\":\n",
      "  - \",\": 0.4383\n",
      "  - \"the\": 0.5026\n",
      "  - \".\": 0.4948\n",
      "  - \"of\": 0.4316\n",
      "  - \"-\": 0.3884\n",
      "  - \"and\": 0.5328\n",
      "  - \"in\": 0.3017\n",
      "  - \"to\": 0.5111\n",
      "  - \"'\": 0.3936\n",
      "  - \"a\": 0.2866\n",
      "  - \")\": 0.3399\n",
      "  - \"(\": 0.3491\n",
      "  - \"is\": 0.7212\n",
      "  - \"s\": 0.4155\n",
      "  - \"for\": 0.4730\n",
      "  - \"was\": 0.7212\n",
      "  - \"on\": 0.3678\n",
      "  - \"that\": 0.6087\n",
      "  - \"as\": 0.4604\n",
      "  - \"it\": 0.4525\n",
      "  - \"with\": 0.4983\n",
      "  - \"by\": 0.5067\n",
      "  - \"\"\": 0.3737\n",
      "  - \"at\": 0.2564\n",
      "  - \"he\": 0.2410\n",
      "  - \"from\": 0.4002\n",
      "  - \"be\": 0.7296\n",
      "  - \"this\": 0.4838\n",
      "  - \"i\": 0.5564\n",
      "  - \"an\": 0.3456\n",
      "  - \"his\": 0.3748\n",
      "  - \"are\": 0.7254\n",
      "  - \"not\": 0.3583\n",
      "  - \"has\": 1.0000\n",
      "  - \"have\": 0.8998\n",
      "  - \"but\": 0.5927\n",
      "  - \"or\": 0.2261\n",
      "  - \"utc\": 0.2925\n",
      "  - \"which\": 0.5152\n",
      "  - \"were\": 0.7213\n",
      "  - \"–\": 0.2297\n",
      "  - \"said\": 0.6697\n",
      "  - \"they\": 0.5600\n",
      "  - \"also\": 0.6234\n",
      "  - \"one\": 0.4413\n",
      "  - \"who\": 0.3783\n",
      "  - \"had\": 1.0000\n",
      "  - \"talk\": 0.5570\n",
      "  - \"new\": 0.4962\n",
      "  - \"their\": 0.5453\n",
      "\n",
      "Similarities with \"talk\":\n",
      "  - \",\": 0.5002\n",
      "  - \"the\": 0.4029\n",
      "  - \".\": 0.4511\n",
      "  - \"of\": 0.3811\n",
      "  - \"-\": 0.3888\n",
      "  - \"and\": 0.4190\n",
      "  - \"in\": 0.2621\n",
      "  - \"to\": 0.3547\n",
      "  - \"'\": 0.3855\n",
      "  - \"a\": 0.2882\n",
      "  - \")\": 0.3800\n",
      "  - \"(\": 0.3654\n",
      "  - \"is\": 0.4389\n",
      "  - \"s\": 0.4585\n",
      "  - \"for\": 0.2959\n",
      "  - \"was\": 0.4389\n",
      "  - \"on\": 0.3002\n",
      "  - \"that\": 0.4158\n",
      "  - \"as\": 0.4259\n",
      "  - \"it\": 0.3664\n",
      "  - \"with\": 0.3167\n",
      "  - \"by\": 0.3733\n",
      "  - \"\"\": 0.4546\n",
      "  - \"at\": 0.2297\n",
      "  - \"he\": 0.2412\n",
      "  - \"from\": 0.3230\n",
      "  - \"be\": 0.5520\n",
      "  - \"this\": 0.3718\n",
      "  - \"i\": 0.5091\n",
      "  - \"an\": 0.3273\n",
      "  - \"his\": 0.3329\n",
      "  - \"are\": 0.4440\n",
      "  - \"not\": 0.2725\n",
      "  - \"has\": 0.5572\n",
      "  - \"have\": 0.6051\n",
      "  - \"but\": 0.4710\n",
      "  - \"or\": 0.2565\n",
      "  - \"utc\": 0.3404\n",
      "  - \"which\": 0.3774\n",
      "  - \"were\": 0.4388\n",
      "  - \"–\": 0.3015\n",
      "  - \"said\": 0.6535\n",
      "  - \"they\": 0.3484\n",
      "  - \"also\": 0.5008\n",
      "  - \"one\": 0.4496\n",
      "  - \"who\": 0.3242\n",
      "  - \"had\": 0.5570\n",
      "  - \"talk\": 1.0000\n",
      "  - \"new\": 0.4661\n",
      "  - \"their\": 0.3046\n",
      "\n",
      "Similarities with \"new\":\n",
      "  - \",\": 0.4197\n",
      "  - \"the\": 0.4347\n",
      "  - \".\": 0.4260\n",
      "  - \"of\": 0.3665\n",
      "  - \"-\": 0.3479\n",
      "  - \"and\": 0.4898\n",
      "  - \"in\": 0.3667\n",
      "  - \"to\": 0.3804\n",
      "  - \"'\": 0.3170\n",
      "  - \"a\": 0.2816\n",
      "  - \")\": 0.2479\n",
      "  - \"(\": 0.2669\n",
      "  - \"is\": 0.4207\n",
      "  - \"s\": 0.4600\n",
      "  - \"for\": 0.3484\n",
      "  - \"was\": 0.4209\n",
      "  - \"on\": 0.3480\n",
      "  - \"that\": 0.4176\n",
      "  - \"as\": 0.4355\n",
      "  - \"it\": 0.3915\n",
      "  - \"with\": 0.3922\n",
      "  - \"by\": 0.3676\n",
      "  - \"\"\": 0.4277\n",
      "  - \"at\": 0.2436\n",
      "  - \"he\": 0.3060\n",
      "  - \"from\": 0.3601\n",
      "  - \"be\": 0.4306\n",
      "  - \"this\": 0.3471\n",
      "  - \"i\": 0.5310\n",
      "  - \"an\": 0.3415\n",
      "  - \"his\": 0.3720\n",
      "  - \"are\": 0.4270\n",
      "  - \"not\": 0.2613\n",
      "  - \"has\": 0.4962\n",
      "  - \"have\": 0.5264\n",
      "  - \"but\": 0.4345\n",
      "  - \"or\": 0.2344\n",
      "  - \"utc\": 0.1797\n",
      "  - \"which\": 0.4570\n",
      "  - \"were\": 0.4208\n",
      "  - \"–\": 0.2158\n",
      "  - \"said\": 0.3497\n",
      "  - \"they\": 0.4113\n",
      "  - \"also\": 0.4566\n",
      "  - \"one\": 0.5107\n",
      "  - \"who\": 0.3572\n",
      "  - \"had\": 0.4962\n",
      "  - \"talk\": 0.4661\n",
      "  - \"new\": 1.0000\n",
      "  - \"their\": 0.4085\n",
      "\n",
      "Similarities with \"their\":\n",
      "  - \",\": 0.3509\n",
      "  - \"the\": 0.5333\n",
      "  - \".\": 0.3642\n",
      "  - \"of\": 0.3765\n",
      "  - \"-\": 0.2973\n",
      "  - \"and\": 0.5092\n",
      "  - \"in\": 0.1554\n",
      "  - \"to\": 0.4696\n",
      "  - \"'\": 0.2767\n",
      "  - \"a\": 0.0989\n",
      "  - \")\": 0.1785\n",
      "  - \"(\": 0.1947\n",
      "  - \"is\": 0.4329\n",
      "  - \"s\": 0.2693\n",
      "  - \"for\": 0.3851\n",
      "  - \"was\": 0.4330\n",
      "  - \"on\": 0.3593\n",
      "  - \"that\": 0.4321\n",
      "  - \"as\": 0.2368\n",
      "  - \"it\": 0.3008\n",
      "  - \"with\": 0.4425\n",
      "  - \"by\": 0.3590\n",
      "  - \"\"\": 0.3309\n",
      "  - \"at\": 0.1039\n",
      "  - \"he\": 0.0817\n",
      "  - \"from\": 0.3191\n",
      "  - \"be\": 0.4431\n",
      "  - \"this\": 0.3742\n",
      "  - \"i\": 0.4224\n",
      "  - \"an\": 0.3010\n",
      "  - \"his\": 0.5999\n",
      "  - \"are\": 0.4379\n",
      "  - \"not\": 0.2851\n",
      "  - \"has\": 0.5452\n",
      "  - \"have\": 0.5227\n",
      "  - \"but\": 0.4198\n",
      "  - \"or\": 0.1260\n",
      "  - \"utc\": 0.1598\n",
      "  - \"which\": 0.4440\n",
      "  - \"were\": 0.4333\n",
      "  - \"–\": 0.2003\n",
      "  - \"said\": 0.3254\n",
      "  - \"they\": 0.6740\n",
      "  - \"also\": 0.3958\n",
      "  - \"one\": 0.3331\n",
      "  - \"who\": 0.3646\n",
      "  - \"had\": 0.5453\n",
      "  - \"talk\": 0.3046\n",
      "  - \"new\": 0.4085\n",
      "  - \"their\": 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_retrofitted_gensim_dict = convert_matrix_to_dict(subset_retrofitted_wordVecMat, subset_retrofitted_wordList)\n",
    "new_retrofitted_gensim_similarity_matrix = generate_cosine_similarity_matrix(new_retrofitted_gensim_dict)\n",
    "print_vec_similarities(wordList_gensim, new_retrofitted_gensim_similarity_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "French corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/French/word_embeddings/vecs100-linear-frwiki \n"
     ]
    }
   ],
   "source": [
    "wordVecs_FR = read_word_vecs(\"../data/French/word_embeddings/vecs100-linear-frwiki\")\n",
    "lexical_similarity = read_lexicon(\"../data/French/lexicon/rg65_french.txt\")\n",
    "output_file = \"../data/French/output_vectors/output_vectors.txt\"\n",
    "outFileName = output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_lexicon_FR(target_words, relation_types):\n",
    "    lexicon = {}\n",
    "        \n",
    "    for word in target_words:\n",
    "        related_words = []\n",
    "        word_synsets = wordnet.synsets(word)\n",
    "        \n",
    "        # Skip word if no synsets found\n",
    "        if not word_synsets:\n",
    "            continue\n",
    "\n",
    "        for syn in word_synsets:\n",
    "            for lemma in syn.lemmas('fra'):\n",
    "                if lemma.name() != word:\n",
    "                    if \"synonyms\" in relation_types:\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"antonyms\" in relation_types:\n",
    "                if syn.lemmas('fra')[0].antonyms():\n",
    "                    related_words.append(syn.lemmas()[0].antonyms()[0].name())\n",
    "            if \"hyponyms\" in relation_types:\n",
    "                for hypo in syn.hyponyms():\n",
    "                    for lemma in hypo.lemmas('fra'):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"hypernyms\" in relation_types:\n",
    "                for hyper in syn.hypernyms():\n",
    "                    for lemma in hyper.lemmas('fra'):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"meronyms\" in relation_types:\n",
    "                for part in syn.part_meronyms():\n",
    "                    for lemma in part.lemmas('fra'):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"holonyms\" in relation_types:\n",
    "                for whole in syn.part_holonyms():\n",
    "                    for lemma in whole.lemmas('fra'):\n",
    "                        related_words.append(lemma.name())\n",
    "            if \"homonyms\" in relation_types:\n",
    "                for lemma in syn.lemmas('fra'):\n",
    "                    if lemma.name() != word:\n",
    "                        homonyms = wordnet.lemmas(lemma.name())\n",
    "                        for homonym in homonyms:\n",
    "                            related_words.append(homonym.name())\n",
    "        lexicon[word] = related_words\n",
    "    return lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\ninan/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\ninan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4.zip/omw-1.4/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\ninan/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\ninan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[198], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neighbors_dict \u001b[39m=\u001b[39m get_wordnet_lexicon_FR(wordList, \u001b[39m\"\u001b[39;49m\u001b[39msynonyms\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[197], line 13\u001b[0m, in \u001b[0;36mget_wordnet_lexicon_FR\u001b[1;34m(target_words, relation_types)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m syn \u001b[39min\u001b[39;00m word_synsets:\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mfor\u001b[39;00m lemma \u001b[39min\u001b[39;00m syn\u001b[39m.\u001b[39;49mlemmas(\u001b[39m'\u001b[39;49m\u001b[39mfra\u001b[39;49m\u001b[39m'\u001b[39;49m):\n\u001b[0;32m     14\u001b[0m         \u001b[39mif\u001b[39;00m lemma\u001b[39m.\u001b[39mname() \u001b[39m!=\u001b[39m word:\n\u001b[0;32m     15\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msynonyms\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m relation_types:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:502\u001b[0m, in \u001b[0;36mSynset.lemmas\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m    500\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lemmas\n\u001b[0;32m    501\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name:\n\u001b[1;32m--> 502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wordnet_corpus_reader\u001b[39m.\u001b[39;49m_load_lang_data(lang)\n\u001b[0;32m    503\u001b[0m     lemmark \u001b[39m=\u001b[39m []\n\u001b[0;32m    504\u001b[0m     lemmy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlemma_names(lang)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1303\u001b[0m, in \u001b[0;36mWordNetCorpusReader._load_lang_data\u001b[1;34m(self, lang)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1302\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_omw_reader \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39momw_langs:\n\u001b[1;32m-> 1303\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_omw()\n\u001b[0;32m   1305\u001b[0m \u001b[39mif\u001b[39;00m lang \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlangs():\n\u001b[0;32m   1306\u001b[0m     \u001b[39mraise\u001b[39;00m WordNetError(\u001b[39m\"\u001b[39m\u001b[39mLanguage is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1338\u001b[0m, in \u001b[0;36mWordNetCorpusReader.add_omw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_omw\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m-> 1338\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_provs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_omw_reader)\n\u001b[0;32m   1339\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39momw_langs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprovenances\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\reader\\wordnet.py:1325\u001b[0m, in \u001b[0;36mWordNetCorpusReader.add_provs\u001b[1;34m(self, reader)\u001b[0m\n\u001b[0;32m   1323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_provs\u001b[39m(\u001b[39mself\u001b[39m, reader):\n\u001b[0;32m   1324\u001b[0m     \u001b[39m\"\"\"Add languages from Multilingual Wordnet to the provenance dictionary\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1325\u001b[0m     fileids \u001b[39m=\u001b[39m reader\u001b[39m.\u001b[39;49mfileids()\n\u001b[0;32m   1326\u001b[0m     \u001b[39mfor\u001b[39;00m fileid \u001b[39min\u001b[39;00m fileids:\n\u001b[0;32m   1327\u001b[0m         prov, langfile \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39msplit(fileid)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    122\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     82\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93momw-1.4\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('omw-1.4')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/omw-1.4\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\ninan/nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\share\\\\nltk_data'\n    - 'C:\\\\Program Files\\\\WindowsApps\\\\PythonSoftwareFoundation.Python.3.9_3.9.3568.0_x64__qbz5n2kfra8p0\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\ninan\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "neighbors_dict = get_wordnet_lexicon_FR(wordList, \"synonyms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordList_FR = get_embeddings_words(wordVecs_FR)\n",
    "wordVecMat_FR = convert_dict_to_matrix(wordVecs_FR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "retrieve_neighbors_embedding_matrix() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m neighbors_matrix_FR \u001b[39m=\u001b[39m retrieve_neighbors_embedding_matrix(wordVecMat_FR, wordList_FR, \u001b[39m\"\u001b[39;49m\u001b[39msynonyms\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfra\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;31mTypeError\u001b[0m: retrieve_neighbors_embedding_matrix() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "neighbors_matrix_FR = retrieve_neighbors_embedding_matrix(wordVecMat_FR, wordList_FR, \"synonyms\", \"fra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrofitted_wordVecs_FR, updates_FR= retrofitting_wordVecs_test(wordVecMat_FR, neighbors_matrix_FR, alpha=1, beta=1, nb_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cos_similarity = calculate_average_cosine_similarity(wordVecMat_FR, retrofitted_wordVecs_FR)\n",
    "avg_cos_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
