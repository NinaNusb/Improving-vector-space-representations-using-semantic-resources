{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Compute the similarity between the different embedding files"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Retrieve the necessary embeddings and lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read all the word vectors and normalize them '''\n",
    "def read_word_vecs(filename):\n",
    "  \"\"\"\n",
    "  - input: name of the file containing the word vectors\n",
    "  \"\"\"\n",
    "  wordVectors = {}\n",
    "  with open(filename, 'r', encoding='utf-8') as fileObject:\n",
    "    first_line = True\n",
    "    for line in fileObject:\n",
    "      line = line.strip().lower()\n",
    "      # Skip the first line\n",
    "      if first_line:\n",
    "        first_line =False\n",
    "        continue\n",
    "      # The first word is assumed to be the word itself, and the remaining words are assumed to be the components of the word vector\n",
    "      word = line.split()[0]\n",
    "      # initialize a numpy array of zeros with the same length as the word vector\n",
    "      wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
    "      for index, vecVal in enumerate(line.split()[1:]):\n",
    "        # assign the values in the numpy array to the corresponding components of the word vector\n",
    "        wordVectors[word][index] = float(vecVal)\n",
    "      ''' normalize weight vector '''\n",
    "      # divide each element by the square root of the sum of the squares of all the elements in the array\n",
    "      # plus a small constant (1e-6) to avoid division by zero\n",
    "      wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
    "  \n",
    "  # standard error indicating that the vectors have been read from the file \n",
    "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
    "  return wordVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectors read from: ../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean \n",
      "Vectors read from: ../data/French/word_embeddings/vecs50-linear-frwiki \n",
      "Vectors read from: ../data/French/word_embeddings/vecs100-linear-frwiki \n",
      "Vectors read from: ../data/English/output_vectors/output_vectors.txt \n",
      "Vectors read from: ../data/French/output_vectors/output_vectors.txt \n"
     ]
    }
   ],
   "source": [
    "# Load pre_trained word embeddings\n",
    "# ENGLISH\n",
    "EN_file_non_ret = read_word_vecs(\"../data/English/wordEmbeddings/vectors_datatxt_250_sg_w10_i5_c500_gensim_clean\")\n",
    "# FRENCH\n",
    "FR_file_non_ret_50 = read_word_vecs(\"../data/French/word_embeddings/vecs50-linear-frwiki\")\n",
    "FR_file_non_ret_100 = read_word_vecs(\"../data/French/word_embeddings/vecs100-linear-frwiki\")\n",
    "\n",
    "# Load retrofitted word embeddings\n",
    "# ENGLISH\n",
    "EN_file_ret =read_word_vecs(\"../data/English/output_vectors/output_vectors.txt\")\n",
    "# FRENCH\n",
    "FR_file_ret_100 = read_word_vecs(\"../data/French/output_vectors/output_vectors.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENGLISH\n",
    "\n",
    "#open english lexical_similarity file\n",
    "lex_sim_eng = open (\"../data/English/lexicon/ws353_lexical_similarity.txt\", 'r')\n",
    "#list of word pairs from the lexical similarity file\n",
    "word_pairs_eng = []\n",
    "#list of human scores for each word pair\n",
    "hum_score_eng = []\n",
    "\n",
    "#for every line in the file\n",
    "for line in lex_sim_eng:\n",
    "    #split the line by space\n",
    "    #one line contains the word pair and its score\n",
    "    w1, w2, score = line.split()\n",
    "    #add the words to word_pairs\n",
    "    word_pairs_eng.append((w1, w2))\n",
    "    #add the ratings to human_score\n",
    "    hum_score_eng.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('love', 'sex')\n",
      "6.77\n"
     ]
    }
   ],
   "source": [
    "print(word_pairs_eng[0])\n",
    "print(hum_score_eng[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRENCH\n",
    "\n",
    "#open lexical_similarity file\n",
    "lex_sim_fre = open (\"../data/French/lexicon/rg65_french.txt\", 'r')\n",
    "#list of word pairs from the lexical similarity file\n",
    "word_pairs_fre = []\n",
    "#list of human scores for each word pair\n",
    "hum_score_fre = []\n",
    "#open lexical_similarity file\n",
    "\n",
    "#for every line in the file\n",
    "for line in lex_sim_fre:\n",
    "    #split the line by space\n",
    "    #one line contains the word pair and its score\n",
    "    w1, w2, score = line.split()\n",
    "    #add the words to word_pairs\n",
    "    word_pairs_fre.append((w1, w2))\n",
    "    #add the ratings to human_score\n",
    "    hum_score_fre.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('corde', 'sourire')\n",
      "0.00\n"
     ]
    }
   ],
   "source": [
    "print(word_pairs_fre[0])\n",
    "print(hum_score_fre[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Compute cosine similarity for non-retrofitted vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENGLISH\n",
    "\n",
    "#list of cosine similarities between non-retrofitted vectors\n",
    "cos_non_ret_eng = []\n",
    "\n",
    "#for every word pair\n",
    "for w1, w2 in word_pairs_eng:\n",
    "    #check if the words exist in the word_embeddings\n",
    "    if w1 in EN_file_non_ret and w2 in EN_file_non_ret:\n",
    "        #retrieve word1's vector \n",
    "        vec1 = EN_file_non_ret[w1]\n",
    "        #retreive word2's vector\n",
    "        vec2 = EN_file_non_ret[w2]\n",
    "        #calculate cosine between the two vectors\n",
    "        similarity = 1 - cosine(vec1, vec2)\n",
    "        #add the result to scores\n",
    "        cos_non_ret_eng.append(round(similarity, 2))\n",
    "    #otherwise if words don't exist in the word embeddings\n",
    "    else:\n",
    "        #assign default value of 0.0\n",
    "        cos_non_ret_eng.append(0.00)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRENCH\n",
    "\n",
    "#list of cosine similarities between non-retrofitted vectors\n",
    "cos_non_ret_fre_100 = []\n",
    "\n",
    "#for every word pair\n",
    "for w1, w2 in word_pairs_fre:\n",
    "    #check if the words exist in the word_embeddings\n",
    "    if w1 in FR_file_non_ret_100 and w2 in FR_file_non_ret_100:\n",
    "        #retrieve word1's vector \n",
    "        vec1 = FR_file_non_ret_100[w1]\n",
    "        #retreive word2's vector\n",
    "        vec2 = FR_file_non_ret_100[w2]\n",
    "        #calculate cosine between the two vectors\n",
    "        similarity = 1 - cosine(vec1, vec2)\n",
    "        #add the result to scores\n",
    "        cos_non_ret_fre_100.append(round(similarity, 2))\n",
    "    #otherwise if words don't exist in the word embeddings\n",
    "    else:\n",
    "        #assign default value of 0.0\n",
    "        cos_non_ret_fre_100.append(0.00)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.77', '7.35', '10.00', '7.46', '7.62', '7.58', '5.77', '6.31', '7.50', '6.77', '7.42', '6.85', '6.19', '5.92', '7.00', '6.62', '6.81', '4.62', '5.81', '7.08', '8.08', '1.62', '1.31', '0.92', '1.81', '6.69', '3.73', '0.92', '7.46', '8.12', '7.73', '9.15', '0.31', '0.23', '8.58', '5.92', '6.69', '8.46', '7.65', '1.62', '9.44', '8.62', '9.03', '6.81', '6.63', '7.56', '6.73', '7.65', '2.50', '8.38', '7.38', '6.19', '6.73', '7.92', '8.12', '7.35', '4.88', '5.54', '8.46', '8.13', '3.04', '1.31', '5.96', '6.87', '7.85', '2.65', '8.94', '8.96', '9.29', '8.83', '9.10', '8.87', '9.02', '9.29', '8.79', '7.52', '7.10', '7.38', '6.46', '6.27', '2.69', '4.46', '5.85', '5.00', '2.08', '4.42', '4.38', '1.85', '3.08', '0.92', '3.15', '0.92', '0.54', '2.08', '0.54', '0.62', '8.42', '9.08', '9.04', '8.27', '7.57', '7.29', '8.50', '7.73', '6.88', '5.65', '3.31', '8.00', '8.00', '7.08', '6.85', '7.00', '4.77', '5.62', '5.87', '8.08', '7.00', '6.85', '7.42', '6.58', '6.42', '8.21', '7.69', '7.23', '6.71', '5.58', '7.48', '8.45', '8.06', '8.08', '8.02', '8.11', '7.92', '7.94', '5.85', '3.85', '2.81', '6.65', '2.50', '1.77', '6.04', '6.58', '6.85', '2.40', '2.92', '3.69', '2.15', '7.25', '5.00', '1.92', '5.90', '7.42', '7.27', '1.81', '5.06', '5.09', '6.78', '6.06', '6.94', '8.31', '4.59', '2.94', '5.63', '8.16', '7.53', '4.56', '6.34', '6.56', '2.38', '2.22', '8.66', '4.47', '5.34', '3.69', '3.00', '8.13', '6.31', '6.22', '6.50', '3.91', '2.56', '3.00', '5.63', '7.59', '3.16', '1.19', '3.31', '6.63', '4.75', '3.69', '4.25', '6.56', '4.25', '5.88', '5.94', '7.56', '2.75', '7.03', '5.47', '6.47', '7.91', '4.97', '5.00', '5.19', '7.03', '3.44', '2.31', '5.91', '7.38', '8.13', '4.63', '5.25', '5.03', '6.69', '7.88', '4.50', '4.75', '4.47', '3.25', '5.63', '3.69', '2.94', '5.28', '5.00', '6.44', '4.13', '4.75', '2.38', '4.94', '8.06', '5.31', '8.03', '5.94', '6.00', '5.41', '1.81', '8.97', '6.00', '6.72', '8.00', '4.81', '3.88', '5.16', '2.25', '6.44', '8.88', '6.88', '4.94', '2.56', '6.38', '7.81', '1.75', '4.25', '3.88', '2.88', '7.63', '6.48', '8.44', '7.50', '8.59', '6.34', '3.38', '6.00', '3.88', '7.63', '7.78', '9.22', '7.38', '6.09', '8.50', '8.31', '7.13', '5.91', '6.47', '3.38', '3.63', '7.13', '7.89', '5.97', '7.03', '7.69', '7.47', '6.19', '6.97', '3.56', '7.47', '8.34', '8.70', '7.81', '5.70', '6.22', '6.34', '4.06', '4.47', '5.97', '7.61', '8.36', '7.41', '2.69', '3.94', '7.16', '5.63', '7.53', '8.31', '8.81', '6.25', '8.30', '5.25', '8.53', '7.94', '6.88', '5.94', '4.06', '6.25', '7.72', '6.19', '2.97', '1.94', '3.75', '3.31', '3.69', '7.44', '6.41', '5.44', '6.25', '2.63', '0.88', '3.19', '4.69', '6.75', '5.31', '7.31', '5.75', '3.97', '3.47', '3.63', '5.56', '7.83', '3.88', '5.31', '6.81', '7.59', '7.19', '4.38', '6.53', '6.19', '7.69', '6.31', '6.03', '8.34', '6.25', '6.34', '3.78']\n",
      "[0.32, 0.45, 1, 0.57, 0.49, 0.5, 0.41, 0.5, 0.37, 0.65, 0.32, 0.43, 0.81, 0.69, 0.57, 0.51, 0.46, 0.29, 0.4, 0.46, 0.54, 0.25, 0.0, 0.25, 0.17, 0.29, 0.19, 0.16, 0.38, 0.38, 0.45, 0.75, 0.1, 0.17, 0.69, 0.29, 0.44, 0.0, 0.0, 0.1, 0.26, 0.0, 0.73, 0.74, 0.5, 0.31, 0.0, 0.0, 0.0, 0.55, 0.39, 0.45, 0.33, 0.46, 0.37, 0.83, 0.23, 0.29, 0.57, 0.66, 0.35, 0.22, 0.3, 0.65, 0.61, 0.28, 0.65, 0.67, 0.51, 0.58, 0.6, 0.31, 0.47, 0.8, 0.67, 0.53, 0.47, 0.5, 0.44, 0.33, 0.14, 0.29, 0.24, 0.23, 0.4, 0.25, 0.31, 0.25, 0.38, 0.25, 0.4, 0.22, 0.24, 0.27, 0.12, 0.09, 0.47, 0.75, 0.46, 0.5, 0.36, 0.27, 0.38, 0.39, 0.18, 0.49, 0.13, 0.52, 0.4, 0.34, 0.31, 0.34, 0.17, 0.22, 0.45, 0.77, 0.4, 0.2, 0.26, 0.44, 0.43, 0.0, 0.36, 0.5, 0.67, 0.33, 0.68, 0.52, 0.5, 0.57, 0.46, 0.57, 0.41, 0.35, 0.35, 0.19, 0.08, 0.37, 0.14, 0.1, 0.29, 0.21, 0.17, 0.11, 0.11, 0.07, 0.14, 0.2, 0.08, 0.06, 0.16, 0.32, 0.47, 0.15, 0.51, 0.37, 0.42, 0.38, 0.0, 0.0, 0.32, 0.0, 0.0, 0.43, 0.31, 0.2, 0.23, 0.54, 0.17, 0.0, 0.72, 0.23, 0.17, 0.31, 0.32, 0.42, 0.3, 0.53, 0.0, 0.25, 0.31, 0.16, 0.51, 0.3, 0.22, 0.09, 0.15, 0.42, 0.28, 0.24, 0.2, 0.4, 0.36, 0.43, 0.25, 0.41, 0.29, 0.32, 0.23, 0.25, 0.44, 0.36, 0.23, 0.14, 0.58, 0.37, 0.14, 0.42, 0.4, 0.0, 0.23, 0.25, 0.34, 0.19, 0.39, 0.21, 0.31, 0.37, 0.14, 0.0, 0.22, 0.18, 0.3, 0.25, 0.3, 0.19, 0.44, 0.11, 0.31, 0.47, 0.32, 0.33, 0.32, 0.22, 0.38, 0.18, 0.52, 0.24, 0.51, 0.47, 0.37, 0.33, 0.25, 0.23, 0.28, 0.79, 0.33, 0.22, 0.12, 0.4, 0.43, 0.09, 0.58, 0.18, 0.26, 0.54, 0.35, 0.69, 0.45, 0.0, 0.32, 0.25, 0.26, 0.05, 0.2, 0.5, 0.36, 0.34, 0.12, 0.65, 0.32, 0.31, 0.24, 0.42, 0.44, 0.05, 0.18, 0.55, 0.41, 0.32, 0.36, 0.55, 0.42, 0.35, 0.42, 0.33, 0.7, 0.7, 0.48, 0.42, 0.41, 0.14, 0.34, 0.31, 0.29, 0.19, 0.74, 0.29, 0.14, 0.37, 0.26, 0.19, 0.38, 0.53, 0.58, 0.29, 0.67, 0.23, 0.71, 0.56, 0.35, 0.29, 0.37, 0.24, 0.57, 0.44, 0.2, 0.15, 0.23, 0.31, 0.39, 0.0, 0.59, 0.31, 0.15, 0.2, 0.1, 0.35, 0.36, 0.31, 0.2, 0.39, 0.16, 0.17, 0.27, 0.31, 0.48, 0.58, 0.32, 0.39, 0.49, 0.54, 0.47, 0.25, 0.16, 0.13, 0.42, 0.49, 0.25, 0.64, 0.26, 0.42, 0.3]\n"
     ]
    }
   ],
   "source": [
    "print(hum_score_eng)\n",
    "print(cos_non_ret_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.00', '0.00', '0.06', '0.11', '0.00', '0.00', '0.06', '0.00', '0.00', '0.22', '0.22', '0.44', '0.06', '0.17', '0.17', '0.50', '0.22', '0.11', '0.33', '0.39', '0.29', '0.06', '0.17', '0.44', '0.17', '0.61', '0.11', '0.28', '0.06', '2.17', '0.56', '0.28', '0.44', '0.33', '0.22', '0.56', '0.56', '0.94', '2.00', '0.83', '1.28', '1.65', '2.41', '2.78', '2.89', '3.28', '2.78', '2.67', '2.94', '3.33', '3.39', '1.50', '1.89', '2.59', '3.56', '2.50', '3.72', '3.00', '4.00', '3.83', '3.00', '4.00', '3.94', '3.22', '2.17']\n",
      "[0.47, 0.18, 0.4, 0.2, 0.24, 0.28, 0.37, 0.08, 0.35, 0.44, 0.22, 0.56, 0.35, 0.19, 0.27, 0.51, 0.44, 0.3, 0.54, 0.33, 0.1, 0.2, 0.17, 0.5, 0.38, 0.34, 0.44, 0.23, 0.4, 0.31, 0.11, 0.45, 0.48, 0.21, 0.26, 0.51, 0.32, 0.31, 0.46, 0.21, 0.16, 0.43, 0.5, 0.4, 0.64, 0.53, 0.36, 0.71, 0.19, 0.51, 0.32, 0.44, 0.33, 0.55, 0.28, 0.25, 0.67, 0.57, 1, 0.55, 0.6, 1, 0.51, 0.46, 0.02]\n"
     ]
    }
   ],
   "source": [
    "print(hum_score_fre)\n",
    "print(cos_non_ret_fre_100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Compute cosine similarity for retrofitted vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ENGLISH\n",
    "\n",
    "#list of cosine similarities between retrofitted vectors\n",
    "cos_ret_eng = []\n",
    "\n",
    "#for every word pair\n",
    "for w1, w2 in word_pairs_eng:\n",
    "    #check if the words exist in the word_embeddings\n",
    "    if w1 in EN_file_ret and w2 in EN_file_ret:\n",
    "        #retrieve word1's vector \n",
    "        vec1 = EN_file_ret[w1]\n",
    "        #retreive word2's vector\n",
    "        vec2 = EN_file_ret[w2]\n",
    "        #calculate cosine between the two vectors\n",
    "        similarity = 1 - cosine(vec1, vec2)\n",
    "        #add the result to scores\n",
    "        cos_ret_eng.append(round(similarity, 2))\n",
    "    #otherwise if words don't exist in the word embeddings\n",
    "    else:\n",
    "        #assign default value of 0.0\n",
    "        cos_ret_eng.append(0.00)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRENCH\n",
    "\n",
    "#list of cosine similarities between retrofitted vectors\n",
    "cos_ret_fre_100 = []\n",
    "\n",
    "#for every word pair\n",
    "for w1, w2 in word_pairs_fre:\n",
    "    #check if the words exist in the word_embeddings\n",
    "    if w1 in FR_file_ret_100 and w2 in FR_file_ret_100:\n",
    "        #retrieve word1's vector \n",
    "        vec1 = FR_file_ret_100[w1]\n",
    "        #retreive word2's vector\n",
    "        vec2 = FR_file_ret_100[w2]\n",
    "        #calculate cosine between the two vectors\n",
    "        similarity = 1 - cosine(vec1, vec2)\n",
    "        #add the result to scores\n",
    "        cos_ret_fre_100.append(round(similarity, 2))\n",
    "    #otherwise if words don't exist in the word embeddings\n",
    "    else:\n",
    "        #assign default value of 0.0\n",
    "        cos_ret_fre_100.append(0.00)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6.77', '7.35', '10.00', '7.46', '7.62', '7.58', '5.77', '6.31', '7.50', '6.77', '7.42', '6.85', '6.19', '5.92', '7.00', '6.62', '6.81', '4.62', '5.81', '7.08', '8.08', '1.62', '1.31', '0.92', '1.81', '6.69', '3.73', '0.92', '7.46', '8.12', '7.73', '9.15', '0.31', '0.23', '8.58', '5.92', '6.69', '8.46', '7.65', '1.62', '9.44', '8.62', '9.03', '6.81', '6.63', '7.56', '6.73', '7.65', '2.50', '8.38', '7.38', '6.19', '6.73', '7.92', '8.12', '7.35', '4.88', '5.54', '8.46', '8.13', '3.04', '1.31', '5.96', '6.87', '7.85', '2.65', '8.94', '8.96', '9.29', '8.83', '9.10', '8.87', '9.02', '9.29', '8.79', '7.52', '7.10', '7.38', '6.46', '6.27', '2.69', '4.46', '5.85', '5.00', '2.08', '4.42', '4.38', '1.85', '3.08', '0.92', '3.15', '0.92', '0.54', '2.08', '0.54', '0.62', '8.42', '9.08', '9.04', '8.27', '7.57', '7.29', '8.50', '7.73', '6.88', '5.65', '3.31', '8.00', '8.00', '7.08', '6.85', '7.00', '4.77', '5.62', '5.87', '8.08', '7.00', '6.85', '7.42', '6.58', '6.42', '8.21', '7.69', '7.23', '6.71', '5.58', '7.48', '8.45', '8.06', '8.08', '8.02', '8.11', '7.92', '7.94', '5.85', '3.85', '2.81', '6.65', '2.50', '1.77', '6.04', '6.58', '6.85', '2.40', '2.92', '3.69', '2.15', '7.25', '5.00', '1.92', '5.90', '7.42', '7.27', '1.81', '5.06', '5.09', '6.78', '6.06', '6.94', '8.31', '4.59', '2.94', '5.63', '8.16', '7.53', '4.56', '6.34', '6.56', '2.38', '2.22', '8.66', '4.47', '5.34', '3.69', '3.00', '8.13', '6.31', '6.22', '6.50', '3.91', '2.56', '3.00', '5.63', '7.59', '3.16', '1.19', '3.31', '6.63', '4.75', '3.69', '4.25', '6.56', '4.25', '5.88', '5.94', '7.56', '2.75', '7.03', '5.47', '6.47', '7.91', '4.97', '5.00', '5.19', '7.03', '3.44', '2.31', '5.91', '7.38', '8.13', '4.63', '5.25', '5.03', '6.69', '7.88', '4.50', '4.75', '4.47', '3.25', '5.63', '3.69', '2.94', '5.28', '5.00', '6.44', '4.13', '4.75', '2.38', '4.94', '8.06', '5.31', '8.03', '5.94', '6.00', '5.41', '1.81', '8.97', '6.00', '6.72', '8.00', '4.81', '3.88', '5.16', '2.25', '6.44', '8.88', '6.88', '4.94', '2.56', '6.38', '7.81', '1.75', '4.25', '3.88', '2.88', '7.63', '6.48', '8.44', '7.50', '8.59', '6.34', '3.38', '6.00', '3.88', '7.63', '7.78', '9.22', '7.38', '6.09', '8.50', '8.31', '7.13', '5.91', '6.47', '3.38', '3.63', '7.13', '7.89', '5.97', '7.03', '7.69', '7.47', '6.19', '6.97', '3.56', '7.47', '8.34', '8.70', '7.81', '5.70', '6.22', '6.34', '4.06', '4.47', '5.97', '7.61', '8.36', '7.41', '2.69', '3.94', '7.16', '5.63', '7.53', '8.31', '8.81', '6.25', '8.30', '5.25', '8.53', '7.94', '6.88', '5.94', '4.06', '6.25', '7.72', '6.19', '2.97', '1.94', '3.75', '3.31', '3.69', '7.44', '6.41', '5.44', '6.25', '2.63', '0.88', '3.19', '4.69', '6.75', '5.31', '7.31', '5.75', '3.97', '3.47', '3.63', '5.56', '7.83', '3.88', '5.31', '6.81', '7.59', '7.19', '4.38', '6.53', '6.19', '7.69', '6.31', '6.03', '8.34', '6.25', '6.34', '3.78']\n",
      "[0.38, 0.32, 1, 0.66, 0.31, 0.34, 0.31, 0.22, 0.19, 1.0, 0.4, 0.67, 0.35, 0.67, 0.56, 0.37, 0.45, 0.32, 0.29, 0.62, 0.57, 0.32, 0.0, 0.36, 0.38, 0.3, 0.59, 0.64, 0.66, 0.31, 0.83, 0.51, 0.17, 0.39, 0.79, 0.23, 0.16, 0.0, 0.0, 0.24, 0.44, 0.0, 1.0, 0.74, 0.5, 0.24, 0.0, 0.0, 0.0, 0.25, 0.44, 0.3, 0.3, 0.38, 0.22, 0.54, 0.28, 0.3, 0.55, 0.66, 0.39, 0.5, 0.57, 0.67, 0.59, 0.51, 0.26, 0.91, 0.87, 0.92, 0.53, 0.6, 0.6, 1.0, 0.29, 0.44, 0.51, 0.27, 0.39, 0.27, 0.5, 0.44, 0.17, 0.22, 0.45, 0.21, 0.4, 0.43, 0.38, 0.34, 0.52, 0.23, 0.24, 0.33, 0.3, 0.2, 0.32, 0.51, 0.46, 0.5, 0.28, 0.18, 0.31, 0.41, 0.2, 0.36, 0.3, 1.0, 0.4, 0.4, 0.22, 0.31, 0.27, 0.33, 0.22, 0.61, 0.14, 0.32, 0.21, 0.26, 0.32, 0.0, 0.48, 0.32, 0.44, 0.22, 0.43, 0.43, 0.2, 0.29, 0.26, 0.2, 0.31, 0.4, 0.57, 0.44, 0.35, 0.6, 0.51, 0.44, 0.44, 0.36, 0.24, 0.22, 0.34, 0.31, 0.23, 0.51, 0.27, 0.25, 0.23, 0.32, 0.22, 0.43, 0.29, 0.52, 0.38, 0.18, 0.0, 0.0, 0.57, 0.0, 0.0, 0.72, 0.12, 0.57, 0.43, 0.44, 0.6, 0.0, 0.72, 0.37, 0.24, 0.17, 0.28, 0.44, 0.77, 0.34, 0.0, 0.23, 0.41, 0.61, 0.55, 0.42, 0.23, 0.27, 0.38, 0.32, 0.33, 0.25, 0.36, 0.35, 0.26, 0.34, 0.27, 0.41, 0.25, 0.29, 0.27, 0.25, 0.47, 0.44, 0.41, 0.34, 0.42, 0.57, 0.24, 0.4, 0.28, 0.0, 0.38, 0.45, 0.25, 0.24, 0.56, 0.51, 0.36, 0.32, 0.15, 0.0, 0.4, 0.35, 0.33, 0.49, 0.18, 0.11, 0.25, 0.13, 0.4, 0.55, 0.61, 0.2, 0.35, 0.6, 0.39, 0.21, 0.28, 0.37, 0.44, 0.53, 0.6, 0.29, 0.48, 0.48, 0.42, 1.0, 0.26, 0.25, 0.41, 0.45, 0.34, 0.3, 0.44, 0.56, 0.55, 0.33, 0.23, 0.93, 0.4, 0.0, 0.48, 0.21, 0.48, 0.52, 0.44, 0.23, 0.79, 0.36, 0.34, 0.33, 0.52, 0.31, 0.24, 0.1, 0.3, 0.43, 0.33, 0.15, 0.17, 0.54, 0.42, 0.35, 0.41, 0.47, 0.3, 0.33, 0.18, 0.7, 0.14, 0.2, 0.49, 0.13, 0.43, 0.76, 0.65, 0.68, 0.2, 0.45, 0.45, 0.22, 0.24, 0.16, 0.33, 0.53, 0.38, 0.44, 0.54, 0.22, 0.37, 0.15, 0.28, 0.49, 0.54, 0.37, 0.34, 0.31, 0.31, 0.36, 0.54, 0.18, 0.26, 0.0, 0.33, 0.33, 0.37, 0.25, 0.33, 0.56, 0.31, 0.38, 0.26, 0.35, 0.25, 0.69, 0.32, 0.38, 0.46, 0.43, 0.33, 0.23, 0.07, 0.46, 0.35, 0.22, 0.62, 0.46, 0.39, 0.38, 0.66, 0.45, 0.22, 0.4, 0.25]\n"
     ]
    }
   ],
   "source": [
    "print(hum_score_eng)\n",
    "print(cos_ret_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.00', '0.00', '0.06', '0.11', '0.00', '0.00', '0.06', '0.00', '0.00', '0.22', '0.22', '0.44', '0.06', '0.17', '0.17', '0.50', '0.22', '0.11', '0.33', '0.39', '0.29', '0.06', '0.17', '0.44', '0.17', '0.61', '0.11', '0.28', '0.06', '2.17', '0.56', '0.28', '0.44', '0.33', '0.22', '0.56', '0.56', '0.94', '2.00', '0.83', '1.28', '1.65', '2.41', '2.78', '2.89', '3.28', '2.78', '2.67', '2.94', '3.33', '3.39', '1.50', '1.89', '2.59', '3.56', '2.50', '3.72', '3.00', '4.00', '3.83', '3.00', '4.00', '3.94', '3.22', '2.17']\n",
      "[0.47, 0.18, 0.4, 0.2, 0.24, 0.37, 0.31, 0.36, 0.47, 0.27, 0.45, 0.56, 0.35, 0.19, 0.27, 0.24, 0.44, 0.12, 0.54, 0.31, 0.15, 0.32, 0.17, 0.38, 0.38, 0.34, 0.44, 0.34, 0.4, 0.31, 0.17, 0.45, 0.48, 0.53, 0.26, 0.51, 0.57, 0.19, 0.39, 0.12, 0.2, 0.43, 0.5, 0.4, 0.64, 0.42, 0.29, 0.71, 0.19, 0.51, 0.35, 0.23, 0.33, 0.22, 0.16, 0.25, 0.67, 0.35, 1, 0.26, 0.6, 1, 0.9, 0.46, 0.02]\n"
     ]
    }
   ],
   "source": [
    "print(hum_score_fre)\n",
    "print(cos_ret_fre_100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computing correlation scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman correlation coefficient for english (using non-retrofitted vectors):  0.576\n",
      "\n",
      "The Spearman correlation coefficient for french (using non-retrofitted vectors (100)):  0.472\n"
     ]
    }
   ],
   "source": [
    "#calculate the spearman rank correlation between human ratings and non-retrofitted vectors\n",
    "spearman_non_ret_eng, _ = spearmanr(hum_score_eng, cos_non_ret_eng)\n",
    "print(\"The Spearman correlation coefficient for english (using non-retrofitted vectors): \", round(spearman_non_ret_eng,3))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "spearman_non_ret_fre_100, _ = spearmanr(hum_score_fre, cos_non_ret_fre_100)\n",
    "print(\"The Spearman correlation coefficient for french (using non-retrofitted vectors (100)): \", round(spearman_non_ret_fre_100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Spearman correlation coefficient for english (using retrofitted vectors):  0.137\n",
      "\n",
      "The Spearman correlation coefficient for french (using retrofitted vectors):  0.226\n"
     ]
    }
   ],
   "source": [
    "#calculate the spearman rank correlation between human ratings and retrofitted vectors\n",
    "spearman_ret_eng, _ = spearmanr(hum_score_eng, cos_ret_eng)\n",
    "print(\"The Spearman correlation coefficient for english (using retrofitted vectors): \", round(spearman_ret_eng,3))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "spearman_ret_fre_100, _ = spearmanr(hum_score_fre, cos_ret_fre_100)\n",
    "print(\"The Spearman correlation coefficient for french (using retrofitted vectors): \", round(spearman_ret_fre_100,3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation coefficient for english (using non-retrofitted vectors :  0.5606\n",
      "p_value:  0.0\n",
      "\n",
      "\n",
      "The Pearson correlation coefficient for french (using non-retrofitted vectors (100)):  0.5209\n",
      "p_value:  0.0\n"
     ]
    }
   ],
   "source": [
    "#convert values from string to float\n",
    "hum_score_eng = [float(value) for value in (hum_score_eng)]\n",
    "#compute the pearson correlation coefficient and the p_value between human ratings and non-retrofitted vectors\n",
    "pearson_non_ret_eng, p_value_non_ret_eng = pearsonr(hum_score_eng, cos_non_ret_eng)\n",
    "\n",
    "#print results\n",
    "print(\"The Pearson correlation coefficient for english (using non-retrofitted vectors : \", round(pearson_non_ret_eng, 4))\n",
    "print(\"p_value: \", round(p_value_non_ret_eng, 4))\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "#convert values from string to float\n",
    "hum_score_fre = [float(value) for value in (hum_score_fre)]\n",
    "#compute the pearson correlation coefficient and the p_value\n",
    "pearson_non_ret_fre_100, p_value_non_ret_fre_100 = pearsonr(hum_score_fre, cos_non_ret_fre_100)\n",
    "\n",
    "print(\"\")\n",
    "#print results\n",
    "print(\"The Pearson correlation coefficient for french (using non-retrofitted vectors (100)): \", round(pearson_non_ret_fre_100, 4))\n",
    "print(\"p_value: \", round(p_value_non_ret_fre_100, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Pearson correlation coefficient for english (using retrofitted vectors :  0.1908\n",
      "p_value:  0.0003\n",
      "The Pearson correlation coefficient for french (using retrofitted vectors:  0.3891\n",
      "p_value:  0.0014\n"
     ]
    }
   ],
   "source": [
    "#compute the pearson correlation coefficient and the p_value between human ratings and retrofitted vectors\n",
    "pearson_ret_eng, p_value_ret_eng = pearsonr(hum_score_eng, cos_ret_eng)\n",
    "\n",
    "#print results\n",
    "print(\"The Pearson correlation coefficient for english (using retrofitted vectors : \", round(pearson_ret_eng, 4))\n",
    "print(\"p_value: \", round(p_value_ret_eng, 4))\n",
    "\n",
    "pearson_ret_fre_100, p_value_ret_fre_100 = pearsonr(hum_score_fre, cos_ret_fre_100)\n",
    "\n",
    "#print results\n",
    "print(\"The Pearson correlation coefficient for french (using retrofitted vectors: \", round(pearson_ret_fre_100, 4))\n",
    "print(\"p_value: \", round(p_value_ret_fre_100, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
